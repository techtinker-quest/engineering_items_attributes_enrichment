{
  "metadata": {
    "tool": "Python Symbol Table Builder",
    "version": "2.0.0",
    "scan_time": "2025-11-10T03:02:39.374700",
    "project_root": "C:\\00Projects\\engineering_items_attributes_enrichment",
    "files_scanned": 54,
    "errors": 0,
    "include_private": true
  },
  "modules": {
    "main": {
      "file_path": "C:\\00Projects\\engineering_items_attributes_enrichment\\main.py",
      "module_docstring": null,
      "classes": {},
      "functions": []
    },
    "deployment.setup": {
      "file_path": "C:\\00Projects\\engineering_items_attributes_enrichment\\deployment\\setup.py",
      "module_docstring": null,
      "classes": {},
      "functions": []
    },
    "scripts.download_models": {
      "file_path": "C:\\00Projects\\engineering_items_attributes_enrichment\\scripts\\download_models.py",
      "module_docstring": "Download YOLOv8 models for shape detection.",
      "classes": {},
      "functions": [
        {
          "name": "download_file",
          "line": 18,
          "docstring": "Download file with progress bar.",
          "signature": {
            "parameters": [
              {
                "name": "url",
                "type": "str"
              },
              {
                "name": "destination",
                "type": "Path"
              }
            ],
            "return_type": null
          }
        },
        {
          "name": "main",
          "line": 31,
          "docstring": null,
          "signature": {
            "parameters": [],
            "return_type": null
          }
        }
      ]
    },
    "scripts.setup_environment": {
      "file_path": "C:\\00Projects\\engineering_items_attributes_enrichment\\scripts\\setup_environment.py",
      "module_docstring": "Environment Setup Script\n\nSets up the complete environment for the Drawing Intelligence System.",
      "classes": {},
      "functions": [
        {
          "name": "print_header",
          "line": 14,
          "docstring": "Print formatted header.",
          "signature": {
            "parameters": [
              {
                "name": "message",
                "type": "str"
              }
            ],
            "return_type": null
          }
        },
        {
          "name": "check_python_version",
          "line": 21,
          "docstring": "Check Python version.",
          "signature": {
            "parameters": [],
            "return_type": null
          }
        },
        {
          "name": "create_directories",
          "line": 36,
          "docstring": "Create required directories.",
          "signature": {
            "parameters": [],
            "return_type": null
          }
        },
        {
          "name": "install_dependencies",
          "line": 61,
          "docstring": "Install Python dependencies.",
          "signature": {
            "parameters": [],
            "return_type": null
          }
        },
        {
          "name": "setup_configuration",
          "line": 86,
          "docstring": "Setup configuration files.",
          "signature": {
            "parameters": [],
            "return_type": null
          }
        },
        {
          "name": "setup_environment_variables",
          "line": 209,
          "docstring": "Guide user through environment variable setup.",
          "signature": {
            "parameters": [],
            "return_type": null
          }
        },
        {
          "name": "download_models_prompt",
          "line": 234,
          "docstring": "Prompt user to download models.",
          "signature": {
            "parameters": [],
            "return_type": null
          }
        },
        {
          "name": "run_tests",
          "line": 254,
          "docstring": "Run test suite.",
          "signature": {
            "parameters": [],
            "return_type": null
          }
        },
        {
          "name": "print_summary",
          "line": 272,
          "docstring": "Print setup summary.",
          "signature": {
            "parameters": [],
            "return_type": null
          }
        },
        {
          "name": "main",
          "line": 297,
          "docstring": "Run complete setup.",
          "signature": {
            "parameters": [],
            "return_type": null
          }
        }
      ]
    },
    "scripts.validate_installation": {
      "file_path": "C:\\00Projects\\engineering_items_attributes_enrichment\\scripts\\validate_installation.py",
      "module_docstring": "Validate system installation and dependencies.",
      "classes": {},
      "functions": [
        {
          "name": "check_python_version",
          "line": 25,
          "docstring": "Check Python version.",
          "signature": {
            "parameters": [],
            "return_type": null
          }
        },
        {
          "name": "check_dependencies",
          "line": 35,
          "docstring": "Check required packages.",
          "signature": {
            "parameters": [],
            "return_type": null
          }
        },
        {
          "name": "check_structure",
          "line": 48,
          "docstring": "Check directory structure.",
          "signature": {
            "parameters": [],
            "return_type": null
          }
        },
        {
          "name": "main",
          "line": 61,
          "docstring": null,
          "signature": {
            "parameters": [],
            "return_type": null
          }
        }
      ]
    },
    "src.drawing_intelligence": {
      "file_path": "C:\\00Projects\\engineering_items_attributes_enrichment\\src\\drawing_intelligence\\__init__.py",
      "module_docstring": "Drawing Intelligence System\n\nAutomated extraction of structured data from engineering drawings.",
      "classes": {},
      "functions": []
    },
    "src.drawing_intelligence.cli.config_validator": {
      "file_path": "C:\\00Projects\\engineering_items_attributes_enrichment\\src\\drawing_intelligence\\cli\\config_validator.py",
      "module_docstring": "Configuration Validator Module.\n\nThis module provides comprehensive validation for system configuration settings.\nIt validates paths, LLM integration, model files, and database configuration\nusing a modular, profile-based approach.\n\nExample:\n    >>> from drawing_intelligence.cli.config_validator import ConfigValidator\n    >>> validator = ConfigValidator(config, profile=\"strict\")\n    >>> result = validator.validate_all()\n    >>> if not result:\n    ...     print(f\"Validation failed: {result.errors}\")",
      "classes": {
        "ValidationProfile": {
          "line": 36,
          "docstring": "Validation strictness profiles.",
          "bases": [
            "Enum"
          ],
          "methods": [],
          "nested_classes": []
        },
        "ProviderName": {
          "line": 44,
          "docstring": "Supported LLM provider names.",
          "bases": [
            "Enum"
          ],
          "methods": [],
          "nested_classes": []
        },
        "ConfigurationValidationError": {
          "line": 77,
          "docstring": "Base exception for configuration validation errors.",
          "bases": [
            "Exception"
          ],
          "methods": [
            {
              "name": "__init__",
              "line": 80,
              "docstring": null,
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "message",
                    "type": "str"
                  },
                  {
                    "name": "config_key",
                    "type": "Optional[str]"
                  }
                ],
                "return_type": null
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        },
        "CriticalConfigError": {
          "line": 85,
          "docstring": "Raised for critical configuration errors that prevent startup.",
          "bases": [
            "ConfigurationValidationError"
          ],
          "methods": [],
          "nested_classes": []
        },
        "PathConfigError": {
          "line": 91,
          "docstring": "Raised for path-related configuration errors.",
          "bases": [
            "ConfigurationValidationError"
          ],
          "methods": [],
          "nested_classes": []
        },
        "APIKeyError": {
          "line": 97,
          "docstring": "Raised for API key validation errors.",
          "bases": [
            "ConfigurationValidationError"
          ],
          "methods": [],
          "nested_classes": []
        },
        "ValidationResult": {
          "line": 109,
          "docstring": "Immutable container for configuration validation results.\n\nAttributes:\n    is_valid: True if configuration passes all validation checks.\n    errors: List of critical error messages that prevent system operation.\n    warnings: List of non-critical warnings that don't prevent operation.\n    info: List of informational messages about the validation process.",
          "bases": [],
          "methods": [
            {
              "name": "__bool__",
              "line": 124,
              "docstring": "Allow using ValidationResult in boolean context.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "bool"
              },
              "method_type": "instance"
            },
            {
              "name": "to_dict",
              "line": 128,
              "docstring": "Convert to dictionary for JSON serialization.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "Dict[str, any]"
              },
              "method_type": "instance"
            },
            {
              "name": "to_json",
              "line": 137,
              "docstring": "Convert to JSON string.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "str"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        },
        "BaseValidator": {
          "line": 147,
          "docstring": "Abstract base class for configuration validators.",
          "bases": [
            "ABC"
          ],
          "methods": [
            {
              "name": "__init__",
              "line": 150,
              "docstring": null,
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "config",
                    "type": "'SystemConfig'"
                  },
                  {
                    "name": "profile",
                    "type": "ValidationProfile"
                  }
                ],
                "return_type": null
              },
              "method_type": "instance"
            },
            {
              "name": "validate",
              "line": 155,
              "docstring": "Validate configuration section.\n\nReturns:\n    Tuple of (errors, warnings).",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "Tuple[List[str], List[str]]"
              },
              "method_type": "instance"
            },
            {
              "name": "_get_section",
              "line": 163,
              "docstring": "Get configuration section with unified error handling.\n\nArgs:\n    section_name: Name of the configuration section.\n    required: Whether the section is required.\n\nReturns:\n    Configuration section object or None if not required and missing.\n\nRaises:\n    CriticalConfigError: If required section is missing.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "section_name",
                    "type": "str"
                  },
                  {
                    "name": "required",
                    "type": "bool"
                  }
                ],
                "return_type": "Optional[any]"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        },
        "PathValidator": {
          "line": 191,
          "docstring": "Validates file system path configurations.",
          "bases": [
            "BaseValidator"
          ],
          "methods": [
            {
              "name": "validate",
              "line": 194,
              "docstring": "Validate all path configurations.\n\nReturns:\n    Tuple of (errors, warnings).",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "Tuple[List[str], List[str]]"
              },
              "method_type": "instance"
            },
            {
              "name": "_validate_and_create_dir",
              "line": 237,
              "docstring": "Validate a directory path and optionally create it.\n\nArgs:\n    paths_obj: Paths configuration object.\n    path_key: Key name in paths configuration.\n    description: Human-readable description of the path.\n    auto_create: Whether to create the directory if missing.\n\nReturns:\n    Tuple of (errors, warnings).",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "paths_obj",
                    "type": "any"
                  },
                  {
                    "name": "path_key",
                    "type": "str"
                  },
                  {
                    "name": "description",
                    "type": "str"
                  },
                  {
                    "name": "auto_create",
                    "type": "bool"
                  }
                ],
                "return_type": "Tuple[List[str], List[str]]"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        },
        "LLMValidator": {
          "line": 326,
          "docstring": "Validates LLM integration configuration.",
          "bases": [
            "BaseValidator"
          ],
          "methods": [
            {
              "name": "register_provider",
              "line": 333,
              "docstring": "Decorator to register provider-specific validators.",
              "signature": {
                "parameters": [
                  {
                    "name": "cls"
                  },
                  {
                    "name": "provider",
                    "type": "ProviderName"
                  }
                ],
                "return_type": "Callable[[Callable], Callable]"
              },
              "method_type": "class"
            },
            {
              "name": "validate",
              "line": 344,
              "docstring": "Validate LLM configuration and API keys.\n\nReturns:\n    Tuple of (errors, warnings).",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "Tuple[List[str], List[str]]"
              },
              "method_type": "instance"
            },
            {
              "name": "_validate_provider",
              "line": 405,
              "docstring": "Validate a single provider configuration.\n\nArgs:\n    llm_config: LLM configuration object.\n    provider_key: Key for provider (e.g., 'primary_provider').\n    required: Whether this provider is required.\n\nReturns:\n    Tuple of (errors, warnings).",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "llm_config",
                    "type": "any"
                  },
                  {
                    "name": "provider_key",
                    "type": "str"
                  },
                  {
                    "name": "required",
                    "type": "bool"
                  }
                ],
                "return_type": "Tuple[List[str], List[str]]"
              },
              "method_type": "instance"
            },
            {
              "name": "_validate_cost_controls",
              "line": 461,
              "docstring": "Validate cost control settings.\n\nArgs:\n    llm_config: LLM configuration object.\n\nReturns:\n    Tuple of (errors, warnings).",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "llm_config",
                    "type": "any"
                  }
                ],
                "return_type": "Tuple[List[str], List[str]]"
              },
              "method_type": "instance"
            },
            {
              "name": "_validate_api_key_format",
              "line": 501,
              "docstring": "Validate API key format using provider registry.\n\nArgs:\n    provider: Provider name (e.g., 'openai', 'anthropic').\n    api_key: The API key string to validate.\n\nReturns:\n    Tuple of (is_valid, error_message).",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "provider",
                    "type": "str"
                  },
                  {
                    "name": "api_key",
                    "type": "str"
                  }
                ],
                "return_type": "Tuple[bool, str]"
              },
              "method_type": "instance"
            },
            {
              "name": "_check_api_key_security",
              "line": 526,
              "docstring": "Check for potentially fake or exposed API keys.\n\nArgs:\n    api_key: API key to check.\n\nReturns:\n    List of security warnings.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "api_key",
                    "type": "str"
                  }
                ],
                "return_type": "List[str]"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        },
        "ModelValidator": {
          "line": 583,
          "docstring": "Validates YOLO model file configuration.",
          "bases": [
            "BaseValidator"
          ],
          "methods": [
            {
              "name": "validate",
              "line": 586,
              "docstring": "Validate YOLO model files.\n\nReturns:\n    Tuple of (errors, warnings).",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "Tuple[List[str], List[str]]"
              },
              "method_type": "instance"
            },
            {
              "name": "_validate_model_file",
              "line": 618,
              "docstring": "Validate model file existence and properties.\n\nArgs:\n    detection_config: Shape detection configuration object.\n\nReturns:\n    Tuple of (errors, warnings).",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "detection_config",
                    "type": "any"
                  }
                ],
                "return_type": "Tuple[List[str], List[str]]"
              },
              "method_type": "instance"
            },
            {
              "name": "_validate_device",
              "line": 673,
              "docstring": "Validate device configuration for model inference.\n\nArgs:\n    detection_config: Shape detection configuration object.\n\nReturns:\n    Tuple of (errors, warnings).",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "detection_config",
                    "type": "any"
                  }
                ],
                "return_type": "Tuple[List[str], List[str]]"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        },
        "DatabaseValidator": {
          "line": 716,
          "docstring": "Validates database configuration.",
          "bases": [
            "BaseValidator"
          ],
          "methods": [
            {
              "name": "validate",
              "line": 719,
              "docstring": "Validate database configuration.\n\nReturns:\n    Tuple of (errors, warnings).",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "Tuple[List[str], List[str]]"
              },
              "method_type": "instance"
            },
            {
              "name": "_validate_database_path",
              "line": 746,
              "docstring": "Validate database file path and permissions.\n\nArgs:\n    db_config: Database configuration object.\n\nReturns:\n    Tuple of (errors, warnings).",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "db_config",
                    "type": "any"
                  }
                ],
                "return_type": "Tuple[List[str], List[str]]"
              },
              "method_type": "instance"
            },
            {
              "name": "_validate_backup_config",
              "line": 801,
              "docstring": "Validate backup configuration.\n\nArgs:\n    db_config: Database configuration object.\n\nReturns:\n    Tuple of (errors, warnings).",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "db_config",
                    "type": "any"
                  }
                ],
                "return_type": "Tuple[List[str], List[str]]"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        },
        "ConfigValidator": {
          "line": 845,
          "docstring": "Main configuration validator coordinating all validation modules.\n\nAttributes:\n    config: The SystemConfig object to validate.\n    profile: Validation strictness profile.",
          "bases": [],
          "methods": [
            {
              "name": "__init__",
              "line": 853,
              "docstring": "Initialize the configuration validator.\n\nArgs:\n    config: SystemConfig object containing all configuration settings.\n    profile: Validation profile ('permissive', 'standard', 'strict').\n\nRaises:\n    ValueError: If profile is invalid.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "config",
                    "type": "'SystemConfig'"
                  },
                  {
                    "name": "profile",
                    "type": "str"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "validate_all",
              "line": 878,
              "docstring": "Validate all configuration sections.\n\nPerforms comprehensive validation using modular validators for each\nconfiguration area. Aggregates all errors, warnings, and info\nmessages into a single ValidationResult.\n\nReturns:\n    ValidationResult containing validation status and all messages.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "ValidationResult"
              },
              "method_type": "instance"
            },
            {
              "name": "print_validation_report",
              "line": 951,
              "docstring": "Print formatted validation report to console.\n\nDisplays a human-readable report with sections for information,\nwarnings, and errors, along with a final validation status.\nOptionally outputs in JSON format.\n\nArgs:\n    result: ValidationResult object to format and display.\n    use_json: If True, output JSON format instead of human-readable.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "result",
                    "type": "ValidationResult"
                  },
                  {
                    "name": "use_json",
                    "type": "bool"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        }
      },
      "functions": [
        {
          "name": "validate_openai_key",
          "line": 552,
          "docstring": "Validate OpenAI API key format.",
          "signature": {
            "parameters": [
              {
                "name": "api_key",
                "type": "str"
              }
            ],
            "return_type": "Tuple[bool, str]"
          }
        },
        {
          "name": "validate_anthropic_key",
          "line": 560,
          "docstring": "Validate Anthropic API key format.",
          "signature": {
            "parameters": [
              {
                "name": "api_key",
                "type": "str"
              }
            ],
            "return_type": "Tuple[bool, str]"
          }
        },
        {
          "name": "validate_google_key",
          "line": 568,
          "docstring": "Validate Google API key format.",
          "signature": {
            "parameters": [
              {
                "name": "api_key",
                "type": "str"
              }
            ],
            "return_type": "Tuple[bool, str]"
          }
        },
        {
          "name": "validate_config",
          "line": 1012,
          "docstring": "Convenience function to validate configuration.\n\nArgs:\n    config: SystemConfig object to validate.\n    profile: Validation profile ('permissive', 'standard', 'strict').\n    print_report: Whether to print the validation report.\n    json_output: Whether to use JSON format for report.\n\nReturns:\n    ValidationResult object.\n\nExample:\n    >>> from drawing_intelligence.utils.config_loader import Config\n    >>> config = Config.load()\n    >>> result = validate_config(config, profile=\"strict\")\n    >>> if not result:\n    ...     sys.exit(1)",
          "signature": {
            "parameters": [
              {
                "name": "config",
                "type": "'SystemConfig'"
              },
              {
                "name": "profile",
                "type": "str"
              },
              {
                "name": "print_report",
                "type": "bool"
              },
              {
                "name": "json_output",
                "type": "bool"
              }
            ],
            "return_type": "ValidationResult"
          }
        }
      ]
    },
    "src.drawing_intelligence.cli.main": {
      "file_path": "C:\\00Projects\\engineering_items_attributes_enrichment\\src\\drawing_intelligence\\cli\\main.py",
      "module_docstring": "CLI Interface Module\n\nProvides command-line interface for the Drawing Intelligence System, supporting\nsingle drawing processing, batch operations, exports, cost reporting, and\nsystem configuration validation.\n\nThis module serves as the primary entry point for all CLI operations and\ncoordinates between system components (database, orchestration, export, etc.).",
      "classes": {},
      "functions": [
        {
          "name": "setup_logging",
          "line": 65,
          "docstring": "Configure logging for the CLI application.\n\nSets up console logging with timestamp, logger name, level, and message\nformat. Application output goes to stdout, logs go to stderr.\n\nArgs:\n    log_level: Logging level as string (DEBUG, INFO, WARNING, ERROR).\n        Defaults to \"INFO\".",
          "signature": {
            "parameters": [
              {
                "name": "log_level",
                "type": "str"
              }
            ],
            "return_type": "None"
          }
        },
        {
          "name": "get_database_manager",
          "line": 83,
          "docstring": "Context manager for database connections.\n\nArgs:\n    config_path: Path to system configuration file.\n\nYields:\n    tuple: (Config, DatabaseManager) objects.\n\nRaises:\n    ConfigurationError: If configuration cannot be loaded.\n    DatabaseError: If database connection fails.",
          "signature": {
            "parameters": [
              {
                "name": "config_path",
                "type": "str"
              }
            ],
            "return_type": null
          }
        },
        {
          "name": "initialize_components",
          "line": 107,
          "docstring": "Initialize core system components.\n\nArgs:\n    config: Loaded system configuration.\n    db: Database manager instance.\n\nReturns:\n    tuple: (BudgetController, CheckpointManager, RoutingEngine,\n            PipelineOrchestrator)",
          "signature": {
            "parameters": [
              {
                "name": "config"
              },
              {
                "name": "db",
                "type": "DatabaseManager"
              }
            ],
            "return_type": null
          }
        },
        {
          "name": "validate_path",
          "line": 142,
          "docstring": "Validate file or directory path.\n\nArgs:\n    path: Path to validate.\n    must_exist: Whether the path must exist.\n\nRaises:\n    FileNotFoundError: If path doesn't exist and must_exist is True.\n    ValueError: If path is invalid.",
          "signature": {
            "parameters": [
              {
                "name": "path",
                "type": "Path"
              },
              {
                "name": "must_exist",
                "type": "bool"
              }
            ],
            "return_type": "None"
          }
        },
        {
          "name": "ensure_output_directory",
          "line": 163,
          "docstring": "Create output directory if it doesn't exist.\n\nArgs:\n    path: Directory path to create.\n\nRaises:\n    PermissionError: If directory cannot be created.",
          "signature": {
            "parameters": [
              {
                "name": "path",
                "type": "Path"
              }
            ],
            "return_type": "None"
          }
        },
        {
          "name": "handle_error",
          "line": 178,
          "docstring": "Centralized error handling for commands.\n\nArgs:\n    context: Description of the operation that failed.\n    error: Exception that was raised.\n\nReturns:\n    Exit code 1.",
          "signature": {
            "parameters": [
              {
                "name": "context",
                "type": "str"
              },
              {
                "name": "error",
                "type": "Exception"
              }
            ],
            "return_type": "int"
          }
        },
        {
          "name": "main",
          "line": 201,
          "docstring": "Execute the main CLI entry point.\n\nParses command-line arguments, configures logging, and routes to the\nappropriate command handler. All exceptions are caught and logged.\n\nReturns:\n    Exit code: 0 for success, non-zero for errors.\n\nExample:\n    $ python main.py process drawing.pdf\n    $ python main.py batch --input-dir ./drawings --workers 4",
          "signature": {
            "parameters": [],
            "return_type": "int"
          }
        },
        {
          "name": "command_process",
          "line": 255,
          "docstring": "Process a single PDF drawing through the extraction pipeline.\n\nInitializes all required components (database, budget controller, routing\nengine, orchestrator) and processes the specified drawing. Optionally\nexports results in JSON or CSV format.\n\nArgs:\n    args: Parsed command-line arguments containing:\n        - pdf_path: Path to the PDF file to process\n        - force_llm: Whether to force LLM enhancement\n        - export: Whether to export results\n        - export_format: Format for export (json/csv)\n        - output: Optional output path\n        - config: Path to system configuration file\n\nReturns:\n    Exit code: 0 for success, 1 for failure.",
          "signature": {
            "parameters": [
              {
                "name": "args",
                "type": "argparse.Namespace"
              }
            ],
            "return_type": "int"
          }
        },
        {
          "name": "command_batch",
          "line": 307,
          "docstring": "Process multiple PDF drawings in batch mode with parallel workers.\n\nDiscovers PDF files in the input directory (optionally recursively),\nprocesses them using configurable parallel workers, and supports\ncheckpoint-based resumption. Generates batch summary and optional exports.\n\nArgs:\n    args: Parsed command-line arguments containing:\n        - input_dir: Directory containing PDF files\n        - recursive: Whether to search subdirectories\n        - workers: Number of parallel processing workers\n        - batch_id: Optional batch identifier\n        - resume: Whether to resume a previous batch\n        - export: Whether to export results\n        - export_format: Format for export (json/csv)\n        - output: Optional output path\n        - report: Optional HTML report path\n        - config: Path to system configuration file\n\nReturns:\n    Exit code: 0 for success, 1 for failure.",
          "signature": {
            "parameters": [
              {
                "name": "args",
                "type": "argparse.Namespace"
              }
            ],
            "return_type": "int"
          }
        },
        {
          "name": "command_export",
          "line": 391,
          "docstring": "Export results for a previously processed drawing.\n\nSupports multiple export formats: JSON (structured data), CSV (tabular),\nand HTML report (human-readable summary).\n\nArgs:\n    args: Parsed command-line arguments containing:\n        - drawing_id: Identifier of the drawing to export\n        - format: Export format (json/csv/report)\n        - output: Optional output path (defaults to drawing_id-based name)\n        - config: Path to system configuration file\n\nReturns:\n    Exit code: 0 for success, 1 for failure.",
          "signature": {
            "parameters": [
              {
                "name": "args",
                "type": "argparse.Namespace"
              }
            ],
            "return_type": "int"
          }
        },
        {
          "name": "command_cost_report",
          "line": 419,
          "docstring": "Generate LLM cost analysis report for a date range.\n\nProduces an HTML report summarizing LLM API usage and costs. Date range\ncan be specified either as number of days from now or explicit start/end\ndates.\n\nArgs:\n    args: Parsed command-line arguments containing either:\n        - days: Number of days to look back from now, OR\n        - start_date: ISO format start date (YYYY-MM-DD)\n        - end_date: ISO format end date (YYYY-MM-DD)\n        - output: Optional output path (defaults to 'cost_report.html')\n        - config: Path to system configuration file\n\nReturns:\n    Exit code: 0 for success, 1 for failure.",
          "signature": {
            "parameters": [
              {
                "name": "args",
                "type": "argparse.Namespace"
              }
            ],
            "return_type": "int"
          }
        },
        {
          "name": "command_validate_config",
          "line": 473,
          "docstring": "Validate system configuration file for correctness and completeness.\n\nChecks all configuration sections (paths, database, models, LLM settings)\nand prints a detailed validation report with errors, warnings, and info\nmessages.\n\nArgs:\n    args: Parsed command-line arguments containing:\n        - config: Path to system configuration file to validate\n\nReturns:\n    Exit code: 0 if configuration is valid, 1 if errors found.",
          "signature": {
            "parameters": [
              {
                "name": "args",
                "type": "argparse.Namespace"
              }
            ],
            "return_type": "int"
          }
        },
        {
          "name": "command_list_drawings",
          "line": 503,
          "docstring": "Query and display processed drawings from the database.\n\nLists drawings with filtering options (status, review flag) and pagination\nsupport. Displays drawing ID, confidence score, status, and review flag\nin a formatted table.\n\nArgs:\n    args: Parsed command-line arguments containing:\n        - status: Optional status filter\n        - needs_review: Whether to show only drawings needing review\n        - limit: Maximum number of results (default: 50)\n        - offset: Result offset for pagination (default: 0)\n        - config: Path to system configuration file\n\nReturns:\n    Exit code: 0 for success, 1 for failure.",
          "signature": {
            "parameters": [
              {
                "name": "args",
                "type": "argparse.Namespace"
              }
            ],
            "return_type": "int"
          }
        },
        {
          "name": "handle_export",
          "line": 570,
          "docstring": "Handle export operations for a single drawing.\n\nArgs:\n    db: Database manager instance.\n    drawing_id: Drawing identifier.\n    export_format: Export format (json/csv/report).\n    output: Optional output path.\n\nReturns:\n    Path to exported file(s).\n\nRaises:\n    ValueError: If export format is invalid.",
          "signature": {
            "parameters": [
              {
                "name": "db",
                "type": "DatabaseManager"
              },
              {
                "name": "drawing_id",
                "type": "str"
              },
              {
                "name": "export_format",
                "type": "str"
              },
              {
                "name": "output",
                "type": "Optional[str]"
              }
            ],
            "return_type": "str"
          }
        },
        {
          "name": "handle_batch_export",
          "line": 618,
          "docstring": "Handle export operations for batch results.\n\nArgs:\n    db: Database manager instance.\n    batch_result: Batch processing result object.\n    export_format: Export format (json/csv).\n    output: Optional output path.\n    report_path: Optional HTML report path.",
          "signature": {
            "parameters": [
              {
                "name": "db",
                "type": "DatabaseManager"
              },
              {
                "name": "batch_result"
              },
              {
                "name": "export_format",
                "type": "str"
              },
              {
                "name": "output",
                "type": "Optional[str]"
              },
              {
                "name": "report_path",
                "type": "Optional[str]"
              }
            ],
            "return_type": "None"
          }
        },
        {
          "name": "setup_argument_parser",
          "line": 662,
          "docstring": "Configure the argument parser with all CLI commands and options.\n\nCreates a parser with subcommands for:\n- process: Single drawing processing\n- batch: Batch processing with parallel workers\n- export: Export drawing results\n- cost-report: Generate LLM cost reports\n- validate-config: Validate system configuration\n- list: Query processed drawings\n\nReturns:\n    Configured ArgumentParser instance ready to parse sys.argv.\n\nExample:\n    parser = setup_argument_parser()\n    args = parser.parse_args()",
          "signature": {
            "parameters": [],
            "return_type": "argparse.ArgumentParser"
          }
        },
        {
          "name": "print_batch_summary",
          "line": 889,
          "docstring": "Print formatted summary of batch processing results.\n\nArgs:\n    batch_result: Batch processing result object.",
          "signature": {
            "parameters": [
              {
                "name": "batch_result"
              }
            ],
            "return_type": "None"
          }
        },
        {
          "name": "print_result_summary",
          "line": 910,
          "docstring": "Print a formatted summary of drawing processing results to console.\n\nDisplays key metrics including drawing ID, status, confidence score,\nentity/shape counts, associations, and review flags (first 5 shown).\n\nArgs:\n    result: ProcessingResult object containing all extraction results\n        and metadata for a processed drawing.",
          "signature": {
            "parameters": [
              {
                "name": "result",
                "type": "ProcessingResult"
              }
            ],
            "return_type": "None"
          }
        }
      ]
    },
    "src.drawing_intelligence.cli": {
      "file_path": "C:\\00Projects\\engineering_items_attributes_enrichment\\src\\drawing_intelligence\\cli\\__init__.py",
      "module_docstring": "CLI interface for drawing intelligence system.",
      "classes": {},
      "functions": []
    },
    "src.drawing_intelligence.database.database_manager": {
      "file_path": "C:\\00Projects\\engineering_items_attributes_enrichment\\src\\drawing_intelligence\\database\\database_manager.py",
      "module_docstring": "Database manager for the Drawing Intelligence System.\n\nThis module provides a comprehensive database management layer for storing and\nretrieving drawing processing results, including OCR text blocks, extracted\nentities, shape detections, component hierarchies, and LLM usage tracking.\n\nThe DatabaseManager uses SQLite with Write-Ahead Logging (WAL) mode for improved\nconcurrency. Thread safety is ensured via thread-local connections.\n\nClasses:\n    DatabaseManager: Main database operations manager.\n\nTypical usage example:\n    with DatabaseManager(db_path=\"./data/drawings.db\") as db_manager:\n        drawing_id = db_manager.store_drawing(processing_result)\n        db_manager.store_entities(drawing_id, entities)",
      "classes": {
        "ProcessingStatus": {
          "line": 56,
          "docstring": "Processing status enumeration for audit and status tracking.",
          "bases": [
            "Enum"
          ],
          "methods": [],
          "nested_classes": []
        },
        "DatabaseManager": {
          "line": 66,
          "docstring": "Manages all database operations for the Drawing Intelligence System.\n\nThis class provides a comprehensive interface for storing and querying\ndrawing processing results in SQLite. It handles the complete lifecycle\nof drawing data including text blocks, entities, shape detections,\nassociations, hierarchies, and audit logs.\n\nThread Safety:\n    This implementation uses thread-local storage for SQLite connections\n    to ensure thread safety in multi-threaded batch processing scenarios.\n    Each thread maintains its own connection, eliminating race conditions\n    while maintaining the benefits of WAL mode for concurrency.\n\nContext Manager:\n    DatabaseManager implements the context manager protocol. Use it with\n    'with' statements to ensure proper cleanup:\n\n        with DatabaseManager(db_path) as db:\n            db.store_drawing(result)\n\nAttributes:\n    db_path: Path to the SQLite database file.\n    schema_path: Path to the SQL schema definition file.\n    _local: Thread-local storage for connections.\n    _lock: Threading lock for initialization operations.\n\nRaises:\n    DatabaseError: For all database operation failures.\n    FileNotFoundError: If schema file cannot be located during\n        initialization.",
          "bases": [],
          "methods": [
            {
              "name": "__init__",
              "line": 153,
              "docstring": "Initialize database manager and establish connection.\n\nCreates the database directory if it doesn't exist, establishes a\nconnection with WAL mode enabled, and initializes the schema.\n\nArgs:\n    db_path: Path to SQLite database file. Parent directories will be\n        created if they don't exist.\n    schema_path: Optional path to schema SQL file. If not provided,\n        defaults to schema.sql in the same directory as this module.\n\nRaises:\n    DatabaseError: If connection establishment fails.\n    FileNotFoundError: If schema_path is invalid.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "db_path",
                    "type": "str"
                  },
                  {
                    "name": "schema_path",
                    "type": "Optional[str]"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "__enter__",
              "line": 184,
              "docstring": "Context manager entry.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "'DatabaseManager'"
              },
              "method_type": "instance"
            },
            {
              "name": "__exit__",
              "line": 188,
              "docstring": "Context manager exit - closes connection for current thread.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "exc_type"
                  },
                  {
                    "name": "exc_val"
                  },
                  {
                    "name": "exc_tb"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "_get_connection",
              "line": 192,
              "docstring": "Get or create thread-local database connection.\n\nReturns:\n    Thread-specific SQLite connection.\n\nRaises:\n    DatabaseError: If connection cannot be established.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "sqlite3.Connection"
              },
              "method_type": "instance"
            },
            {
              "name": "_validate_connection",
              "line": 231,
              "docstring": "Validate that the connection is still alive.\n\nReturns:\n    True if connection is valid, False otherwise.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "bool"
              },
              "method_type": "instance"
            },
            {
              "name": "_transaction",
              "line": 246,
              "docstring": "Context manager for database transactions.\n\nYields:\n    sqlite3.Connection: Database connection with active transaction.\n\nRaises:\n    DatabaseError: If transaction fails.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": null
              },
              "method_type": "instance"
            },
            {
              "name": "transaction",
              "line": 265,
              "docstring": "Public transaction context manager for multi-step operations.\n\nYields:\n    sqlite3.Connection: Database connection with active transaction.\n\nExample:\n    with db_manager.transaction():\n        db_manager.store_drawing(result)\n        db_manager.store_entities(drawing_id, entities)",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": null
              },
              "method_type": "instance"
            },
            {
              "name": "_serialize_hierarchy",
              "line": 280,
              "docstring": "Serialize component hierarchy to JSON.\n\nArgs:\n    hierarchy: ComponentHierarchy object or None.\n\nReturns:\n    JSON string representation or None if hierarchy is None.\n\nRaises:\n    DatabaseError: If serialization fails.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "hierarchy",
                    "type": "Optional[ComponentHierarchy]"
                  }
                ],
                "return_type": "Optional[str]"
              },
              "method_type": "instance"
            },
            {
              "name": "_serialize_normalized_value",
              "line": 305,
              "docstring": "Serialize normalized value dictionary to JSON.\n\nArgs:\n    value: Normalized value dictionary.\n\nReturns:\n    JSON string representation.\n\nRaises:\n    DatabaseError: If serialization fails.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "value",
                    "type": "Dict[str, Any]"
                  }
                ],
                "return_type": "str"
              },
              "method_type": "instance"
            },
            {
              "name": "_batch_execute",
              "line": 326,
              "docstring": "Execute batch insert in chunks to prevent memory issues.\n\nArgs:\n    cursor: Database cursor.\n    query: SQL INSERT query.\n    data: List of tuples containing row data.\n    batch_size: Number of rows per batch (default: 5000).",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "cursor",
                    "type": "sqlite3.Cursor"
                  },
                  {
                    "name": "query",
                    "type": "str"
                  },
                  {
                    "name": "data",
                    "type": "List[Tuple[Any, ...]]"
                  },
                  {
                    "name": "batch_size",
                    "type": "int"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "initialize_database",
              "line": 346,
              "docstring": "Create database tables and indexes from schema file.\n\nReads and executes the SQL schema file to create all required tables,\nindexes, and constraints. This operation is idempotent - it can be\nsafely called multiple times as the schema uses CREATE TABLE IF NOT\nEXISTS.\n\nRaises:\n    DatabaseError: If schema execution fails.\n    FileNotFoundError: If schema file doesn't exist.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "store_drawing",
              "line": 381,
              "docstring": "Store complete drawing processing result in database.\n\nInserts the main drawing record with metadata, confidence scores, and\nserialized component hierarchy. This method should be called before\nstoring related entities, text blocks, or detections.\n\nArgs:\n    processing_result: Complete ProcessingResult object containing all\n        drawing metadata, confidence scores, and hierarchy.\n\nReturns:\n    The drawing_id that was stored.\n\nRaises:\n    DatabaseError: If insertion fails or drawing_id already exists.\n    ValueError: If required fields are missing or invalid.\n\nNote:\n    The component_hierarchy is serialized to JSON using\n    dataclasses.asdict(). Ensure all nested objects are\n    JSON-serializable.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "processing_result",
                    "type": "ProcessingResult"
                  }
                ],
                "return_type": "str"
              },
              "method_type": "instance"
            },
            {
              "name": "store_text_blocks",
              "line": 457,
              "docstring": "Store OCR text blocks for a drawing.\n\nInserts all text blocks extracted during OCR processing, including\ncontent, bounding boxes, confidence scores, and region types.\n\nArgs:\n    drawing_id: Drawing identifier (must exist in drawings table).\n    text_blocks: List of TextBlock objects from OCR pipeline.\n\nRaises:\n    DatabaseError: If insertion fails or drawing_id doesn't exist.\n\nNote:\n    Uses executemany() with chunking for optimized batch insertion.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "drawing_id",
                    "type": "str"
                  },
                  {
                    "name": "text_blocks",
                    "type": "List[TextBlock]"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "store_entities",
              "line": 509,
              "docstring": "Store extracted entities for a drawing.\n\nInserts all entities (part numbers, dimensions, materials, etc.)\nextracted from the drawing, including normalized values and confidence\nscores.\n\nArgs:\n    drawing_id: Drawing identifier (must exist in drawings table).\n    entities: List of Entity objects from entity extraction pipeline.\n\nRaises:\n    DatabaseError: If insertion fails or drawing_id doesn't exist.\n\nNote:\n    The normalized_value dict is serialized to JSON. Entity types are\n    stored as strings (enum values if available, otherwise raw strings).",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "drawing_id",
                    "type": "str"
                  },
                  {
                    "name": "entities",
                    "type": "List[Entity]"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "store_detections",
              "line": 566,
              "docstring": "Store shape detections for a drawing.\n\nInserts all shape/component detections from the YOLOv8 model, including\nclass names, bounding boxes, and confidence scores.\n\nArgs:\n    drawing_id: Drawing identifier (must exist in drawings table).\n    detections: List of Detection objects from shape detection pipeline.\n\nRaises:\n    DatabaseError: If insertion fails or drawing_id doesn't exist.\n\nNote:\n    Only pixel-based bounding boxes are stored (normalized boxes are\n    computed on-the-fly when needed). Model version defaults to\n    \"unknown\" if not provided in Detection object.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "drawing_id",
                    "type": "str"
                  },
                  {
                    "name": "detections",
                    "type": "List[Detection]"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "store_associations",
              "line": 619,
              "docstring": "Store text-shape associations for a drawing.\n\nInserts associations between text blocks and detected shapes, capturing\nrelationships like dimensions, labels, and notes.\n\nArgs:\n    drawing_id: Drawing identifier (must exist in drawings table).\n    associations: List of Association objects from data association\n        pipeline.\n\nRaises:\n    DatabaseError: If insertion fails or foreign key constraints are\n        violated.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "drawing_id",
                    "type": "str"
                  },
                  {
                    "name": "associations",
                    "type": "List[Association]"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "store_hierarchy",
              "line": 670,
              "docstring": "Store component hierarchy for a drawing.\n\nUpdates the drawings table with a serialized component hierarchy,\nreplacing any existing hierarchy for this drawing.\n\nArgs:\n    drawing_id: Drawing identifier (must exist in drawings table).\n    hierarchy: ComponentHierarchy object representing assembly structure.\n\nRaises:\n    DatabaseError: If update fails or drawing_id doesn't exist.\n\nNote:\n    The hierarchy is serialized to JSON using dataclasses.asdict(). This\n    operation replaces (not appends to) any existing hierarchy.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "drawing_id",
                    "type": "str"
                  },
                  {
                    "name": "hierarchy",
                    "type": "ComponentHierarchy"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "store_llm_usage",
              "line": 711,
              "docstring": "Store LLM API usage record for cost tracking.\n\nRecords all commercial LLM API calls with token counts and costs for\nbudget monitoring and cost attribution.\n\nArgs:\n    drawing_id: Drawing identifier (must exist in drawings table).\n    provider: LLM provider name (e.g., \"openai\", \"anthropic\").\n    model: Model identifier (e.g., \"gpt-4o-2024-08-06\").\n    tokens: TokenUsage object with input/output token counts.\n    cost: Cost in USD for this API call.\n    use_case: Use case type (e.g., \"ocr_verification\",\n        \"entity_extraction\").\n\nRaises:\n    DatabaseError: If insertion fails.\n\nNote:\n    Generates a unique usage_id with \"LLM\" prefix. Timestamp is set to\n    current time in ISO format with UTC timezone.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "drawing_id",
                    "type": "str"
                  },
                  {
                    "name": "provider",
                    "type": "str"
                  },
                  {
                    "name": "model",
                    "type": "str"
                  },
                  {
                    "name": "tokens",
                    "type": "TokenUsage"
                  },
                  {
                    "name": "cost",
                    "type": "float"
                  },
                  {
                    "name": "use_case",
                    "type": "str"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "store_audit_entry",
              "line": 767,
              "docstring": "Store processing audit entry for pipeline tracking.\n\nRecords the execution of each pipeline stage with status, duration, and\nerror details for debugging and performance monitoring.\n\nArgs:\n    drawing_id: Drawing identifier.\n    stage: Processing stage name (e.g., \"pdf_processing\",\n        \"ocr_extraction\").\n    status: Status code (use ProcessingStatus enum values).\n    duration: Execution duration in seconds.\n    error_message: Optional error message if status is \"failed\".\n\nNote:\n    This method does NOT raise exceptions on failure - it only logs\n    errors. This prevents audit logging failures from disrupting the\n    main pipeline.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "drawing_id",
                    "type": "str"
                  },
                  {
                    "name": "stage",
                    "type": "str"
                  },
                  {
                    "name": "status",
                    "type": "str"
                  },
                  {
                    "name": "duration",
                    "type": "float"
                  },
                  {
                    "name": "error_message",
                    "type": "Optional[str]"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "get_drawing_by_id",
              "line": 817,
              "docstring": "Retrieve drawing record by identifier.\n\nArgs:\n    drawing_id: Drawing identifier to look up.\n\nReturns:\n    Dictionary containing all drawing table columns, or None if not\n    found.\n\nRaises:\n    DatabaseError: If query execution fails.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "drawing_id",
                    "type": "str"
                  }
                ],
                "return_type": "Optional[Dict[str, Any]]"
              },
              "method_type": "instance"
            },
            {
              "name": "query_drawings",
              "line": 851,
              "docstring": "Query drawings with flexible filtering and pagination.\n\nSupports filtering by status, confidence range, review flag, and date\nrange, with built-in pagination support.\n\nArgs:\n    filters: QueryFilter object specifying filter criteria, ordering,\n        and pagination parameters.\n\nReturns:\n    List of drawing records (as dicts) matching filter criteria, ordered\n    by processing_timestamp descending.\n\nRaises:\n    DatabaseError: If query execution fails.\n    ValueError: If filter parameters are invalid.\n\nNote:\n    Results are always ordered by processing_timestamp DESC. Pagination\n    is controlled via filters.limit and filters.offset.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "filters",
                    "type": "QueryFilter"
                  }
                ],
                "return_type": "List[Dict[str, Any]]"
              },
              "method_type": "instance"
            },
            {
              "name": "query_drawings_count",
              "line": 928,
              "docstring": "Get total count of drawings matching filters (for pagination).\n\nArgs:\n    filters: QueryFilter object specifying filter criteria.\n\nReturns:\n    Total count of matching drawings.\n\nRaises:\n    DatabaseError: If query execution fails.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "filters",
                    "type": "QueryFilter"
                  }
                ],
                "return_type": "int"
              },
              "method_type": "instance"
            },
            {
              "name": "get_drawings_for_review",
              "line": 982,
              "docstring": "Get drawings flagged for manual review.\n\nRetrieves drawings where needs_review=True, ordered by most recent\nfirst.\n\nArgs:\n    limit: Maximum number of drawings to return (default: 50).\n\nReturns:\n    List of drawing records needing review.\n\nRaises:\n    DatabaseError: If query execution fails.\n    ValueError: If limit is negative.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "limit",
                    "type": "int"
                  }
                ],
                "return_type": "List[Dict[str, Any]]"
              },
              "method_type": "instance"
            },
            {
              "name": "update_drawing_status",
              "line": 1023,
              "docstring": "Update drawing processing status.\n\nArgs:\n    drawing_id: Drawing identifier to update.\n    status: New status value (recommend using ProcessingStatus enum\n        values: \"completed\", \"failed\", \"in_progress\", etc.).\n\nRaises:\n    DatabaseError: If update fails.\n\nNote:\n    This method does not validate status values. Consider using\n    ProcessingStatus enum for type safety.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "drawing_id",
                    "type": "str"
                  },
                  {
                    "name": "status",
                    "type": "str"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "delete_drawing",
              "line": 1054,
              "docstring": "Delete drawing and all related data via cascade.\n\nRemoves the drawing record and all foreign key related records\n(entities, text blocks, detections, associations, audit entries,\nLLM usage).\n\nArgs:\n    drawing_id: Drawing identifier to delete.\n\nRaises:\n    DatabaseError: If deletion fails.\n\nWarning:\n    This operation is irreversible and cascades to all related tables.\n    Consider implementing soft deletes for production use.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "drawing_id",
                    "type": "str"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "get_llm_usage",
              "line": 1090,
              "docstring": "Get LLM usage records for a date range.\n\nRetrieves all LLM API call records between start_date and end_date for\ncost reporting and budget analysis.\n\nArgs:\n    start_date: Start of date range (inclusive).\n    end_date: End of date range (inclusive).\n\nReturns:\n    List of LLM usage records ordered by timestamp descending.\n\nRaises:\n    DatabaseError: If query execution fails.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "start_date",
                    "type": "datetime"
                  },
                  {
                    "name": "end_date",
                    "type": "datetime"
                  }
                ],
                "return_type": "List[Dict[str, Any]]"
              },
              "method_type": "instance"
            },
            {
              "name": "get_database_stats",
              "line": 1129,
              "docstring": "Get comprehensive database statistics.\n\nComputes aggregate statistics including counts, costs, and date ranges\nfor monitoring and reporting.\n\nReturns:\n    Dictionary containing:\n        - total_drawings: Total number of drawings processed\n        - drawings_needs_review: Count of drawings flagged for review\n        - total_entities: Total entities extracted across all drawings\n        - total_detections: Total shape detections across all drawings\n        - total_llm_calls: Total LLM API calls made\n        - total_llm_cost: Total LLM cost in USD\n        - database_size_mb: Database file size in megabytes\n        - oldest_drawing: Timestamp of oldest drawing (or None)\n        - newest_drawing: Timestamp of newest drawing (or None)\n\nRaises:\n    DatabaseError: If any statistics query fails.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "Dict[str, Any]"
              },
              "method_type": "instance"
            },
            {
              "name": "backup_database",
              "line": 1203,
              "docstring": "Create a consistent backup using SQLite's backup API.\n\nUses the SQLite backup API to create a consistent snapshot of the\ndatabase, even during active writes. This is safer than file copying.\n\nArgs:\n    backup_path: Destination path for backup file.\n\nReturns:\n    True if backup succeeded, False otherwise.\n\nNote:\n    This method uses SQLite's backup API which ensures consistency\n    during concurrent writes. The backup is performed page-by-page.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "backup_path",
                    "type": "str"
                  }
                ],
                "return_type": "bool"
              },
              "method_type": "instance"
            },
            {
              "name": "close",
              "line": 1242,
              "docstring": "Close the database connection for the current thread.\n\nShould be called when the DatabaseManager is no longer needed to release\nresources. After calling close(), no further database operations can be\nperformed without reconnecting (which happens automatically on next\noperation).",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "close_all",
              "line": 1256,
              "docstring": "Close all database connections across all threads.\n\nThis method should be called during application shutdown to ensure\nall connections are properly closed. Note that it can only close\nconnections from the current thread - connections in other threads\nmust be closed by those threads.\n\nWarning:\n    This is a best-effort cleanup. Thread-local connections in other\n    threads cannot be accessed from here.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        }
      },
      "functions": []
    },
    "src.drawing_intelligence.database.query_filters": {
      "file_path": "C:\\00Projects\\engineering_items_attributes_enrichment\\src\\drawing_intelligence\\database\\query_filters.py",
      "module_docstring": "Query filters for database queries.\n\nThis module provides filtering capabilities for querying engineering drawing\nrecords from the database with support for status, confidence scores, dates,\nsorting, and pagination.",
      "classes": {
        "DrawingStatus": {
          "line": 15,
          "docstring": "Valid processing status values for engineering drawings.",
          "bases": [
            "str",
            "Enum"
          ],
          "methods": [],
          "nested_classes": []
        },
        "SortOrder": {
          "line": 23,
          "docstring": "Valid sort order values for query results.",
          "bases": [
            "str",
            "Enum"
          ],
          "methods": [],
          "nested_classes": []
        },
        "QueryFilters": {
          "line": 31,
          "docstring": "Filters for querying engineering drawing records.\n\nThis class encapsulates all filter criteria that can be applied when\nquerying the drawing database. It includes validation logic to ensure\nfilter values are within acceptable ranges and provides utility methods\nfor pagination and filter manipulation.\n\nAttributes:\n    status: Filter by processing status. None returns drawings with any status.\n    needs_review: Filter by review flag. True returns only drawings\n        requiring human review, False returns only drawings not requiring\n        review, None returns all.\n    min_confidence: Minimum overall confidence score (0.0-1.0). Only\n        drawings with confidence >= this value are returned.\n    max_confidence: Maximum overall confidence score (0.0-1.0). Only\n        drawings with confidence <= this value are returned.\n    has_part_number: Filter for drawings with part numbers. True returns\n        only drawings with part numbers, False returns only drawings\n        without, None returns all.\n    date_from: Start date (inclusive) for filtering by processing timestamp.\n        Only drawings processed on or after this date are returned.\n    date_to: End date (inclusive) for filtering by processing timestamp.\n        Only drawings processed on or before this date are returned.\n    sort_by: Column name to sort by (e.g., 'processing_timestamp', 'confidence').\n    sort_order: Sort direction (ascending or descending).\n    limit: Maximum number of results to return. Defaults to 100. Maximum is 1000.\n    offset: Number of results to skip for pagination. Defaults to 0.\n\nRaises:\n    ValueError: If validation fails for any filter value.\n\nExamples:\n    >>> # Filter for high-confidence drawings needing review\n    >>> filters = QueryFilters(\n    ...     needs_review=True,\n    ...     min_confidence=0.8,\n    ...     limit=50\n    ... )\n\n    >>> # Filter by date range with sorting\n    >>> filters = QueryFilters(\n    ...     date_from=datetime(2025, 1, 1),\n    ...     date_to=datetime(2025, 1, 31),\n    ...     status=DrawingStatus.COMPLETE,\n    ...     sort_by='processing_timestamp',\n    ...     sort_order=SortOrder.DESC\n    ... )\n\n    >>> # Pagination example\n    >>> first_page = QueryFilters(limit=50)\n    >>> second_page = first_page.next_page()\n    >>> print(second_page.page_number)  # 2",
          "bases": [],
          "methods": [
            {
              "name": "__post_init__",
              "line": 107,
              "docstring": "Validate filter values after initialization.\n\nPerforms comprehensive validation of all filter parameters to ensure\nthey are within acceptable ranges and logically consistent.\n\nRaises:\n    ValueError: If any validation check fails with a descriptive\n        message indicating which parameter is invalid and why.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "_validate_status",
              "line": 123,
              "docstring": "Validate status field.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "_validate_confidence_scores",
              "line": 136,
              "docstring": "Validate confidence score bounds and consistency.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "_validate_date_range",
              "line": 162,
              "docstring": "Validate date range consistency and timezone handling.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "_validate_pagination",
              "line": 179,
              "docstring": "Validate pagination parameters.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "_validate_sorting",
              "line": 193,
              "docstring": "Validate sorting parameters.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "has_confidence_filter",
              "line": 217,
              "docstring": "Check if any confidence filtering is applied.\n\nReturns:\n    True if min_confidence or max_confidence is set, False otherwise.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "bool"
              },
              "method_type": "instance"
            },
            {
              "name": "has_date_filter",
              "line": 225,
              "docstring": "Check if any date filtering is applied.\n\nReturns:\n    True if date_from or date_to is set, False otherwise.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "bool"
              },
              "method_type": "instance"
            },
            {
              "name": "is_empty",
              "line": 233,
              "docstring": "Check if any non-pagination filters are active.\n\nReturns:\n    True if no filters (excluding limit/offset) are set, False otherwise.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "bool"
              },
              "method_type": "instance"
            },
            {
              "name": "to_query_params",
              "line": 250,
              "docstring": "Export active filters as a dictionary.\n\nReturns only non-None filter values, useful for logging, serialization,\nor passing to query builders.\n\nReturns:\n    Dictionary containing only the active filter parameters.\n\nExample:\n    >>> filters = QueryFilters(min_confidence=0.8, limit=50)\n    >>> filters.to_query_params()\n    {'min_confidence': 0.8, 'limit': 50, 'offset': 0}",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "Dict[str, Any]"
              },
              "method_type": "instance"
            },
            {
              "name": "page_number",
              "line": 292,
              "docstring": "Calculate the current 1-based page number.\n\nReturns:\n    Current page number (1-indexed). Returns 1 if limit is 0.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "int"
              },
              "method_type": "instance"
            },
            {
              "name": "next_page",
              "line": 302,
              "docstring": "Create a new filter instance representing the next page.\n\nReturns:\n    New QueryFilters instance with offset incremented by limit.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "'QueryFilters'"
              },
              "method_type": "instance"
            },
            {
              "name": "previous_page",
              "line": 310,
              "docstring": "Create a new filter instance representing the previous page.\n\nReturns:\n    New QueryFilters instance with offset decremented by limit.\n    Offset will not go below 0.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "'QueryFilters'"
              },
              "method_type": "instance"
            },
            {
              "name": "reset_pagination",
              "line": 320,
              "docstring": "Create a new filter instance with pagination reset to defaults.\n\nReturns:\n    New QueryFilters instance with limit=100 and offset=0.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "'QueryFilters'"
              },
              "method_type": "instance"
            },
            {
              "name": "copy_with",
              "line": 328,
              "docstring": "Create a modified copy of this filter instance.\n\nUses dataclasses.replace to create a new instance with specified\nattributes changed while preserving all other values.\n\nArgs:\n    **kwargs: Attribute names and new values to apply.\n\nReturns:\n    New QueryFilters instance with modifications applied.\n\nExample:\n    >>> original = QueryFilters(limit=50)\n    >>> modified = original.copy_with(limit=100, offset=50)",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "'QueryFilters'"
              },
              "method_type": "instance"
            },
            {
              "name": "merge",
              "line": 346,
              "docstring": "Merge with another filter instance, giving precedence to other.\n\nCreates a new filter where non-None values from 'other' override\nvalues from self. Useful for applying default filters with overrides.\n\nArgs:\n    other: QueryFilters instance whose values take precedence.\n\nReturns:\n    New QueryFilters instance with merged values.\n\nExample:\n    >>> defaults = QueryFilters(limit=100, sort_by='processing_timestamp')\n    >>> overrides = QueryFilters(limit=50)\n    >>> merged = defaults.merge(overrides)\n    >>> merged.limit  # 50\n    >>> merged.sort_by  # 'processing_timestamp'",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "other",
                    "type": "'QueryFilters'"
                  }
                ],
                "return_type": "'QueryFilters'"
              },
              "method_type": "instance"
            },
            {
              "name": "__str__",
              "line": 379,
              "docstring": "Return human-readable string representation of active filters.\n\nReturns:\n    Concise string showing only non-default filter values.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "str"
              },
              "method_type": "instance"
            },
            {
              "name": "__repr__",
              "line": 410,
              "docstring": "Return detailed string representation for debugging.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "str"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        }
      },
      "functions": []
    },
    "src.drawing_intelligence.database": {
      "file_path": "C:\\00Projects\\engineering_items_attributes_enrichment\\src\\drawing_intelligence\\database\\__init__.py",
      "module_docstring": "Database layer for drawing intelligence system.",
      "classes": {},
      "functions": []
    },
    "src.drawing_intelligence.export.csv_exporter": {
      "file_path": "C:\\00Projects\\engineering_items_attributes_enrichment\\src\\drawing_intelligence\\export\\csv_exporter.py",
      "module_docstring": "CSV Exporter Module.\n\nThis module provides functionality to export drawing processing results\nto CSV format with multiple export modes (summary, entities, detections,\nassociations).\n\nClasses:\n    CSVExporter: Handles CSV export operations for drawing records.\n\nExceptions:\n    CSVExportError: Base exception for CSV export operations.\n    InvalidDelimiterError: Raised when delimiter is invalid.\n    EmptyDataError: Raised when no data is available for export.\n    FileWriteError: Raised when file write operation fails.",
      "classes": {
        "CSVExportError": {
          "line": 103,
          "docstring": "Base exception for CSV export operations.",
          "bases": [
            "Exception"
          ],
          "methods": [],
          "nested_classes": []
        },
        "InvalidDelimiterError": {
          "line": 109,
          "docstring": "Raised when CSV delimiter is invalid.",
          "bases": [
            "CSVExportError"
          ],
          "methods": [],
          "nested_classes": []
        },
        "EmptyDataError": {
          "line": 115,
          "docstring": "Raised when no data is available for export.",
          "bases": [
            "CSVExportError"
          ],
          "methods": [],
          "nested_classes": []
        },
        "FileWriteError": {
          "line": 121,
          "docstring": "Raised when file write operation fails.",
          "bases": [
            "CSVExportError"
          ],
          "methods": [],
          "nested_classes": []
        },
        "CSVConfigProtocol": {
          "line": 132,
          "docstring": "Protocol defining required CSV configuration attributes.",
          "bases": [
            "Protocol"
          ],
          "methods": [],
          "nested_classes": []
        },
        "CSVExporter": {
          "line": 146,
          "docstring": "Export drawing results to CSV format.\n\nThis class provides multiple export methods to generate CSV files\nfrom drawing processing results, including summary reports and\ndetailed entity/detection/association exports. All exports use\nstreaming generators to minimize memory usage.\n\nAttributes:\n    config: Export configuration object with CSV settings.\n    delimiter: CSV field delimiter character (validated).\n    float_precision: Number of decimal places for float formatting.\n    datetime_format: strftime format string for datetime fields.\n    encoding: Output file encoding.\n\nExample:\n    >>> from drawing_intelligence.export.csv_exporter import CSVExporter\n    >>> exporter = CSVExporter(config)\n    >>> output_path = exporter.export_summary(records, \"output/summary.csv\")",
          "bases": [],
          "methods": [
            {
              "name": "__init__",
              "line": 167,
              "docstring": "Initialize CSV exporter with configuration.\n\nArgs:\n    config: Export configuration object implementing CSVConfigProtocol.\n        Must have: csv_delimiter, float_precision, datetime_format,\n        encoding attributes.\n    progress_callback: Optional callback function(current, total) for\n        progress tracking during large exports.\n\nRaises:\n    InvalidDelimiterError: If delimiter is invalid (length != 1,\n        newline, or other reserved character).",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "config",
                    "type": "CSVConfigProtocol"
                  },
                  {
                    "name": "progress_callback",
                    "type": "Optional[Callable[[int, int], None]]"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "export_summary",
              "line": 212,
              "docstring": "Export summary CSV with one row per drawing.\n\nCreates a CSV file containing high-level statistics for each\ndrawing including confidence scores, entity counts, and review flags.\n\nArgs:\n    drawing_records: List of DrawingRecord objects to export.\n    output_path: Destination file path for the CSV output.\n\nReturns:\n    Path object of the created CSV file.\n\nRaises:\n    EmptyDataError: If drawing_records is empty.\n    FileWriteError: If file write operation fails.\n\nExample:\n    >>> path = exporter.export_summary(records, \"summary.csv\")",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "drawing_records",
                    "type": "List[DrawingRecord]"
                  },
                  {
                    "name": "output_path",
                    "type": "Union[str, Path]"
                  }
                ],
                "return_type": "Path"
              },
              "method_type": "instance"
            },
            {
              "name": "export_entities",
              "line": 257,
              "docstring": "Export entities CSV with one row per entity.\n\nFlattens all entities across drawings into a detailed CSV format,\nincluding bounding box coordinates and extraction metadata.\n\nArgs:\n    drawing_records: List of DrawingRecord objects containing\n        entities.\n    output_path: Destination file path for the CSV output.\n\nReturns:\n    Path object of the created CSV file.\n\nRaises:\n    EmptyDataError: If no entities found in any drawing.\n    FileWriteError: If file write operation fails.\n\nNote:\n    Drawings without entities will be skipped automatically.\n    Entities without bounding boxes will have empty bbox fields.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "drawing_records",
                    "type": "List[DrawingRecord]"
                  },
                  {
                    "name": "output_path",
                    "type": "Union[str, Path]"
                  }
                ],
                "return_type": "Path"
              },
              "method_type": "instance"
            },
            {
              "name": "export_detections",
              "line": 319,
              "docstring": "Export detections CSV with one row per shape detection.\n\nExports all shape detections with both pixel-based and normalized\nbounding box coordinates.\n\nArgs:\n    drawing_records: List of DrawingRecord objects with detections.\n    output_path: Destination file path for the CSV output.\n\nReturns:\n    Path object of the created CSV file.\n\nRaises:\n    EmptyDataError: If no detections found in any drawing.\n    FileWriteError: If file write operation fails.\n\nNote:\n    Includes both absolute and normalized bounding box coordinates.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "drawing_records",
                    "type": "List[DrawingRecord]"
                  },
                  {
                    "name": "output_path",
                    "type": "Union[str, Path]"
                  }
                ],
                "return_type": "Path"
              },
              "method_type": "instance"
            },
            {
              "name": "export_associations",
              "line": 382,
              "docstring": "Export associations CSV linking text and shapes.\n\nCreates a CSV file mapping relationships between text blocks\nand detected shapes, including relationship types and spatial\ndistances.\n\nArgs:\n    drawing_records: List of DrawingRecord objects with\n        associations.\n    output_path: Destination file path for the CSV output.\n\nReturns:\n    Path object of the created CSV file.\n\nRaises:\n    EmptyDataError: If no associations found in any drawing.\n    FileWriteError: If file write operation fails.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "drawing_records",
                    "type": "List[DrawingRecord]"
                  },
                  {
                    "name": "output_path",
                    "type": "Union[str, Path]"
                  }
                ],
                "return_type": "Path"
              },
              "method_type": "instance"
            },
            {
              "name": "export_to_string",
              "line": 431,
              "docstring": "Export drawing records to CSV string (for APIs/testing).\n\nArgs:\n    drawing_records: List of DrawingRecord objects to export.\n    export_type: Type of export ('summary', 'entities', 'detections',\n        'associations').\n\nReturns:\n    CSV content as string.\n\nRaises:\n    ValueError: If export_type is invalid.\n    EmptyDataError: If no data available for export.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "drawing_records",
                    "type": "List[DrawingRecord]"
                  },
                  {
                    "name": "export_type",
                    "type": "str"
                  }
                ],
                "return_type": "str"
              },
              "method_type": "instance"
            },
            {
              "name": "flatten_drawing_data",
              "line": 508,
              "docstring": "Flatten drawing record to single-level dictionary.\n\nConverts a DrawingRecord object into a flat dictionary suitable\nfor CSV export, computing derived fields like entity counts and\nflags.\n\nArgs:\n    drawing_record: DrawingRecord object to flatten.\n\nReturns:\n    Dictionary with string keys and primitive values suitable for\n    CSV. Includes fields defined in SUMMARY_HEADERS.\n\nNote:\n    Converts datetime objects using configured format.\n    None values are converted to empty strings.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "drawing_record",
                    "type": "DrawingRecord"
                  }
                ],
                "return_type": "Dict[str, Any]"
              },
              "method_type": "instance"
            },
            {
              "name": "_export_detail_rows",
              "line": 567,
              "docstring": "Generic method to export detail rows using streaming.\n\nArgs:\n    drawing_records: List of DrawingRecord objects.\n    output_path: Destination file path.\n    headers: CSV column headers.\n    row_extractor: Function that yields rows from a record.\n    export_type: Name of export type for logging.\n\nReturns:\n    Path object of the created CSV file.\n\nRaises:\n    EmptyDataError: If no rows generated.\n    FileWriteError: If file write operation fails.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "drawing_records",
                    "type": "List[DrawingRecord]"
                  },
                  {
                    "name": "output_path",
                    "type": "Union[str, Path]"
                  },
                  {
                    "name": "headers",
                    "type": "List[str]"
                  },
                  {
                    "name": "row_extractor",
                    "type": "Callable[[DrawingRecord], Generator[Dict[str, Any], None, None]]"
                  },
                  {
                    "name": "export_type",
                    "type": "str"
                  }
                ],
                "return_type": "Path"
              },
              "method_type": "instance"
            },
            {
              "name": "_write_csv_atomic",
              "line": 628,
              "docstring": "Write CSV file atomically using temp file + rename.\n\nInternal method that handles the actual CSV file writing operation\nwith atomic write guarantee to prevent corruption.\n\nArgs:\n    data_generator: Generator yielding dictionaries to write as rows.\n    output_path: Destination file path for the CSV output.\n    headers: Ordered list of column headers.\n    expected_rows: Expected number of rows (for logging), or None.\n\nReturns:\n    Path object of the created CSV file.\n\nRaises:\n    FileWriteError: If file write operation fails.\n\nNote:\n    Uses atomic write pattern (temp file + rename) to prevent\n    partial file corruption on failure.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "data_generator",
                    "type": "Generator[Dict[str, Any], None, None]"
                  },
                  {
                    "name": "output_path",
                    "type": "Union[str, Path]"
                  },
                  {
                    "name": "headers",
                    "type": "List[str]"
                  },
                  {
                    "name": "expected_rows",
                    "type": "Optional[int]"
                  }
                ],
                "return_type": "Path"
              },
              "method_type": "instance"
            },
            {
              "name": "_format_float",
              "line": 721,
              "docstring": "Format float value with configured precision.\n\nArgs:\n    value: Float value to format.\n\nReturns:\n    Formatted string representation.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "value",
                    "type": "float"
                  }
                ],
                "return_type": "str"
              },
              "method_type": "instance"
            },
            {
              "name": "_sanitize_value",
              "line": 734,
              "docstring": "Sanitize value for CSV output to prevent injection attacks.\n\nArgs:\n    value: Value to sanitize.\n\nReturns:\n    Sanitized string value safe for CSV.\n\nNote:\n    Prepends single quote to values starting with formula characters\n    (=, +, -, @, tab, carriage return) to prevent CSV injection.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "value",
                    "type": "Any"
                  }
                ],
                "return_type": "str"
              },
              "method_type": "instance"
            },
            {
              "name": "_get_entity_rows",
              "line": 759,
              "docstring": "Get entity rows for a record (helper for export_to_string).",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "record",
                    "type": "DrawingRecord"
                  }
                ],
                "return_type": "Generator[Dict[str, Any], None, None]"
              },
              "method_type": "instance"
            },
            {
              "name": "_get_detection_rows",
              "line": 787,
              "docstring": "Get detection rows for a record (helper for export_to_string).",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "record",
                    "type": "DrawingRecord"
                  }
                ],
                "return_type": "Generator[Dict[str, Any], None, None]"
              },
              "method_type": "instance"
            },
            {
              "name": "_get_association_rows",
              "line": 817,
              "docstring": "Get association rows for a record (helper for export_to_string).",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "record",
                    "type": "DrawingRecord"
                  }
                ],
                "return_type": "Generator[Dict[str, Any], None, None]"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        }
      },
      "functions": []
    },
    "src.drawing_intelligence.export.export_manager": {
      "file_path": "C:\\00Projects\\engineering_items_attributes_enrichment\\src\\drawing_intelligence\\export\\export_manager.py",
      "module_docstring": "Export Manager Module\n\nManages all export operations for drawing intelligence results, coordinating\nJSON, CSV, and report generation through specialized exporter classes.\n\nThis module provides a unified interface for exporting processing results in\nmultiple formats, including single drawing exports, batch exports, and various\nreport types (drawing, batch, cost).\n\nClasses:\n    JSONFormat: Enum for JSON formatting options.\n    ReportFormat: Enum for report output formats.\n    ExportConfig: Configuration for export operations.\n    ExportManager: Coordinates all export operations.\n\nExceptions:\n    ExportError: Base exception for export operations.\n    DrawingNotFoundError: Raised when a drawing is not found in database.\n    ExportFileError: Raised when file write operations fail.\n    InvalidConfigError: Raised when export configuration is invalid.\n\nExample:\n    >>> from drawing_intelligence.database import DatabaseManager\n    >>> from drawing_intelligence.export import ExportManager, ExportConfig, JSONFormat\n    >>>\n    >>> db = DatabaseManager(\"drawings.db\")\n    >>> config = ExportConfig(json_format=JSONFormat.PRETTY)\n    >>> exporter = ExportManager(db, config)\n    >>>\n    >>> # Export single drawing to JSON\n    >>> exporter.export_drawing_json(\"DWG-001\", \"output/drawing.json\")\n    >>>\n    >>> # Export batch to CSV\n    >>> drawing_ids = [\"DWG-001\", \"DWG-002\", \"DWG-003\"]\n    >>> exporter.export_batch_csv(drawing_ids, \"output/batch/\")",
      "classes": {
        "JSONFormat": {
          "line": 62,
          "docstring": "JSON formatting options.",
          "bases": [
            "Enum"
          ],
          "methods": [],
          "nested_classes": []
        },
        "ReportFormat": {
          "line": 69,
          "docstring": "Report output format options.",
          "bases": [
            "Enum"
          ],
          "methods": [],
          "nested_classes": []
        },
        "ExportError": {
          "line": 81,
          "docstring": "Base exception for export operations.",
          "bases": [
            "Exception"
          ],
          "methods": [],
          "nested_classes": []
        },
        "DrawingNotFoundError": {
          "line": 87,
          "docstring": "Raised when a drawing is not found in the database.",
          "bases": [
            "ExportError"
          ],
          "methods": [
            {
              "name": "__init__",
              "line": 90,
              "docstring": null,
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "drawing_id",
                    "type": "str"
                  }
                ],
                "return_type": null
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        },
        "ExportFileError": {
          "line": 95,
          "docstring": "Raised when file write operations fail.",
          "bases": [
            "ExportError"
          ],
          "methods": [
            {
              "name": "__init__",
              "line": 98,
              "docstring": null,
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "path",
                    "type": "Path"
                  },
                  {
                    "name": "message",
                    "type": "str"
                  },
                  {
                    "name": "original_error",
                    "type": "Exception"
                  }
                ],
                "return_type": null
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        },
        "InvalidConfigError": {
          "line": 104,
          "docstring": "Raised when export configuration is invalid.",
          "bases": [
            "ExportError"
          ],
          "methods": [],
          "nested_classes": []
        },
        "ExportConfig": {
          "line": 116,
          "docstring": "Configuration for export operations.\n\nAttributes:\n    json_format: JSON formatting style (PRETTY or COMPACT).\n    csv_delimiter: Delimiter character for CSV files.\n    include_intermediate_results: Whether to include OCR/detection intermediates.\n    include_images: Whether to include image data in exports.\n\nRaises:\n    InvalidConfigError: If configuration is invalid.",
          "bases": [],
          "methods": [
            {
              "name": "__post_init__",
              "line": 134,
              "docstring": "Validate configuration.\n\nRaises:\n    InvalidConfigError: If configuration parameters are invalid.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        },
        "ExportManager": {
          "line": 161,
          "docstring": "Manages all export operations for drawing intelligence results.\n\nCoordinates JSON, CSV, and report generation for drawing results by\ndelegating to specialized exporter classes. Handles both single drawing\nand batch export operations with robust error handling and atomic writes.\n\nAttributes:\n    db: Database manager instance for retrieving drawing data.\n    config: Export configuration settings.\n    json_exporter: JSON format exporter instance.\n    csv_exporter: CSV format exporter instance.\n    report_generator: Report generation instance.\n\nExample:\n    >>> db = DatabaseManager(\"drawings.db\")\n    >>> exporter = ExportManager(db)\n    >>> exporter.export_drawing_json(\"DWG-001\", \"output.json\")",
          "bases": [],
          "methods": [
            {
              "name": "__init__",
              "line": 181,
              "docstring": "Initialize export manager.\n\nArgs:\n    db: Database manager instance for data retrieval.\n    config: Export configuration. If None, uses default configuration.\n    json_exporter: Custom JSON exporter. If None, creates default.\n    csv_exporter: Custom CSV exporter. If None, creates default.\n    report_generator: Custom report generator. If None, creates default.\n\nNote:\n    Custom exporters enable easier unit testing and format extensions.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "db",
                    "type": "DatabaseManager"
                  },
                  {
                    "name": "config",
                    "type": "Optional[ExportConfig]"
                  },
                  {
                    "name": "json_exporter",
                    "type": "Optional[JSONExporter]"
                  },
                  {
                    "name": "csv_exporter",
                    "type": "Optional[CSVExporter]"
                  },
                  {
                    "name": "report_generator",
                    "type": "Optional[ReportGenerator]"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "_sanitize_filename",
              "line": 221,
              "docstring": "Sanitize filename to prevent path traversal and invalid characters.\n\nArgs:\n    filename: Raw filename or ID to sanitize.\n\nReturns:\n    Sanitized filename safe for file system use.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "filename",
                    "type": "str"
                  }
                ],
                "return_type": "str"
              },
              "method_type": "instance"
            },
            {
              "name": "_prepare_output_path",
              "line": 237,
              "docstring": "Prepare and validate output path.\n\nArgs:\n    output_path: Destination file path.\n    expected_format: Expected file format for validation.\n\nReturns:\n    Validated Path object.\n\nRaises:\n    ExportFileError: If path validation fails.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "output_path",
                    "type": "Union[str, Path]"
                  },
                  {
                    "name": "expected_format",
                    "type": "Optional[ReportFormat]"
                  }
                ],
                "return_type": "Path"
              },
              "method_type": "instance"
            },
            {
              "name": "_atomic_write",
              "line": 279,
              "docstring": "Write content atomically using temporary file.\n\nArgs:\n    content_writer: Callable that writes content given a file path.\n    output_path: Final destination path.\n\nRaises:\n    ExportFileError: If write operation fails.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "content_writer"
                  },
                  {
                    "name": "output_path",
                    "type": "Path"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "_get_drawing_or_raise",
              "line": 313,
              "docstring": "Retrieve drawing from database or raise exception.\n\nArgs:\n    drawing_id: Drawing identifier.\n\nReturns:\n    Drawing record from database.\n\nRaises:\n    DrawingNotFoundError: If drawing not found.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "drawing_id",
                    "type": "str"
                  }
                ],
                "return_type": "DrawingRecord"
              },
              "method_type": "instance"
            },
            {
              "name": "_get_batch_records",
              "line": 330,
              "docstring": "Retrieve multiple drawings from database with logging.\n\nArgs:\n    drawing_ids: List of drawing identifiers.\n\nReturns:\n    List of found drawing records.\n\nRaises:\n    ExportError: If no valid drawings found.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "drawing_ids",
                    "type": "List[str]"
                  }
                ],
                "return_type": "List[DrawingRecord]"
              },
              "method_type": "instance"
            },
            {
              "name": "export_drawing_json",
              "line": 384,
              "docstring": "Export single drawing to JSON file.\n\nRetrieves the specified drawing from the database and exports it to\na JSON file using atomic write operations.\n\nArgs:\n    drawing_id: Unique identifier of the drawing to export.\n    output_path: Destination file path for the JSON output.\n    config_override: Temporary config override for this operation.\n\nReturns:\n    Path object of the output file.\n\nRaises:\n    DrawingNotFoundError: If the drawing is not found in the database.\n    ExportFileError: If the file write operation fails.\n\nExample:\n    >>> path = exporter.export_drawing_json(\"DWG-001\", \"results/dwg001.json\")\n    >>> print(path)\n    PosixPath('results/dwg001.json')",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "drawing_id",
                    "type": "str"
                  },
                  {
                    "name": "output_path",
                    "type": "Union[str, Path]"
                  },
                  {
                    "name": "config_override",
                    "type": "Optional[ExportConfig]"
                  }
                ],
                "return_type": "Path"
              },
              "method_type": "instance"
            },
            {
              "name": "export_drawing_csv",
              "line": 444,
              "docstring": "Export single drawing to multiple CSV files.\n\nCreates separate CSV files for different data types:\n- {drawing_id}_summary.csv: High-level drawing information\n- {drawing_id}_entities.csv: Extracted entities (if present)\n- {drawing_id}_detections.csv: Shape detections (if present)\n- {drawing_id}_associations.csv: Entity-shape associations (if present)\n\nArgs:\n    drawing_id: Unique identifier of the drawing to export.\n    output_dir: Destination directory for CSV files.\n    config_override: Temporary config override for this operation.\n\nReturns:\n    List of Path objects for all generated CSV files.\n\nRaises:\n    DrawingNotFoundError: If the drawing is not found in the database.\n    ExportFileError: If file write operations fail.\n\nExample:\n    >>> files = exporter.export_drawing_csv(\"DWG-001\", \"results/\")\n    >>> print([f.name for f in files])\n    ['DWG-001_summary.csv', 'DWG-001_entities.csv']",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "drawing_id",
                    "type": "str"
                  },
                  {
                    "name": "output_dir",
                    "type": "Union[str, Path]"
                  },
                  {
                    "name": "config_override",
                    "type": "Optional[ExportConfig]"
                  }
                ],
                "return_type": "List[Path]"
              },
              "method_type": "instance"
            },
            {
              "name": "export_batch_json",
              "line": 551,
              "docstring": "Export multiple drawings to single JSON file.\n\nConsolidates all specified drawings into a single JSON file. Drawings\nnot found in the database are logged and skipped.\n\nArgs:\n    drawing_ids: List of drawing identifiers to export.\n    output_path: Destination file path for the consolidated JSON.\n    config_override: Temporary config override for this operation.\n\nReturns:\n    Path object of the output file.\n\nRaises:\n    ExportError: If no valid drawings are found to export.\n    ExportFileError: If the file write operation fails.\n\nExample:\n    >>> ids = [\"DWG-001\", \"DWG-002\", \"DWG-003\"]\n    >>> path = exporter.export_batch_json(ids, \"results/batch.json\")",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "drawing_ids",
                    "type": "List[str]"
                  },
                  {
                    "name": "output_path",
                    "type": "Union[str, Path]"
                  },
                  {
                    "name": "config_override",
                    "type": "Optional[ExportConfig]"
                  }
                ],
                "return_type": "Path"
              },
              "method_type": "instance"
            },
            {
              "name": "export_batch_csv",
              "line": 609,
              "docstring": "Export batch of drawings to consolidated CSV files.\n\nCreates consolidated CSV files combining data from all drawings:\n- batch_summary.csv: Summary information for all drawings\n- batch_entities.csv: All entities from all drawings\n- batch_detections.csv: All detections from all drawings\n- batch_associations.csv: All associations from all drawings\n\nArgs:\n    drawing_ids: List of drawing identifiers to export.\n    output_dir: Destination directory for CSV files.\n    config_override: Temporary config override for this operation.\n\nReturns:\n    List of Path objects for all generated CSV files.\n\nRaises:\n    ExportError: If no valid drawings are found to export.\n    ExportFileError: If file write operations fail.\n\nNote:\n    Drawings not found in the database are logged and skipped.\n\nExample:\n    >>> ids = [\"DWG-001\", \"DWG-002\", \"DWG-003\"]\n    >>> files = exporter.export_batch_csv(ids, \"results/batch/\")\n    >>> print(len(files))\n    4",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "drawing_ids",
                    "type": "List[str]"
                  },
                  {
                    "name": "output_dir",
                    "type": "Union[str, Path]"
                  },
                  {
                    "name": "config_override",
                    "type": "Optional[ExportConfig]"
                  }
                ],
                "return_type": "List[Path]"
              },
              "method_type": "instance"
            },
            {
              "name": "generate_batch_report",
              "line": 715,
              "docstring": "Generate comprehensive batch processing report.\n\nCreates a detailed report summarizing batch processing results,\nincluding success rates, review requirements, costs, and timing.\n\nArgs:\n    batch_id: Unique identifier of the batch to report on.\n    output_path: Destination file path for the report.\n    format: Report output format (HTML or PDF).\n\nReturns:\n    Path object of the report file.\n\nRaises:\n    ExportError: If batch is not found.\n    ExportFileError: If file write operation fails.\n\nWarning:\n    Batch tracking must be implemented in the database layer.\n\nExample:\n    >>> path = exporter.generate_batch_report(\n    ...     \"BATCH-2025-01\",\n    ...     \"reports/batch_report.html\",\n    ...     format=ReportFormat.HTML\n    ... )",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "batch_id",
                    "type": "str"
                  },
                  {
                    "name": "output_path",
                    "type": "Union[str, Path]"
                  },
                  {
                    "name": "format",
                    "type": "ReportFormat"
                  }
                ],
                "return_type": "Path"
              },
              "method_type": "instance"
            },
            {
              "name": "export_cost_report",
              "line": 796,
              "docstring": "Generate LLM usage and cost report for a date range.\n\nCreates a report detailing LLM API usage, costs by provider/model/use-case,\nand token consumption statistics for the specified period.\n\nArgs:\n    start_date: Beginning of the reporting period (inclusive).\n    end_date: End of the reporting period (inclusive).\n    output_path: Destination file path for the report.\n    format: Report output format (HTML or PDF).\n\nReturns:\n    Path object of the report file.\n\nRaises:\n    ExportError: If start_date >= end_date.\n    ExportFileError: If file write operation fails.\n\nExample:\n    >>> from datetime import datetime, timedelta\n    >>> end = datetime.now()\n    >>> start = end - timedelta(days=30)\n    >>> path = exporter.export_cost_report(\n    ...     start, end,\n    ...     \"reports/monthly_costs.html\"\n    ... )",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "start_date",
                    "type": "datetime"
                  },
                  {
                    "name": "end_date",
                    "type": "datetime"
                  },
                  {
                    "name": "output_path",
                    "type": "Union[str, Path]"
                  },
                  {
                    "name": "format",
                    "type": "ReportFormat"
                  }
                ],
                "return_type": "Path"
              },
              "method_type": "instance"
            },
            {
              "name": "export_drawing_report",
              "line": 874,
              "docstring": "Generate detailed report for a single drawing.\n\nCreates a comprehensive report including processing results, extracted\nentities, detected shapes, quality metrics, and any validation issues.\n\nArgs:\n    drawing_id: Unique identifier of the drawing to report on.\n    output_path: Destination file path for the report.\n    format: Report output format (HTML or PDF).\n\nReturns:\n    Path object of the report file.\n\nRaises:\n    DrawingNotFoundError: If drawing is not found.\n    ExportFileError: If file write operation fails.\n\nExample:\n    >>> path = exporter.export_drawing_report(\n    ...     \"DWG-001\",\n    ...     \"reports/dwg001_report.pdf\",\n    ...     format=ReportFormat.PDF\n    ... )",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "drawing_id",
                    "type": "str"
                  },
                  {
                    "name": "output_path",
                    "type": "Union[str, Path]"
                  },
                  {
                    "name": "format",
                    "type": "ReportFormat"
                  }
                ],
                "return_type": "Path"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        }
      },
      "functions": []
    },
    "src.drawing_intelligence.export.json_exporter": {
      "file_path": "C:\\00Projects\\engineering_items_attributes_enrichment\\src\\drawing_intelligence\\export\\json_exporter.py",
      "module_docstring": "JSON Exporter Module.\n\nThis module provides functionality to export drawing processing results\nto JSON format with schema validation and support for both single and\nbatch exports.\n\nExample:\n    >>> from export_manager import ExportConfig\n    >>> config = ExportConfig(format=\"json\", output_path=\"output.json\")\n    >>> exporter = JSONExporter(config)\n    >>> exporter.export_single(drawing_record, Path(\"output.json\"))",
      "classes": {
        "ExportConfigProtocol": {
          "line": 42,
          "docstring": "Protocol defining the expected configuration interface.",
          "bases": [
            "Protocol"
          ],
          "methods": [],
          "nested_classes": []
        },
        "JSONExportError": {
          "line": 49,
          "docstring": "Base exception for JSON export operations.",
          "bases": [
            "Exception"
          ],
          "methods": [
            {
              "name": "__init__",
              "line": 52,
              "docstring": null,
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "message",
                    "type": "str"
                  },
                  {
                    "name": "drawing_id",
                    "type": "Optional[str]"
                  }
                ],
                "return_type": null
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        },
        "SchemaValidationError": {
          "line": 57,
          "docstring": "Exception raised when schema validation fails.",
          "bases": [
            "JSONExportError"
          ],
          "methods": [
            {
              "name": "__init__",
              "line": 60,
              "docstring": null,
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "message",
                    "type": "str"
                  },
                  {
                    "name": "errors",
                    "type": "List[str]"
                  },
                  {
                    "name": "drawing_id",
                    "type": "Optional[str]"
                  }
                ],
                "return_type": null
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        },
        "ExportFileError": {
          "line": 67,
          "docstring": "Exception raised when file operations fail.",
          "bases": [
            "JSONExportError"
          ],
          "methods": [],
          "nested_classes": []
        },
        "DrawingJSONEncoder": {
          "line": 73,
          "docstring": "Custom JSON encoder for drawing data structures.\n\nHandles serialization of:\n- datetime objects -> ISO 8601 strings\n- Enum objects -> their values\n- BoundingBox objects -> dictionaries\n- Path objects -> strings\n\nExample:\n    >>> encoder = DrawingJSONEncoder()\n    >>> json.dumps(data, cls=DrawingJSONEncoder)",
          "bases": [
            "json.JSONEncoder"
          ],
          "methods": [
            {
              "name": "default",
              "line": 87,
              "docstring": "Override default serialization behavior.\n\nArgs:\n    obj: Object to serialize.\n\nReturns:\n    JSON-serializable representation of the object.\n\nRaises:\n    TypeError: If object type is not serializable.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "obj",
                    "type": "Any"
                  }
                ],
                "return_type": "Any"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        },
        "JSONExporter": {
          "line": 115,
          "docstring": "Exports drawing results to JSON format with schema validation.\n\nThis class handles serialization of complex drawing data structures\nincluding entities, detections, associations, and hierarchies into\nJSON format suitable for external consumption or archival.\n\nAttributes:\n    config: Export configuration containing format preferences and options.\n\nExample:\n    >>> config = ExportConfig(format=\"json\", output_path=\"output.json\")\n    >>> exporter = JSONExporter(config)\n    >>> exporter.export_single(record, Path(\"output.json\"))",
          "bases": [],
          "methods": [
            {
              "name": "__init__",
              "line": 131,
              "docstring": "Initialize JSON exporter with configuration.\n\nArgs:\n    config: Export configuration object containing format preferences\n        and export options such as json_format (\"pretty\" or \"compact\").\n\nExample:\n    >>> config = ExportConfig(format=\"json\", output_path=\"out.json\")\n    >>> exporter = JSONExporter(config)",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "config",
                    "type": "ExportConfigProtocol"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "export_single",
              "line": 145,
              "docstring": "Export a single drawing record to a JSON file.\n\nFormats the drawing record, optionally validates the schema,\nand writes the result to the specified file path using atomic\nwrite operations. Creates parent directories if they don't exist.\n\nArgs:\n    drawing_record: Drawing record containing all processing results\n        to be exported.\n    output_path: File system path where the JSON file will be written.\n\nRaises:\n    JSONExportError: If export operation fails.\n    SchemaValidationError: If validation is enabled and fails.\n    ExportFileError: If file write operation fails.\n\nExample:\n    >>> exporter.export_single(record, Path(\"results/drawing_001.json\"))",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "drawing_record",
                    "type": "DrawingRecord"
                  },
                  {
                    "name": "output_path",
                    "type": "Union[str, Path]"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "export_batch",
              "line": 204,
              "docstring": "Export multiple drawing records to a single JSON file.\n\nCreates a batch export containing all provided drawings with\nmetadata including export timestamp and total count. All drawings\nare wrapped in a top-level \"drawings\" array.\n\nArgs:\n    drawing_records: List of drawing records to export in batch.\n    output_path: File system path for the output JSON file.\n\nRaises:\n    JSONExportError: If export operation fails.\n    ExportFileError: If file write operation fails.\n\nExample:\n    >>> exporter.export_batch(records, Path(\"results/batch.json\"))",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "drawing_records",
                    "type": "List[DrawingRecord]"
                  },
                  {
                    "name": "output_path",
                    "type": "Union[str, Path]"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "export_batch_streaming",
              "line": 266,
              "docstring": "Export multiple drawings using streaming to minimize memory usage.\n\nWrites each drawing incrementally rather than building the entire\ndata structure in memory. Ideal for large batch exports.\n\nArgs:\n    drawing_records: List of drawing records to export.\n    output_path: File system path for the output JSON file.\n\nRaises:\n    JSONExportError: If export operation fails.\n    ExportFileError: If file write operation fails.\n\nExample:\n    >>> exporter.export_batch_streaming(records, \"large_batch.json\")",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "drawing_records",
                    "type": "List[DrawingRecord]"
                  },
                  {
                    "name": "output_path",
                    "type": "Union[str, Path]"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "export_to_string",
              "line": 361,
              "docstring": "Export drawing record to JSON string.\n\nUseful for API responses or testing without file I/O.\n\nArgs:\n    drawing_record: Drawing record to export.\n    pretty: If True, format with indentation.\n\nReturns:\n    JSON string representation of the drawing.\n\nRaises:\n    JSONExportError: If serialization fails.\n\nExample:\n    >>> json_str = exporter.export_to_string(record, pretty=True)\n    >>> print(json_str)",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "drawing_record",
                    "type": "DrawingRecord"
                  },
                  {
                    "name": "pretty",
                    "type": "bool"
                  }
                ],
                "return_type": "str"
              },
              "method_type": "instance"
            },
            {
              "name": "format_drawing_result",
              "line": 393,
              "docstring": "Convert DrawingRecord to a JSON-serializable dictionary.\n\nTransforms all nested data structures (entities, detections, etc.)\ninto plain dictionaries suitable for JSON serialization. Handles\noptional fields gracefully by checking for None values.\n\nArgs:\n    drawing_record: Drawing record to format for export.\n\nReturns:\n    Dictionary containing all drawing data in serializable format,\n    including metadata, entities, detections, associations, and\n    hierarchies.\n\nExample:\n    >>> formatted = exporter.format_drawing_result(record)\n    >>> print(formatted.keys())\n    dict_keys(['drawing_id', 'entities', 'detections', ...])",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "drawing_record",
                    "type": "DrawingRecord"
                  }
                ],
                "return_type": "Dict[str, Any]"
              },
              "method_type": "instance"
            },
            {
              "name": "_format_list",
              "line": 449,
              "docstring": "Format a list of items using the provided serializer function.\n\nArgs:\n    items: Optional list of items to serialize.\n    serializer: Function to serialize each item.\n\nReturns:\n    List of serialized dictionaries, or empty list if items is None.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "items",
                    "type": "Optional[List[Any]]"
                  },
                  {
                    "name": "serializer",
                    "type": "Callable[[Any], Dict[str, Any]]"
                  }
                ],
                "return_type": "List[Dict[str, Any]]"
              },
              "method_type": "instance"
            },
            {
              "name": "_serialize_text_block",
              "line": 465,
              "docstring": "Serialize a text block to a dictionary.\n\nArgs:\n    text_block: Text block object from OCR processing.\n\nReturns:\n    Dictionary containing text block data.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "text_block",
                    "type": "TextBlock"
                  }
                ],
                "return_type": "Dict[str, Any]"
              },
              "method_type": "instance"
            },
            {
              "name": "_serialize_entity",
              "line": 483,
              "docstring": "Serialize an entity to a dictionary.\n\nArgs:\n    entity: Entity object containing extracted information.\n\nReturns:\n    Dictionary with entity data.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "entity",
                    "type": "Entity"
                  }
                ],
                "return_type": "Dict[str, Any]"
              },
              "method_type": "instance"
            },
            {
              "name": "_serialize_detection",
              "line": 504,
              "docstring": "Serialize a shape detection to a dictionary.\n\nArgs:\n    detection: Detection object from shape detection pipeline.\n\nReturns:\n    Dictionary containing detection data with both bbox formats.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "detection",
                    "type": "Detection"
                  }
                ],
                "return_type": "Dict[str, Any]"
              },
              "method_type": "instance"
            },
            {
              "name": "_serialize_association",
              "line": 526,
              "docstring": "Serialize a text-shape association to a dictionary.\n\nArgs:\n    association: Association linking text blocks to detected shapes.\n\nReturns:\n    Dictionary with association metadata.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "association",
                    "type": "Association"
                  }
                ],
                "return_type": "Dict[str, Any]"
              },
              "method_type": "instance"
            },
            {
              "name": "_serialize_hierarchy",
              "line": 544,
              "docstring": "Serialize component hierarchy to a dictionary.\n\nArgs:\n    hierarchy: Component hierarchy object describing assembly\n        structure.\n\nReturns:\n    Dictionary containing root component ID, assemblies list, and\n    hierarchy tree structure.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "hierarchy",
                    "type": "ComponentHierarchy"
                  }
                ],
                "return_type": "Dict[str, Any]"
              },
              "method_type": "instance"
            },
            {
              "name": "_serialize_review_flag",
              "line": 569,
              "docstring": "Serialize a review flag to a dictionary.\n\nArgs:\n    flag: Review flag indicating issues requiring human attention.\n\nReturns:\n    Dictionary with flag metadata.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "flag",
                    "type": "ReviewFlag"
                  }
                ],
                "return_type": "Dict[str, Any]"
              },
              "method_type": "instance"
            },
            {
              "name": "_serialize_bbox",
              "line": 589,
              "docstring": "Serialize a bounding box to a dictionary.\n\nArgs:\n    bbox: Bounding box with pixel coordinates.\n\nReturns:\n    Dictionary with x, y, width, height keys.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "bbox",
                    "type": "BoundingBox"
                  }
                ],
                "return_type": "Dict[str, Any]"
              },
              "method_type": "instance"
            },
            {
              "name": "_serialize_bbox_safe",
              "line": 605,
              "docstring": "Serialize bounding box with None handling.\n\nArgs:\n    bbox: Optional bounding box with pixel coordinates.\n\nReturns:\n    Dictionary with coordinates, or None if input is None.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "bbox",
                    "type": "Optional[BoundingBox]"
                  }
                ],
                "return_type": "Optional[Dict[str, Any]]"
              },
              "method_type": "instance"
            },
            {
              "name": "_write_json_file_atomic",
              "line": 620,
              "docstring": "Write JSON data to file atomically using temporary file.\n\nThis prevents partial file creation if the write operation fails.\n\nArgs:\n    data: Dictionary to serialize to JSON.\n    output_path: File path for output.\n\nRaises:\n    ExportFileError: If file write fails.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "data",
                    "type": "Dict[str, Any]"
                  },
                  {
                    "name": "output_path",
                    "type": "Path"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "_validate_or_raise",
              "line": 666,
              "docstring": "Validate JSON data and raise exception if invalid.\n\nArgs:\n    json_data: Dictionary to validate.\n    drawing_id: ID of the drawing being validated.\n\nRaises:\n    SchemaValidationError: If validation fails.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "json_data",
                    "type": "Dict[str, Any]"
                  },
                  {
                    "name": "drawing_id",
                    "type": "str"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "validate_schema",
              "line": 684,
              "docstring": "Validate JSON data against expected schema.\n\nPerforms basic structural validation including required field\npresence, data type checking, and value range validation for\nconfidence scores.\n\nArgs:\n    json_data: Dictionary to validate before export.\n\nReturns:\n    Tuple containing:\n        - bool: True if validation passed, False otherwise\n        - List[str]: List of validation error messages\n            (empty if valid)\n\nExample:\n    >>> is_valid, errors = exporter.validate_schema(data)\n    >>> if not is_valid:\n    ...     print(f\"Validation failed: {errors}\")",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "json_data",
                    "type": "Dict[str, Any]"
                  }
                ],
                "return_type": "Tuple[bool, List[str]]"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        }
      },
      "functions": []
    },
    "src.drawing_intelligence.export.report_generator": {
      "file_path": "C:\\00Projects\\engineering_items_attributes_enrichment\\src\\drawing_intelligence\\export\\report_generator.py",
      "module_docstring": "Report Generator Module\n\nGenerates visual reports (HTML/PDF) for drawing processing results with\ncharts, statistics, and detailed analysis.",
      "classes": {
        "ReportFormat": {
          "line": 55,
          "docstring": "Supported report output formats.",
          "bases": [
            "Enum"
          ],
          "methods": [],
          "nested_classes": []
        },
        "ReportGenerationError": {
          "line": 62,
          "docstring": "Base exception for report generation errors.",
          "bases": [
            "Exception"
          ],
          "methods": [],
          "nested_classes": []
        },
        "TemplateError": {
          "line": 68,
          "docstring": "Exception raised when template rendering fails.",
          "bases": [
            "ReportGenerationError"
          ],
          "methods": [],
          "nested_classes": []
        },
        "ChartGenerationError": {
          "line": 74,
          "docstring": "Exception raised when chart generation fails.",
          "bases": [
            "ReportGenerationError"
          ],
          "methods": [],
          "nested_classes": []
        },
        "MissingDependencyError": {
          "line": 80,
          "docstring": "Exception raised when required dependency is missing.",
          "bases": [
            "ReportGenerationError"
          ],
          "methods": [],
          "nested_classes": []
        },
        "ReportGenerator": {
          "line": 86,
          "docstring": "Generate visual reports from drawing processing results.\n\nThis class creates comprehensive HTML and PDF reports for batch processing\nresults, cost analysis, and individual drawing details. It uses Jinja2\ntemplates for HTML generation and optionally converts to PDF using\nWeasyPrint. Charts are generated using Matplotlib when available.\n\nAttributes:\n    template_dir (Path): Directory containing Jinja2 templates.\n    env (Optional[Environment]): Jinja2 environment for template rendering,\n        None if jinja2 is not available.\n    max_drawings_in_report (int): Maximum number of drawings to include\n        in batch reports.\n    chart_dpi (int): DPI resolution for generated charts.\n    enable_charts (bool): Whether to generate charts even if matplotlib\n        is available.\n\nNote:\n    Requires optional dependencies: jinja2, matplotlib, weasyprint\n    (for PDF).",
          "bases": [],
          "methods": [
            {
              "name": "__init__",
              "line": 109,
              "docstring": "Initialize report generator.\n\nArgs:\n    template_dir: Directory containing Jinja2 templates. Will be used\n        as the template loader search path.\n    max_drawings_in_report: Maximum number of drawings to include in\n        batch report details.\n    chart_dpi: DPI resolution for chart images.\n    enable_charts: Whether to generate charts. Can be disabled for\n        performance even if matplotlib is available.\n\nRaises:\n    FileNotFoundError: If template_dir does not exist.\n    MissingDependencyError: If jinja2 is not available.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "template_dir",
                    "type": "Union[str, Path]"
                  },
                  {
                    "name": "max_drawings_in_report",
                    "type": "int"
                  },
                  {
                    "name": "chart_dpi",
                    "type": "int"
                  },
                  {
                    "name": "enable_charts",
                    "type": "bool"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "generate_batch_report",
              "line": 158,
              "docstring": "Generate comprehensive batch processing report.\n\nCreates a report summarizing batch processing results including success\nrates, review rates, costs, and individual drawing summaries. Includes\nconfidence distribution and status charts when matplotlib is available.\n\nArgs:\n    batch_result: BatchResult object containing aggregate statistics.\n    drawing_records: List of DrawingRecord objects for individual\n        drawings.\n    output_path: Output file path for the generated report.\n    format: Report format (HTML or PDF). Defaults to HTML.\n\nReturns:\n    Path to the generated report file.\n\nRaises:\n    ValueError: If format is invalid.\n    IOError: If file write operation fails.\n    TemplateError: If template rendering fails.\n\nNote:\n    PDF generation requires weasyprint. Falls back to HTML if\n    unavailable.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "batch_result",
                    "type": "'BatchResult'"
                  },
                  {
                    "name": "drawing_records",
                    "type": "List['DrawingRecord']"
                  },
                  {
                    "name": "output_path",
                    "type": "Union[str, Path]"
                  },
                  {
                    "name": "format",
                    "type": "ReportFormat"
                  }
                ],
                "return_type": "Path"
              },
              "method_type": "instance"
            },
            {
              "name": "generate_cost_report",
              "line": 221,
              "docstring": "Generate cost analysis report with detailed breakdowns.\n\nCreates a report showing LLM API costs broken down by use case,\nprovider, model, and daily trends. Includes bar charts and trend lines\nwhen matplotlib is available.\n\nArgs:\n    cost_report: CostReport object containing cost statistics and\n        breakdowns.\n    output_path: Output file path for the generated report.\n    format: Report format (HTML or PDF). Defaults to HTML.\n\nReturns:\n    Path to the generated report file.\n\nRaises:\n    ValueError: If format is invalid.\n    IOError: If file write operation fails.\n    TemplateError: If template rendering fails.\n\nNote:\n    Charts require matplotlib. PDF generation requires weasyprint.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "cost_report",
                    "type": "'CostReport'"
                  },
                  {
                    "name": "output_path",
                    "type": "Union[str, Path]"
                  },
                  {
                    "name": "format",
                    "type": "ReportFormat"
                  }
                ],
                "return_type": "Path"
              },
              "method_type": "instance"
            },
            {
              "name": "generate_drawing_report",
              "line": 277,
              "docstring": "Generate detailed report for a single drawing.\n\nCreates a comprehensive report for one drawing including all extracted\nentities, detected shapes, confidence scores, and review flags.\n\nArgs:\n    drawing_record: DrawingRecord object containing all drawing data.\n    output_path: Output file path for the generated report.\n    format: Report format (HTML or PDF). Defaults to HTML.\n\nReturns:\n    Path to the generated report file.\n\nRaises:\n    ValueError: If format is invalid.\n    IOError: If file write operation fails.\n    TemplateError: If template rendering fails.\n\nNote:\n    PDF generation requires weasyprint. Falls back to HTML if\n    unavailable.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "drawing_record",
                    "type": "'DrawingRecord'"
                  },
                  {
                    "name": "output_path",
                    "type": "Union[str, Path]"
                  },
                  {
                    "name": "format",
                    "type": "ReportFormat"
                  }
                ],
                "return_type": "Path"
              },
              "method_type": "instance"
            },
            {
              "name": "_prepare_batch_context",
              "line": 337,
              "docstring": "Prepare template context for batch report.\n\nArgs:\n    batch_result: BatchResult with aggregate statistics.\n    drawing_records: List of DrawingRecord objects.\n\nReturns:\n    Dictionary with template variables.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "batch_result",
                    "type": "'BatchResult'"
                  },
                  {
                    "name": "drawing_records",
                    "type": "List['DrawingRecord']"
                  }
                ],
                "return_type": "Dict[str, Any]"
              },
              "method_type": "instance"
            },
            {
              "name": "_prepare_cost_context",
              "line": 386,
              "docstring": "Prepare template context for cost report.\n\nArgs:\n    cost_report: CostReport with cost statistics.\n\nReturns:\n    Dictionary with template variables.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "cost_report",
                    "type": "'CostReport'"
                  }
                ],
                "return_type": "Dict[str, Any]"
              },
              "method_type": "instance"
            },
            {
              "name": "_prepare_drawing_context",
              "line": 431,
              "docstring": "Prepare template context for drawing report.\n\nArgs:\n    drawing_record: DrawingRecord with drawing data.\n\nReturns:\n    Dictionary with template variables.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "drawing_record",
                    "type": "'DrawingRecord'"
                  }
                ],
                "return_type": "Dict[str, Any]"
              },
              "method_type": "instance"
            },
            {
              "name": "_write_report",
              "line": 502,
              "docstring": "Write report to file in specified format using atomic write.\n\nArgs:\n    html_content: Rendered HTML content.\n    output_path: Target file path.\n    format: Output format (HTML or PDF).\n\nReturns:\n    Path to the generated file.\n\nRaises:\n    IOError: If file write fails.\n    MissingDependencyError: If PDF format requested but weasyprint\n        not available.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "html_content",
                    "type": "str"
                  },
                  {
                    "name": "output_path",
                    "type": "Path"
                  },
                  {
                    "name": "format",
                    "type": "ReportFormat"
                  }
                ],
                "return_type": "Path"
              },
              "method_type": "instance"
            },
            {
              "name": "_render_template",
              "line": 543,
              "docstring": "Render Jinja2 template with provided context.\n\nArgs:\n    template_name: Name of template file in template_dir.\n    context: Dictionary of template variables.\n\nReturns:\n    Rendered HTML string.\n\nRaises:\n    TemplateError: If template rendering fails.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "template_name",
                    "type": "str"
                  },
                  {
                    "name": "context",
                    "type": "Dict[str, Any]"
                  }
                ],
                "return_type": "str"
              },
              "method_type": "instance"
            },
            {
              "name": "_fig_to_base64_uri",
              "line": 568,
              "docstring": "Convert matplotlib figure to base64 data URI.\n\nArgs:\n    fig: Matplotlib figure object.\n\nReturns:\n    Base64-encoded PNG image as data URI string.\n\nRaises:\n    ChartGenerationError: If conversion fails.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "fig"
                  }
                ],
                "return_type": "str"
              },
              "method_type": "instance"
            },
            {
              "name": "_generate_confidence_chart",
              "line": 591,
              "docstring": "Generate confidence score distribution histogram.\n\nArgs:\n    confidences: List of confidence scores (0.0 to 1.0).\n\nReturns:\n    Base64-encoded PNG image as data URI string, or empty string\n    if chart generation fails.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "confidences",
                    "type": "List[float]"
                  }
                ],
                "return_type": "str"
              },
              "method_type": "instance"
            },
            {
              "name": "_generate_status_chart",
              "line": 623,
              "docstring": "Generate batch status distribution pie chart.\n\nArgs:\n    batch_result: BatchResult with successful, needs_review, and\n        failed counts.\n\nReturns:\n    Base64-encoded PNG image as data URI string, or empty string\n    if chart generation fails.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "batch_result",
                    "type": "'BatchResult'"
                  }
                ],
                "return_type": "str"
              },
              "method_type": "instance"
            },
            {
              "name": "_generate_cost_chart",
              "line": 666,
              "docstring": "Generate horizontal bar chart for cost breakdown.\n\nArgs:\n    cost_data: Dictionary mapping categories to cost values.\n    title: Chart title. Defaults to \"Cost Breakdown\".\n\nReturns:\n    Base64-encoded PNG image as data URI string, or empty string\n    if chart generation fails.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "cost_data",
                    "type": "Dict[str, float]"
                  },
                  {
                    "name": "title",
                    "type": "str"
                  }
                ],
                "return_type": "str"
              },
              "method_type": "instance"
            },
            {
              "name": "_generate_daily_trend_chart",
              "line": 707,
              "docstring": "Generate line chart showing daily cost trends.\n\nArgs:\n    daily_costs: List of DailyCost objects with date and total_cost.\n\nReturns:\n    Base64-encoded PNG image as data URI string, or empty string\n    if chart generation fails.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "daily_costs",
                    "type": "List['DailyCost']"
                  }
                ],
                "return_type": "str"
              },
              "method_type": "instance"
            },
            {
              "name": "_convert_html_to_pdf",
              "line": 747,
              "docstring": "Convert HTML string to PDF file using WeasyPrint.\n\nArgs:\n    html_content: Complete HTML document string.\n    pdf_path: Target PDF file path.\n\nReturns:\n    Path to the generated PDF (or HTML if weasyprint unavailable).\n\nRaises:\n    MissingDependencyError: If weasyprint is not available.\n    IOError: If PDF conversion fails.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "html_content",
                    "type": "str"
                  },
                  {
                    "name": "pdf_path",
                    "type": "Path"
                  }
                ],
                "return_type": "Path"
              },
              "method_type": "instance"
            },
            {
              "name": "_generate_simple_batch_report",
              "line": 796,
              "docstring": "Generate plain text batch report as fallback.\n\nUsed when Jinja2 is not available. Creates simple formatted text\nfile with key statistics.\n\nArgs:\n    batch_result: BatchResult object with statistics to report.\n    output_path: Output text file path.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "batch_result",
                    "type": "'BatchResult'"
                  },
                  {
                    "name": "output_path",
                    "type": "Path"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "_generate_simple_cost_report",
              "line": 825,
              "docstring": "Generate plain text cost report as fallback.\n\nUsed when Jinja2 is not available. Creates simple formatted text\nfile with cost summary.\n\nArgs:\n    cost_report: CostReport object with cost data to report.\n    output_path: Output text file path.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "cost_report",
                    "type": "'CostReport'"
                  },
                  {
                    "name": "output_path",
                    "type": "Path"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "_generate_simple_drawing_report",
              "line": 848,
              "docstring": "Generate plain text drawing report as fallback.\n\nUsed when Jinja2 is not available. Creates simple formatted text\nfile with drawing metadata.\n\nArgs:\n    drawing_record: DrawingRecord object with drawing data.\n    output_path: Output text file path.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "drawing_record",
                    "type": "'DrawingRecord'"
                  },
                  {
                    "name": "output_path",
                    "type": "Path"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        }
      },
      "functions": []
    },
    "src.drawing_intelligence.export": {
      "file_path": "C:\\00Projects\\engineering_items_attributes_enrichment\\src\\drawing_intelligence\\export\\__init__.py",
      "module_docstring": "Export module for drawing intelligence results.",
      "classes": {},
      "functions": []
    },
    "src.drawing_intelligence.llm.budget_controller": {
      "file_path": "C:\\00Projects\\engineering_items_attributes_enrichment\\src\\drawing_intelligence\\llm\\budget_controller.py",
      "module_docstring": "Budget controller for LLM API cost management.\n\nThis module provides unified budget control with automatic model tier step-down\nfunctionality. It integrates with the ModelRegistry for consistent model\nmanagement and tracks both daily and per-drawing spending limits.\n\nExample:\n    Basic usage with budget limits::\n\n        controller = BudgetController(\n            daily_budget_usd=50.00,\n            per_drawing_limit_usd=0.30\n        )\n\n        allowed, reason, model = controller.pre_call_check(\n            estimated_input_tokens=2500,\n            estimated_output_tokens=800,\n            image_count=1,\n            use_case=UseCaseType.ENTITY_EXTRACTION,\n            drawing_id=\"DWG-001\"\n        )",
      "classes": {
        "UseCaseType": {
          "line": 38,
          "docstring": "Enumeration of LLM use case types.\n\nAttributes:\n    DRAWING_ASSESSMENT: Overall drawing quality and complexity analysis.\n    OCR_VERIFICATION: Text recognition verification and correction.\n    ENTITY_EXTRACTION: Structured data extraction from drawings.\n    SHAPE_VALIDATION: Geometric shape detection validation.\n    COMPLEX_REASONING: Advanced multi-step reasoning tasks.",
          "bases": [
            "Enum"
          ],
          "methods": [],
          "nested_classes": []
        },
        "UseCaseModelConfig": {
          "line": 57,
          "docstring": "Model configuration for a specific use case with tier fallbacks.\n\nAttributes:\n    use_case: The use case type this configuration applies to.\n    preferred_model: Canonical model name from ModelRegistry (highest\n        tier).\n    tier_1_fallback: Mid-tier fallback model canonical name.\n    tier_0_fallback: Cheapest fallback model canonical name.\n    max_tokens: Maximum tokens for model output.\n    temperature: Sampling temperature (0.0 = deterministic).\n    requires_vision: Whether the use case requires vision capabilities.",
          "bases": [],
          "methods": [],
          "nested_classes": []
        },
        "BudgetController": {
          "line": 80,
          "docstring": "Manages LLM budget with automatic model step-down.\n\nThis class tracks daily and per-drawing LLM spending, automatically\nsteps down to cheaper models when budget thresholds are reached, and\nprevents calls that would exceed configured limits.\n\nAttributes:\n    daily_budget: Maximum daily spending limit in USD.\n    per_drawing_limit: Maximum spending per drawing in USD.\n    alert_threshold: Spending level that triggers tier step-down.\n    db: Optional database manager for persistent tracking.\n    current_tier: Current active model tier (may be stepped down).\n    tier_stepped_down: Whether automatic step-down has occurred.\n    current_drawing_spend: Accumulated spend for current drawing.\n\nExample:\n    Initialize and check budget before LLM call::\n\n        controller = BudgetController(\n            daily_budget_usd=50.00,\n            per_drawing_limit_usd=0.30,\n            alert_threshold_pct=0.80\n        )\n\n        allowed, reason, model = controller.pre_call_check(\n            estimated_input_tokens=2500,\n            estimated_output_tokens=800,\n            image_count=1,\n            use_case=UseCaseType.ENTITY_EXTRACTION,\n            drawing_id=\"DWG-001\"\n        )\n\n        if allowed:\n            # Make LLM call with model\n            pass",
          "bases": [],
          "methods": [
            {
              "name": "__init__",
              "line": 161,
              "docstring": "Initialize budget controller with spending limits.\n\nArgs:\n    daily_budget_usd: Maximum daily spending in USD.\n    per_drawing_limit_usd: Maximum spending per drawing in USD.\n    alert_threshold_pct: Percentage of daily budget that triggers\n        model tier step-down (default: 0.80).\n    db_manager: Optional database manager for persistent tracking.\n        If None, tracking is in-memory only.\n\nRaises:\n    ValueError: If budget values are negative or alert_threshold_pct\n        is not between 0 and 1.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "daily_budget_usd",
                    "type": "float"
                  },
                  {
                    "name": "per_drawing_limit_usd",
                    "type": "float"
                  },
                  {
                    "name": "alert_threshold_pct",
                    "type": "float"
                  },
                  {
                    "name": "db_manager",
                    "type": "Optional['DatabaseManager']"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "get_model_for_use_case",
              "line": 201,
              "docstring": "Get the appropriate model for a use case considering budget.\n\nSelects a model based on the current tier level (which may have been\nstepped down due to budget constraints) and the use case requirements.\n\nArgs:\n    use_case: The type of LLM task being performed.\n    override_model: Optional model canonical name to force use of\n        a specific model (bypasses tier selection).\n\nReturns:\n    Tuple containing:\n        - ModelSpec: The selected model specification.\n        - str: Reason for model selection.\n\nRaises:\n    ValueError: If the selected model doesn't support required\n        capabilities (e.g., vision when needed).\n    KeyError: If override_model is not found in ModelRegistry.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "use_case",
                    "type": "UseCaseType"
                  },
                  {
                    "name": "override_model",
                    "type": "Optional[str]"
                  }
                ],
                "return_type": "Tuple[ModelSpec, str]"
              },
              "method_type": "instance"
            },
            {
              "name": "pre_call_check",
              "line": 257,
              "docstring": "Pre-flight check before making LLM call.\n\nValidates that the proposed LLM call would not exceed budget limits,\nautomatically steps down to cheaper models if near threshold, and\nreturns the appropriate model to use.\n\nArgs:\n    estimated_input_tokens: Expected number of input tokens.\n    estimated_output_tokens: Expected number of output tokens.\n    image_count: Number of images to be processed.\n    use_case: Type of LLM task being performed.\n    drawing_id: Unique identifier for the drawing being processed.\n\nReturns:\n    Tuple containing:\n        - bool: Whether the call should proceed.\n        - str: Explanation of the decision.\n        - Optional[ModelSpec]: The model to use (None if call denied).\n\nNote:\n    This method may modify `self.current_tier` if budget threshold\n    is reached, affecting subsequent calls.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "estimated_input_tokens",
                    "type": "int"
                  },
                  {
                    "name": "estimated_output_tokens",
                    "type": "int"
                  },
                  {
                    "name": "image_count",
                    "type": "int"
                  },
                  {
                    "name": "use_case",
                    "type": "UseCaseType"
                  },
                  {
                    "name": "drawing_id",
                    "type": "str"
                  }
                ],
                "return_type": "Tuple[bool, str, Optional[ModelSpec]]"
              },
              "method_type": "instance"
            },
            {
              "name": "track_call",
              "line": 348,
              "docstring": "Track an LLM call and return actual cost.\n\nRecords the LLM call in the database (if available) and updates\nper-drawing spending tracker. Should be called after successful\nLLM API call with actual token counts.\n\nArgs:\n    provider: Name of the LLM provider (e.g., \"anthropic\", \"openai\").\n    model_id: Specific model version identifier.\n    input_tokens: Actual number of input tokens used.\n    output_tokens: Actual number of output tokens generated.\n    image_count: Number of images processed.\n    drawing_id: Unique identifier for the drawing.\n    use_case: Type of LLM task that was performed.\n    timestamp: Optional timestamp for the call. If None, uses current\n        time.\n\nReturns:\n    Actual cost in USD for the call.\n\nRaises:\n    KeyError: If model_id is not found in ModelRegistry.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "provider",
                    "type": "str"
                  },
                  {
                    "name": "model_id",
                    "type": "str"
                  },
                  {
                    "name": "input_tokens",
                    "type": "int"
                  },
                  {
                    "name": "output_tokens",
                    "type": "int"
                  },
                  {
                    "name": "image_count",
                    "type": "int"
                  },
                  {
                    "name": "drawing_id",
                    "type": "str"
                  },
                  {
                    "name": "use_case",
                    "type": "UseCaseType"
                  },
                  {
                    "name": "timestamp",
                    "type": "Optional[datetime]"
                  }
                ],
                "return_type": "float"
              },
              "method_type": "instance"
            },
            {
              "name": "_step_down_tier",
              "line": 418,
              "docstring": "Step down to next cheaper tier.\n\nReduces the current tier level and logs the change. Called\nautomatically by pre_call_check when budget threshold is reached.\n\nNote:\n    Has no effect if already at TIER_0_CHEAP (lowest tier).",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "_get_daily_spend",
              "line": 438,
              "docstring": "Get today's total LLM spend.\n\nReturns:\n    Total spending in USD for the current date. Returns 0.0 if\n    database manager is not configured.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "float"
              },
              "method_type": "instance"
            },
            {
              "name": "_get_drawing_spend",
              "line": 457,
              "docstring": "Get total spend for a specific drawing.\n\nArgs:\n    drawing_id: Unique identifier for the drawing.\n\nReturns:\n    Total spending in USD for the specified drawing. Returns\n    in-memory tracker value if database is not configured.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "drawing_id",
                    "type": "str"
                  }
                ],
                "return_type": "float"
              },
              "method_type": "instance"
            },
            {
              "name": "_get_budget_used_pct",
              "line": 478,
              "docstring": "Get percentage of daily budget used.\n\nReturns:\n    Percentage (0-100) of daily budget that has been spent.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "float"
              },
              "method_type": "instance"
            },
            {
              "name": "reset_drawing_tracker",
              "line": 488,
              "docstring": "Reset per-drawing spend tracker.\n\nShould be called when starting processing of a new drawing to\nensure per-drawing limits are correctly enforced.\n\nNote:\n    This only resets in-memory tracking. Historical database\n    records are not affected.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "get_usage_summary",
              "line": 500,
              "docstring": "Get current usage summary.\n\nReturns:\n    Dictionary containing:\n        - daily_budget (float): Configured daily limit.\n        - daily_spend (float): Current daily spending.\n        - remaining_budget (float): Budget remaining today.\n        - budget_used_pct (float): Percentage of budget used.\n        - current_tier (str): Active model tier name.\n        - tier_stepped_down (bool): Whether step-down occurred.\n        - alert_threshold (float): Threshold that triggers step-down.\n        - alert_triggered (bool): Whether threshold was reached.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "Dict[str, Union[float, str, bool]]"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        }
      },
      "functions": []
    },
    "src.drawing_intelligence.llm.cost_tracker": {
      "file_path": "C:\\00Projects\\engineering_items_attributes_enrichment\\src\\drawing_intelligence\\llm\\cost_tracker.py",
      "module_docstring": "Cost tracking module for LLM usage.\n\nThis module provides comprehensive tracking and reporting of LLM API costs\nacross multiple dimensions including time periods, providers, models, use cases,\nand individual drawings. All timestamps are handled in UTC.",
      "classes": {
        "CostRecord": {
          "line": 31,
          "docstring": "Structured representation of an LLM usage record.\n\nAttributes:\n    timestamp: UTC timestamp of the API call.\n    drawing_id: Unique identifier for the drawing being processed.\n    provider: Provider name (e.g., 'openai', 'anthropic', 'google').\n    model: Model identifier (e.g., 'gpt-4o-2024-08-06').\n    use_case: Type of operation (e.g., 'entity_extraction').\n    tokens_input: Number of input tokens consumed.\n    tokens_output: Number of output tokens generated.\n    image_count: Number of images processed (0 if none).\n    cost_usd: Total cost in USD for this API call.",
          "bases": [],
          "methods": [
            {
              "name": "from_dict",
              "line": 57,
              "docstring": "Create CostRecord from database dictionary.\n\nArgs:\n    record: Dictionary from database query result.\n\nReturns:\n    CostRecord instance with parsed values.",
              "signature": {
                "parameters": [
                  {
                    "name": "cls"
                  },
                  {
                    "name": "record",
                    "type": "Dict[str, Any]"
                  }
                ],
                "return_type": "'CostRecord'"
              },
              "method_type": "class"
            }
          ],
          "nested_classes": []
        },
        "CostTracker": {
          "line": 79,
          "docstring": "Track and report LLM API costs across multiple dimensions.\n\nThis class provides comprehensive cost tracking for LLM API usage,\nsupporting aggregation by time period, provider, model, use case,\nand individual drawings. All costs are tracked in USD and timestamps\nare handled in UTC.\n\nAttributes:\n    db: Optional DatabaseManager instance for persistent cost tracking.\n    top_n_default: Default number of top items to include in reports.\n\nExample:\n    >>> tracker = CostTracker(db_manager)\n    >>> tracker.track_call(\n    ...     provider=\"openai\",\n    ...     model=\"gpt-4o\",\n    ...     tokens=token_usage,\n    ...     cost=0.05,\n    ...     drawing_id=\"DWG-001\",\n    ...     use_case=\"entity_extraction\"\n    ... )\n    >>> report = tracker.generate_cost_report(\"weekly\", start, end)",
          "bases": [],
          "methods": [
            {
              "name": "__init__",
              "line": 107,
              "docstring": "Initialize cost tracker.\n\nArgs:\n    db_manager: Optional DatabaseManager for persistent tracking.\n        If None, cost tracking will log but not persist data.\n    top_n_default: Default number of top items to include in\n        reports (default: 10).\n\nRaises:\n    ValueError: If top_n_default is less than 1.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "db_manager",
                    "type": "Optional[DatabaseManager]"
                  },
                  {
                    "name": "top_n_default",
                    "type": "int"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "track_call",
              "line": 137,
              "docstring": "Track a single LLM API call and persist usage data.\n\nRecords token usage and cost information for a specific LLM API call.\nIf database manager is unavailable, logs the call but does not persist.\n\nArgs:\n    provider: Provider name (e.g., 'openai', 'anthropic', 'google').\n    model: Model identifier (e.g., 'gpt-4o-2024-08-06').\n    tokens: TokenUsage object containing input/output token counts\n        and optional image count.\n    cost: Total cost of the API call in USD.\n    drawing_id: Unique identifier for the drawing being processed.\n    use_case: Type of operation (e.g., 'entity_extraction',\n        'ocr_verification', 'drawing_assessment').\n\nRaises:\n    ValueError: If cost is negative or tokens are invalid.\n\nNote:\n    This method is designed to never interrupt processing pipeline\n    even if cost tracking fails. Database errors are logged but\n    not raised.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "provider",
                    "type": "str"
                  },
                  {
                    "name": "model",
                    "type": "str"
                  },
                  {
                    "name": "tokens",
                    "type": "TokenUsage"
                  },
                  {
                    "name": "cost",
                    "type": "float"
                  },
                  {
                    "name": "drawing_id",
                    "type": "str"
                  },
                  {
                    "name": "use_case",
                    "type": "str"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "get_daily_cost",
              "line": 200,
              "docstring": "Get total LLM API cost for a specific day.\n\nArgs:\n    date: Date to query (timezone-aware or naive, treated as UTC).\n        If None, defaults to current UTC date.\n\nReturns:\n    Total cost in USD for all LLM API calls on the specified date.\n    Returns 0.0 if no database is available or no records exist.\n\nExample:\n    >>> cost = tracker.get_daily_cost(datetime(2025, 11, 8, tzinfo=timezone.utc))\n    >>> print(f\"Cost on 2025-11-08: ${cost:.2f}\")",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "date",
                    "type": "Optional[datetime]"
                  }
                ],
                "return_type": "float"
              },
              "method_type": "instance"
            },
            {
              "name": "get_cost_by_use_case",
              "line": 236,
              "docstring": "Get costs aggregated by use case type.\n\nArgs:\n    start_date: Start of date range (inclusive, UTC).\n    end_date: End of date range (exclusive, UTC).\n\nReturns:\n    Dictionary mapping use case names to total costs in USD.\n    Empty dict if no database is available or no records exist.\n\nExample:\n    >>> costs = tracker.get_cost_by_use_case(start, end)\n    >>> print(f\"Entity extraction: ${costs.get('entity_extraction', 0):.2f}\")",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "start_date",
                    "type": "datetime"
                  },
                  {
                    "name": "end_date",
                    "type": "datetime"
                  }
                ],
                "return_type": "Dict[str, float]"
              },
              "method_type": "instance"
            },
            {
              "name": "get_cost_by_provider",
              "line": 255,
              "docstring": "Get costs aggregated by LLM provider.\n\nArgs:\n    start_date: Start of date range (inclusive, UTC).\n    end_date: End of date range (exclusive, UTC).\n\nReturns:\n    Dictionary mapping provider names to total costs in USD.\n    Empty dict if no database is available or no records exist.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "start_date",
                    "type": "datetime"
                  },
                  {
                    "name": "end_date",
                    "type": "datetime"
                  }
                ],
                "return_type": "Dict[str, float]"
              },
              "method_type": "instance"
            },
            {
              "name": "get_cost_by_model",
              "line": 270,
              "docstring": "Get costs aggregated by model identifier.\n\nArgs:\n    start_date: Start of date range (inclusive, UTC).\n    end_date: End of date range (exclusive, UTC).\n\nReturns:\n    Dictionary mapping model identifiers to total costs in USD.\n    Empty dict if no database is available or no records exist.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "start_date",
                    "type": "datetime"
                  },
                  {
                    "name": "end_date",
                    "type": "datetime"
                  }
                ],
                "return_type": "Dict[str, float]"
              },
              "method_type": "instance"
            },
            {
              "name": "get_cost_by_drawing",
              "line": 285,
              "docstring": "Get total LLM cost for a specific drawing.\n\nCalculates cumulative cost across all LLM API calls made during\nprocessing of the specified drawing.\n\nArgs:\n    drawing_id: Unique identifier for the drawing.\n    start_date: Optional start date filter (inclusive, UTC).\n    end_date: Optional end date filter (exclusive, UTC).\n\nReturns:\n    Total cost in USD for all LLM operations on this drawing.\n    Returns 0.0 if no database is available or no records exist.\n\nNote:\n    If date range is not specified, queries all historical records.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "drawing_id",
                    "type": "str"
                  },
                  {
                    "name": "start_date",
                    "type": "Optional[datetime]"
                  },
                  {
                    "name": "end_date",
                    "type": "Optional[datetime]"
                  }
                ],
                "return_type": "float"
              },
              "method_type": "instance"
            },
            {
              "name": "generate_cost_report",
              "line": 339,
              "docstring": "Generate comprehensive cost report with multiple breakdowns.\n\nCreates a detailed report including total costs, call counts,\nbreakdowns by provider/model/use case, daily trends, top drawings,\nand token usage statistics. Fetches data from database once for\nefficiency.\n\nArgs:\n    period: Descriptive name for the reporting period\n        (e.g., 'daily', 'weekly', 'monthly', 'custom').\n    start_date: Start of reporting period (inclusive, UTC).\n    end_date: End of reporting period (exclusive, UTC).\n    top_n: Number of top drawings to include. If None, uses\n        the instance's top_n_default value.\n\nReturns:\n    CostReport object containing all cost metrics and breakdowns.\n    Returns empty report if no database or no records exist.\n\nRaises:\n    ValueError: If period is not a valid period type or date range\n        is invalid.\n\nExample:\n    >>> report = tracker.generate_cost_report(\n    ...     \"weekly\",\n    ...     datetime(2025, 11, 1, tzinfo=timezone.utc),\n    ...     datetime(2025, 11, 8, tzinfo=timezone.utc)\n    ... )\n    >>> print(f\"Total: ${report.total_cost:.2f}\")\n    >>> print(f\"Calls: {report.total_calls}\")",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "period",
                    "type": "str"
                  },
                  {
                    "name": "start_date",
                    "type": "datetime"
                  },
                  {
                    "name": "end_date",
                    "type": "datetime"
                  },
                  {
                    "name": "top_n",
                    "type": "Optional[int]"
                  }
                ],
                "return_type": "CostReport"
              },
              "method_type": "instance"
            },
            {
              "name": "export_cost_data",
              "line": 458,
              "docstring": "Export cost data to file in CSV or JSON format.\n\nArgs:\n    start_date: Start of date range (inclusive, UTC).\n    end_date: End of date range (exclusive, UTC).\n    output_path: Full path for output file.\n    export_format: Output format, either 'csv' or 'json'.\n\nRaises:\n    ValueError: If export_format is not 'csv' or 'json', or if\n        date range is invalid, or if output_path is invalid.\n    IOError: If file writing fails.\n\nNote:\n    Logs warning and returns early if no database is available.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "start_date",
                    "type": "datetime"
                  },
                  {
                    "name": "end_date",
                    "type": "datetime"
                  },
                  {
                    "name": "output_path",
                    "type": "str"
                  },
                  {
                    "name": "export_format",
                    "type": "str"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "_get_aggregated_costs",
              "line": 522,
              "docstring": "Get costs aggregated by a specific field.\n\nArgs:\n    start_date: Start of date range (inclusive, UTC).\n    end_date: End of date range (exclusive, UTC).\n    field: Field name to aggregate by ('use_case', 'provider', 'model').\n\nReturns:\n    Dictionary mapping field values to total costs in USD.\n    Empty dict if no database is available or no records exist.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "start_date",
                    "type": "datetime"
                  },
                  {
                    "name": "end_date",
                    "type": "datetime"
                  },
                  {
                    "name": "field",
                    "type": "str"
                  }
                ],
                "return_type": "Dict[str, float]"
              },
              "method_type": "instance"
            },
            {
              "name": "_aggregate_costs_by_field",
              "line": 551,
              "docstring": "Aggregate costs by a specific field from CostRecord list.\n\nArgs:\n    cost_records: List of CostRecord objects.\n    field: Field name to aggregate by (must be a CostRecord attribute).\n\nReturns:\n    Dictionary mapping field values to total costs.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "cost_records",
                    "type": "List[CostRecord]"
                  },
                  {
                    "name": "field",
                    "type": "str"
                  }
                ],
                "return_type": "Dict[str, float]"
              },
              "method_type": "instance"
            },
            {
              "name": "_calculate_daily_costs",
              "line": 569,
              "docstring": "Calculate daily cost breakdown from CostRecord list.\n\nArgs:\n    cost_records: List of CostRecord objects.\n\nReturns:\n    List of DailyCost objects sorted by date.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "cost_records",
                    "type": "List[CostRecord]"
                  }
                ],
                "return_type": "List[DailyCost]"
              },
              "method_type": "instance"
            },
            {
              "name": "_calculate_top_drawings",
              "line": 601,
              "docstring": "Calculate top N drawings by total cost.\n\nArgs:\n    cost_records: List of CostRecord objects.\n    top_n: Number of top drawings to return.\n\nReturns:\n    List of (drawing_id, total_cost) tuples sorted by cost descending.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "cost_records",
                    "type": "List[CostRecord]"
                  },
                  {
                    "name": "top_n",
                    "type": "int"
                  }
                ],
                "return_type": "List[Tuple[str, float]]"
              },
              "method_type": "instance"
            },
            {
              "name": "_calculate_token_summary",
              "line": 623,
              "docstring": "Calculate aggregate token usage statistics.\n\nArgs:\n    cost_records: List of CostRecord objects.\n\nReturns:\n    TokenUsageSummary with totals and averages for input/output\n    tokens and image counts.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "cost_records",
                    "type": "List[CostRecord]"
                  }
                ],
                "return_type": "TokenUsageSummary"
              },
              "method_type": "instance"
            },
            {
              "name": "_empty_cost_report",
              "line": 654,
              "docstring": "Create an empty cost report for periods with no data.\n\nArgs:\n    period: Descriptive name for the reporting period.\n    start_date: Start of reporting period (UTC).\n    end_date: End of reporting period (UTC).\n\nReturns:\n    CostReport with all numeric fields set to zero.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "period",
                    "type": "str"
                  },
                  {
                    "name": "start_date",
                    "type": "datetime"
                  },
                  {
                    "name": "end_date",
                    "type": "datetime"
                  }
                ],
                "return_type": "CostReport"
              },
              "method_type": "instance"
            },
            {
              "name": "_export_csv",
              "line": 686,
              "docstring": "Export usage records to CSV format.\n\nArgs:\n    usage_records: List of LLM usage record dictionaries.\n    output_path: Full path for output CSV file.\n\nRaises:\n    IOError: If file writing fails.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "usage_records",
                    "type": "List[Dict[str, Any]]"
                  },
                  {
                    "name": "output_path",
                    "type": "str"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "_export_json",
              "line": 721,
              "docstring": "Export usage records to JSON format.\n\nArgs:\n    usage_records: List of LLM usage record dictionaries.\n    output_path: Full path for output JSON file.\n\nRaises:\n    IOError: If file writing fails.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "usage_records",
                    "type": "List[Dict[str, Any]]"
                  },
                  {
                    "name": "output_path",
                    "type": "str"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "_validate_date_range",
              "line": 740,
              "docstring": "Validate that date range is valid.\n\nArgs:\n    start_date: Start date (UTC).\n    end_date: End date (UTC).\n\nRaises:\n    ValueError: If start_date >= end_date.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "start_date",
                    "type": "datetime"
                  },
                  {
                    "name": "end_date",
                    "type": "datetime"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "_validate_cost_inputs",
              "line": 756,
              "docstring": "Validate inputs for cost tracking.\n\nArgs:\n    provider: Provider name.\n    model: Model identifier.\n    cost: Cost in USD.\n    drawing_id: Drawing identifier.\n    use_case: Use case type.\n\nRaises:\n    ValueError: If any input is invalid.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "provider",
                    "type": "str"
                  },
                  {
                    "name": "model",
                    "type": "str"
                  },
                  {
                    "name": "cost",
                    "type": "float"
                  },
                  {
                    "name": "drawing_id",
                    "type": "str"
                  },
                  {
                    "name": "use_case",
                    "type": "str"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "_validate_output_path",
              "line": 782,
              "docstring": "Validate output path for export.\n\nArgs:\n    output_path: Path to validate.\n\nRaises:\n    ValueError: If path is invalid or potentially dangerous.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "output_path",
                    "type": "str"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "_ensure_utc",
              "line": 811,
              "docstring": "Ensure datetime is timezone-aware in UTC.\n\nArgs:\n    dt: Datetime to convert (naive or aware).\n\nReturns:\n    Timezone-aware datetime in UTC.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "dt",
                    "type": "datetime"
                  }
                ],
                "return_type": "datetime"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        }
      },
      "functions": []
    },
    "src.drawing_intelligence.llm.llm_gateway": {
      "file_path": "C:\\00Projects\\engineering_items_attributes_enrichment\\src\\drawing_intelligence\\llm\\llm_gateway.py",
      "module_docstring": "LLM Gateway - unified interface to multiple LLM providers with budget control.\n\nThis module provides a centralized gateway for managing LLM API calls across\nmultiple providers (OpenAI, Anthropic, Google) with features including:\n- Automatic provider selection and fallback\n- Budget enforcement and cost tracking\n- Use-case specific model selection\n- Prompt template management\n- Retry logic with exponential backoff and jitter\n\nTypical usage example:\n\n    config = LLMConfig(\n        enabled=True,\n        primary_provider=ProviderConfig(\n            name=\"openai\",\n            api_key_env=\"OPENAI_API_KEY\"\n        )\n    )\n    budget_controller = BudgetController(daily_budget_usd=50.0)\n\n    with LLMGateway(config, budget_controller) as gateway:\n        response = gateway.call_llm(\n            prompt=\"Extract part number\",\n            image=drawing_image,\n            use_case=UseCaseType.ENTITY_EXTRACTION,\n            drawing_id=\"DWG-001\"\n        )",
      "classes": {
        "LLMDefaults": {
          "line": 72,
          "docstring": "Default configuration values for LLM operations.",
          "bases": [],
          "methods": [],
          "nested_classes": []
        },
        "ProviderConfig": {
          "line": 88,
          "docstring": "Configuration for a single LLM provider.\n\nAttributes:\n    name: Provider name ('openai', 'anthropic', 'google').\n    api_key_env: Environment variable name containing API key.\n    base_url: Optional custom base URL for proxies/Azure (OpenAI only).\n    timeout: Optional custom timeout in seconds.\n    organization: Optional organization ID (OpenAI only).",
          "bases": [],
          "methods": [],
          "nested_classes": []
        },
        "LLMConfig": {
          "line": 107,
          "docstring": "Configuration for LLM gateway initialization.\n\nAttributes:\n    enabled: Whether LLM integration is enabled.\n    primary_provider: Primary provider configuration.\n    fallback_provider: Optional fallback provider config.\n    timeout_seconds: Default API request timeout.\n    max_retries: Maximum retry attempts for transient errors.\n    defaults: Default values for LLM operations.",
          "bases": [],
          "methods": [],
          "nested_classes": []
        },
        "ProviderFactory": {
          "line": 127,
          "docstring": "Factory for creating LLM provider instances.",
          "bases": [],
          "methods": [
            {
              "name": "create",
              "line": 150,
              "docstring": "Create a provider instance by name.\n\nArgs:\n    name: Provider name (case-insensitive).\n    api_key: API authentication key.\n    model_registry: Model registry instance.\n    config: Provider-specific configuration.\n\nReturns:\n    Instantiated provider object.\n\nRaises:\n    ValueError: If provider name is unknown.",
              "signature": {
                "parameters": [
                  {
                    "name": "cls"
                  },
                  {
                    "name": "name",
                    "type": "str"
                  },
                  {
                    "name": "api_key",
                    "type": "str"
                  },
                  {
                    "name": "model_registry",
                    "type": "ModelRegistry"
                  },
                  {
                    "name": "config",
                    "type": "Dict[str, Any]"
                  }
                ],
                "return_type": "BaseLLMProvider"
              },
              "method_type": "class"
            }
          ],
          "nested_classes": []
        },
        "LLMGateway": {
          "line": 181,
          "docstring": "Unified interface to multiple LLM providers with budget control.\n\nThis gateway manages LLM API calls across multiple providers, handling\nprovider initialization, automatic fallback, budget enforcement, cost\ntracking, and retry logic. Supports use-case specific model selection\nvia ModelRegistry and BudgetController.\n\nThe gateway implements a hybrid approach where:\n- 90-95% of drawings use open-source processing only\n- 5-10% of drawings flagged as low-confidence use LLM enhancement\n- All LLM usage is tracked against daily budget limits\n\nAttributes:\n    config: LLMConfig instance defining provider settings and timeouts.\n    budget_controller: BudgetController for enforcing daily spend limits.\n    cost_tracker: Optional CostTracker for detailed cost analytics.\n    prompt_library: PromptLibrary for managing reusable prompt templates.\n    model_registry: ModelRegistry instance for model specifications.",
          "bases": [],
          "methods": [
            {
              "name": "__init__",
              "line": 202,
              "docstring": "Initialize LLM gateway with configuration and dependencies.\n\nArgs:\n    config: LLM configuration including provider settings.\n    budget_controller: Budget controller for cost enforcement.\n    cost_tracker: Optional cost tracker for detailed analytics.\n    prompt_library: Optional prompt library for template management.\n\nRaises:\n    ConfigurationError: If primary provider configuration is invalid.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "config",
                    "type": "LLMConfig"
                  },
                  {
                    "name": "budget_controller",
                    "type": "BudgetController"
                  },
                  {
                    "name": "cost_tracker",
                    "type": "Optional[CostTracker]"
                  },
                  {
                    "name": "prompt_library",
                    "type": "Optional[PromptLibrary]"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "_initialize_providers",
              "line": 232,
              "docstring": "Initialize configured LLM providers from environment variables.\n\nReads API keys from environment and instantiates provider objects.\nStores both provider instances and their configurations for fallback.\n\nRaises:\n    ConfigurationError: If primary provider is missing required config.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "_init_provider",
              "line": 248,
              "docstring": "Initialize a single provider from configuration.\n\nArgs:\n    provider_config: Provider configuration object.\n    is_primary: Whether this is the primary provider.\n\nRaises:\n    ConfigurationError: If primary provider initialization fails.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "provider_config",
                    "type": "ProviderConfig"
                  },
                  {
                    "name": "is_primary",
                    "type": "bool"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "call_llm",
              "line": 300,
              "docstring": "Execute LLM API call with automatic provider and model selection.\n\nThis is the primary method for all LLM interactions. Handles:\n- Input validation\n- Pre-call budget validation\n- Image format conversion and optimization\n- Model selection via BudgetController or override\n- Retry logic with exponential backoff and jitter\n- Automatic fallback to secondary provider\n- Cost tracking and budget updates\n\nArgs:\n    prompt: Text prompt describing the task.\n    image: Optional numpy array image in BGR format.\n    use_case: Type of operation for budget allocation.\n    drawing_id: Unique identifier for cost tracking.\n    override_model: Optional model ID to force specific model.\n    max_tokens: Optional max tokens override.\n    temperature: Optional temperature override.\n\nReturns:\n    LLMResponse object containing content, tokens, and cost.\n\nRaises:\n    BudgetExceededException: If budget check fails.\n    LLMAPIError: If call fails after all retries.\n    ValueError: If inputs are invalid.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "prompt",
                    "type": "str"
                  },
                  {
                    "name": "image",
                    "type": "Optional[np.ndarray]"
                  },
                  {
                    "name": "use_case",
                    "type": "UseCaseType"
                  },
                  {
                    "name": "drawing_id",
                    "type": "str"
                  },
                  {
                    "name": "override_model",
                    "type": "Optional[str]"
                  },
                  {
                    "name": "max_tokens",
                    "type": "Optional[int]"
                  },
                  {
                    "name": "temperature",
                    "type": "Optional[float]"
                  }
                ],
                "return_type": "LLMResponse"
              },
              "method_type": "instance"
            },
            {
              "name": "_call_with_retry",
              "line": 417,
              "docstring": "Execute LLM call with retry logic.\n\nArgs:\n    provider_name: Name of provider to use.\n    prompt: Text prompt.\n    image_bytes: Optional image bytes.\n    model_spec: Model specification.\n    max_tokens: Maximum tokens to generate.\n    temperature: Sampling temperature.\n\nReturns:\n    LLMResponse if successful.\n\nRaises:\n    LLMAPIError: If all retries exhausted.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "provider_name",
                    "type": "str"
                  },
                  {
                    "name": "prompt",
                    "type": "str"
                  },
                  {
                    "name": "image_bytes",
                    "type": "Optional[bytes]"
                  },
                  {
                    "name": "model_spec",
                    "type": "ModelSpec"
                  },
                  {
                    "name": "max_tokens",
                    "type": "int"
                  },
                  {
                    "name": "temperature",
                    "type": "float"
                  }
                ],
                "return_type": "LLMResponse"
              },
              "method_type": "instance"
            },
            {
              "name": "_get_model_spec",
              "line": 489,
              "docstring": "Get model specification with budget validation.\n\nArgs:\n    use_case: Use case for model selection.\n    drawing_id: Drawing ID for tracking.\n    override_model: Optional model override.\n    estimated_input_tokens: Estimated input token count.\n    estimated_output_tokens: Estimated output token count.\n    image_count: Number of images.\n\nReturns:\n    ModelSpec instance.\n\nRaises:\n    BudgetExceededException: If budget check fails.\n    ValueError: If override_model is invalid.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "use_case",
                    "type": "UseCaseType"
                  },
                  {
                    "name": "drawing_id",
                    "type": "str"
                  },
                  {
                    "name": "override_model",
                    "type": "Optional[str]"
                  },
                  {
                    "name": "estimated_input_tokens",
                    "type": "int"
                  },
                  {
                    "name": "estimated_output_tokens",
                    "type": "int"
                  },
                  {
                    "name": "image_count",
                    "type": "int"
                  }
                ],
                "return_type": "ModelSpec"
              },
              "method_type": "instance"
            },
            {
              "name": "_track_cost",
              "line": 543,
              "docstring": "Track LLM call cost in budget controller and cost tracker.\n\nArgs:\n    response: LLM response object.\n    model_spec: Model specification used.\n    drawing_id: Drawing ID for tracking.\n    use_case: Use case type.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "response",
                    "type": "LLMResponse"
                  },
                  {
                    "name": "model_spec",
                    "type": "ModelSpec"
                  },
                  {
                    "name": "drawing_id",
                    "type": "str"
                  },
                  {
                    "name": "use_case",
                    "type": "UseCaseType"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "assess_drawing_quality",
              "line": 592,
              "docstring": "Evaluate drawing quality for pipeline routing decision.\n\nUses LLM vision capabilities to assess drawing quality and recommend\nappropriate processing pipeline (baseline vs enhanced).\n\nArgs:\n    image: Drawing image as numpy array (BGR format).\n    drawing_id: Unique drawing identifier.\n    file_name: Original filename for context.\n\nReturns:\n    DrawingAssessment with quality scores and pipeline recommendation.\n\nNote:\n    Uses structured JSON output for reliable parsing. Falls back to\n    default scores (0.5) if parsing fails.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "image",
                    "type": "np.ndarray"
                  },
                  {
                    "name": "drawing_id",
                    "type": "str"
                  },
                  {
                    "name": "file_name",
                    "type": "str"
                  }
                ],
                "return_type": "DrawingAssessment"
              },
              "method_type": "instance"
            },
            {
              "name": "verify_ocr",
              "line": 666,
              "docstring": "Verify and correct OCR text using LLM vision capabilities.\n\nArgs:\n    image_crop: Cropped image region (BGR format).\n    ocr_text: Original OCR extracted text.\n    drawing_id: Drawing identifier.\n    region_type: Region type for context.\n\nReturns:\n    OCRVerification with corrected text and confidence.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "image_crop",
                    "type": "np.ndarray"
                  },
                  {
                    "name": "ocr_text",
                    "type": "str"
                  },
                  {
                    "name": "drawing_id",
                    "type": "str"
                  },
                  {
                    "name": "region_type",
                    "type": "str"
                  }
                ],
                "return_type": "OCRVerification"
              },
              "method_type": "instance"
            },
            {
              "name": "extract_entities_llm",
              "line": 731,
              "docstring": "Extract structured entities from text using LLM reasoning.\n\nArgs:\n    text: Text to extract entities from.\n    context: Additional context for disambiguation.\n    entity_types: List of entity type names to extract.\n    drawing_id: Drawing identifier for tracking.\n\nReturns:\n    List of Entity objects.\n\nRaises:\n    LLMAPIError: If LLM call fails.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "text",
                    "type": "str"
                  },
                  {
                    "name": "context",
                    "type": "str"
                  },
                  {
                    "name": "entity_types",
                    "type": "List[str]"
                  },
                  {
                    "name": "drawing_id",
                    "type": "str"
                  }
                ],
                "return_type": "List[Entity]"
              },
              "method_type": "instance"
            },
            {
              "name": "_prepare_image",
              "line": 804,
              "docstring": "Convert and optimize numpy image for API transmission.\n\nPerforms validation, optional resizing for cost optimization,\nand JPEG encoding.\n\nArgs:\n    image: Numpy array image in BGR format.\n\nReturns:\n    JPEG-encoded image bytes.\n\nRaises:\n    ValueError: If image is invalid or encoding fails.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "image",
                    "type": "np.ndarray"
                  }
                ],
                "return_type": "bytes"
              },
              "method_type": "instance"
            },
            {
              "name": "_estimate_tokens",
              "line": 862,
              "docstring": "Estimate token count from text.\n\nArgs:\n    text: Input text.\n\nReturns:\n    Estimated token count.\n\nNote:\n    Uses simple word-based estimation. For production, use\n    provider-specific tokenizers (e.g., tiktoken for OpenAI).",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "text",
                    "type": "str"
                  }
                ],
                "return_type": "int"
              },
              "method_type": "instance"
            },
            {
              "name": "_calculate_backoff",
              "line": 877,
              "docstring": "Calculate backoff time with exponential backoff and jitter.\n\nArgs:\n    attempt: Current attempt number (1-indexed).\n\nReturns:\n    Backoff time in seconds.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "attempt",
                    "type": "int"
                  }
                ],
                "return_type": "float"
              },
              "method_type": "instance"
            },
            {
              "name": "_is_retryable_error",
              "line": 890,
              "docstring": "Determine if an error is transient and should be retried.\n\nArgs:\n    error: Exception raised during LLM API call.\n\nReturns:\n    True if error is likely transient.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "error",
                    "type": "Exception"
                  }
                ],
                "return_type": "bool"
              },
              "method_type": "instance"
            },
            {
              "name": "close",
              "line": 935,
              "docstring": "Close all provider connections and cleanup resources.\n\nCall this method when the gateway is no longer needed to release\nnetwork connections and other resources held by providers.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "__enter__",
              "line": 952,
              "docstring": "Context manager entry.\n\nReturns:\n    Self for use in 'with' statements.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "'LLMGateway'"
              },
              "method_type": "instance"
            },
            {
              "name": "__exit__",
              "line": 960,
              "docstring": "Context manager exit with cleanup.\n\nArgs:\n    exc_type: Exception type if an exception was raised.\n    exc_val: Exception value if an exception was raised.\n    exc_tb: Exception traceback if an exception was raised.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "exc_type",
                    "type": "Any"
                  },
                  {
                    "name": "exc_val",
                    "type": "Any"
                  },
                  {
                    "name": "exc_tb",
                    "type": "Any"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        }
      },
      "functions": []
    },
    "src.drawing_intelligence.llm.prompt_library": {
      "file_path": "C:\\00Projects\\engineering_items_attributes_enrichment\\src\\drawing_intelligence\\llm\\prompt_library.py",
      "module_docstring": "Prompt library for LLM use cases.\n\nThis module provides a centralized system for managing versioned prompt templates\nused across different LLM providers. It supports variable substitution, token\nbudget tracking, and model recommendations for cost-optimized LLM operations.\n\nThe library loads both built-in prompts (hardcoded for core use cases) and\ncustom prompts from the config/prompts directory (supports .txt and .yaml formats).\n\nExample:\n    >>> library = PromptLibrary()\n    >>> template = library.get_prompt(\"drawing_assessment\")\n    >>> prompt = library.render_prompt(template, {\"file_name\": \"drawing_001.pdf\"})\n\n    # Or render directly:\n    >>> prompt = library.render(\"drawing_assessment\", {\"file_name\": \"drawing_001.pdf\"})",
      "classes": {
        "PromptLibraryError": {
          "line": 43,
          "docstring": "Base exception for prompt library errors.",
          "bases": [
            "Exception"
          ],
          "methods": [],
          "nested_classes": []
        },
        "PromptNotFoundError": {
          "line": 49,
          "docstring": "Raised when a requested prompt is not found.",
          "bases": [
            "PromptLibraryError"
          ],
          "methods": [
            {
              "name": "__init__",
              "line": 52,
              "docstring": null,
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "use_case",
                    "type": "str"
                  },
                  {
                    "name": "version",
                    "type": "Optional[str]"
                  }
                ],
                "return_type": null
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        },
        "PromptRenderError": {
          "line": 62,
          "docstring": "Raised when prompt rendering fails.",
          "bases": [
            "PromptLibraryError"
          ],
          "methods": [
            {
              "name": "__init__",
              "line": 65,
              "docstring": null,
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "template_name",
                    "type": "str"
                  },
                  {
                    "name": "reason",
                    "type": "str"
                  },
                  {
                    "name": "missing_vars",
                    "type": "Optional[List[str]]"
                  }
                ],
                "return_type": null
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        },
        "PromptValidationError": {
          "line": 77,
          "docstring": "Raised when prompt validation fails.",
          "bases": [
            "PromptLibraryError"
          ],
          "methods": [],
          "nested_classes": []
        },
        "PromptTemplate": {
          "line": 84,
          "docstring": "Prompt template definition with versioning and metadata.\n\nA structured container for LLM prompt templates that supports variable\nsubstitution, token budget estimation, and model recommendations.\n\nAttributes:\n    name: Unique identifier for the prompt use case (e.g., 'drawing_assessment').\n    version: Semantic version string (e.g., 'v1.2' or '1.2.0').\n    template: Prompt text with {variable} placeholders for string formatting.\n    variables: List of variable names required for template rendering.\n    token_budget: Estimated token count for budget tracking and model selection.\n    recommended_model: Model identifier from ModelRegistry for optimal performance.\n    metadata: Additional context (e.g., use_case_type, testing_notes).\n    deprecated: Whether this prompt version is deprecated.",
          "bases": [],
          "methods": [
            {
              "name": "__post_init__",
              "line": 110,
              "docstring": "Validate template after initialization.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": null
              },
              "method_type": "instance"
            },
            {
              "name": "to_dict",
              "line": 121,
              "docstring": "Serialize to dictionary.\n\nReturns:\n    Dictionary representation of the template.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "Dict[str, Any]"
              },
              "method_type": "instance"
            },
            {
              "name": "from_dict",
              "line": 130,
              "docstring": "Deserialize from dictionary.\n\nArgs:\n    data: Dictionary with template data.\n\nReturns:\n    PromptTemplate instance.",
              "signature": {
                "parameters": [
                  {
                    "name": "cls"
                  },
                  {
                    "name": "data",
                    "type": "Dict[str, Any]"
                  }
                ],
                "return_type": "'PromptTemplate'"
              },
              "method_type": "class"
            }
          ],
          "nested_classes": []
        },
        "PromptLibrary": {
          "line": 142,
          "docstring": "Manage versioned prompts for different LLM use cases.\n\nThis class provides a centralized repository for prompt templates with\nversion control, variable substitution, token budget tracking, and model\nrecommendations. It loads both built-in prompts (for core use cases) and\ncustom prompts from the filesystem.\n\nSupports lazy loading and caching for optimal performance.\n\nAttributes:\n    prompts_dir: Path to directory containing custom prompt files.\n    default_token_budget: Default token budget for custom prompts without explicit budget.\n    default_model: Default model for custom prompts without explicit model.\n\nExample:\n    >>> library = PromptLibrary(\"config/prompts\")\n    >>> template = library.get_prompt(\"drawing_assessment\", \"v1.2\")\n    >>> context = {\"file_name\": \"DWG-001.pdf\"}\n    >>> rendered = library.render_prompt(template, context)\n\n    # Or use the convenience method:\n    >>> rendered = library.render(\"drawing_assessment\", context)",
          "bases": [],
          "methods": [
            {
              "name": "__init__",
              "line": 167,
              "docstring": "Initialize prompt library and load all available prompts.\n\nCreates the prompts directory if it doesn't exist, loads built-in\nprompts, and prepares to lazy-load custom prompts from the directory.\n\nArgs:\n    prompts_dir: Relative or absolute path to prompts directory.\n    default_token_budget: Default token budget for custom prompts.\n    default_model: Default model for custom prompts.\n\nRaises:\n    PromptValidationError: If prompts_dir contains invalid characters.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "prompts_dir",
                    "type": "str"
                  },
                  {
                    "name": "default_token_budget",
                    "type": "int"
                  },
                  {
                    "name": "default_model",
                    "type": "str"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "get_prompt",
              "line": 209,
              "docstring": "Retrieve prompt template for specified use case and version.\n\nLazy-loads custom prompts on first access to improve startup performance.\n\nArgs:\n    use_case: Use case identifier (e.g., 'drawing_assessment').\n    version: Semantic version string (e.g., 'v1.2', '1.2.0') or 'latest'.\n\nReturns:\n    PromptTemplate matching the specified use case and version.\n\nRaises:\n    PromptNotFoundError: If use_case or version doesn't exist.\n\nExample:\n    >>> template = library.get_prompt(\"drawing_assessment\", \"latest\")\n    >>> print(template.recommended_model)\n    'claude-3-haiku-20240307'",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "use_case",
                    "type": "str"
                  },
                  {
                    "name": "version",
                    "type": "str"
                  }
                ],
                "return_type": "PromptTemplate"
              },
              "method_type": "instance"
            },
            {
              "name": "render_prompt",
              "line": 255,
              "docstring": "Render prompt template by substituting variables with context values.\n\nUses Python string formatting to replace {variable} placeholders.\nHandles escaped braces ({{, }}) and format specifiers (e.g., {var:.2f}).\n\nArgs:\n    template: PromptTemplate to render.\n    context: Dictionary mapping variable names to their values.\n\nReturns:\n    Fully rendered prompt string ready for LLM API submission.\n\nRaises:\n    PromptRenderError: If rendering fails (missing variables, format errors).\n\nExample:\n    >>> template = library.get_prompt(\"drawing_assessment\")\n    >>> context = {\"file_name\": \"DWG-001.pdf\"}\n    >>> prompt = library.render_prompt(template, context)",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "template",
                    "type": "PromptTemplate"
                  },
                  {
                    "name": "context",
                    "type": "Dict[str, Any]"
                  }
                ],
                "return_type": "str"
              },
              "method_type": "instance"
            },
            {
              "name": "render",
              "line": 308,
              "docstring": "Convenience method to get and render a prompt in one call.\n\nArgs:\n    use_case: Use case identifier.\n    context: Dictionary with variable values.\n    version: Version string or 'latest'.\n\nReturns:\n    Rendered prompt string.\n\nRaises:\n    PromptNotFoundError: If prompt doesn't exist.\n    PromptRenderError: If rendering fails.\n\nExample:\n    >>> prompt = library.render(\"drawing_assessment\", {\"file_name\": \"DWG-001.pdf\"})",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "use_case",
                    "type": "str"
                  },
                  {
                    "name": "context",
                    "type": "Dict[str, Any]"
                  },
                  {
                    "name": "version",
                    "type": "str"
                  }
                ],
                "return_type": "str"
              },
              "method_type": "instance"
            },
            {
              "name": "list_available_prompts",
              "line": 331,
              "docstring": "List all available prompts organized by use case.\n\nArgs:\n    include_metadata: If True, include full template metadata.\n\nReturns:\n    Dictionary mapping use case names to version info.\n    If include_metadata=False: {\"use_case\": [\"v1.0\", \"v1.2\"], ...}\n    If include_metadata=True: {\"use_case\": {\"v1.0\": {...}, \"v1.2\": {...}}, ...}\n\nExample:\n    >>> prompts = library.list_available_prompts()\n    >>> print(prompts[\"ocr_verification\"])\n    ['v1.1']",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "include_metadata",
                    "type": "bool"
                  }
                ],
                "return_type": "Dict[str, Any]"
              },
              "method_type": "instance"
            },
            {
              "name": "add_prompt",
              "line": 370,
              "docstring": "Add or update a prompt template in the library.\n\nArgs:\n    prompt: PromptTemplate to add to the library.\n    overwrite: If False, raises error when overwriting existing prompt.\n\nRaises:\n    PromptValidationError: If prompt already exists and overwrite=False.\n\nExample:\n    >>> custom_prompt = PromptTemplate(\n    ...     name=\"custom_check\",\n    ...     version=\"v1.0\",\n    ...     template=\"Check this: {data}\",\n    ...     variables=[\"data\"],\n    ...     token_budget=500,\n    ...     recommended_model=\"gpt-3.5-turbo\",\n    ...     metadata={}\n    ... )\n    >>> library.add_prompt(custom_prompt)",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "prompt",
                    "type": "PromptTemplate"
                  },
                  {
                    "name": "overwrite",
                    "type": "bool"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "remove_prompt",
              "line": 410,
              "docstring": "Remove a prompt from the library.\n\nArgs:\n    use_case: Use case identifier.\n    version: Version to remove.\n\nRaises:\n    PromptNotFoundError: If prompt doesn't exist.\n\nExample:\n    >>> library.remove_prompt(\"custom_check\", \"v1.0\")",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "use_case",
                    "type": "str"
                  },
                  {
                    "name": "version",
                    "type": "str"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "deprecate_prompt",
              "line": 441,
              "docstring": "Mark a prompt version as deprecated.\n\nArgs:\n    use_case: Use case identifier.\n    version: Version to deprecate.\n\nRaises:\n    PromptNotFoundError: If prompt doesn't exist.\n\nExample:\n    >>> library.deprecate_prompt(\"drawing_assessment\", \"v1.0\")",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "use_case",
                    "type": "str"
                  },
                  {
                    "name": "version",
                    "type": "str"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "_get_latest_version",
              "line": 477,
              "docstring": "Get the latest version for a use case with caching.\n\nArgs:\n    use_case: Use case identifier.\n\nReturns:\n    Latest version string.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "use_case",
                    "type": "str"
                  }
                ],
                "return_type": "str"
              },
              "method_type": "instance"
            },
            {
              "name": "_extract_variables",
              "line": 518,
              "docstring": "Extract variable names from template, handling format specs and escaped braces.\n\nArgs:\n    template_str: Template string.\n\nReturns:\n    Set of variable names.\n\nExample:\n    >>> vars = self._extract_variables(\"Hello {name}, score: {value:.2f}\")\n    >>> print(vars)\n    {'name', 'value'}",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "template_str",
                    "type": "str"
                  }
                ],
                "return_type": "Set[str]"
              },
              "method_type": "instance"
            },
            {
              "name": "_validate_path",
              "line": 538,
              "docstring": "Validate and sanitize file path to prevent traversal attacks.\n\nArgs:\n    path_str: Path string to validate.\n\nReturns:\n    Validated Path object.\n\nRaises:\n    PromptValidationError: If path contains dangerous patterns.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "path_str",
                    "type": "str"
                  }
                ],
                "return_type": "Path"
              },
              "method_type": "instance"
            },
            {
              "name": "_lazy_load_use_case",
              "line": 562,
              "docstring": "Lazy load custom prompts for a specific use case.\n\nArgs:\n    use_case: Use case to load.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "use_case",
                    "type": "str"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "_load_all_custom_prompts",
              "line": 585,
              "docstring": "Load all custom prompts from directory.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "_load_prompt_file",
              "line": 596,
              "docstring": "Load a single prompt file.\n\nArgs:\n    prompt_file: Path to prompt file.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "prompt_file",
                    "type": "Path"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "_load_yaml_prompt",
              "line": 610,
              "docstring": "Load prompt from YAML file with full metadata.\n\nExpected format:\n    name: use_case_name\n    version: v1.0\n    template: |\n        Your prompt text here with {variables}\n    variables:\n        - var1\n        - var2\n    token_budget: 1000\n    recommended_model: gpt-4-turbo\n    metadata:\n        key: value\n\nArgs:\n    prompt_file: Path to YAML file.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "prompt_file",
                    "type": "Path"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "_load_text_prompt",
              "line": 670,
              "docstring": "Load prompt from plain text file.\n\nFile naming: {use_case}_{version}.txt or {use_case}.txt (defaults to v1.0)\n\nArgs:\n    prompt_file: Path to text file.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "prompt_file",
                    "type": "Path"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "_load_builtin_prompts",
              "line": 714,
              "docstring": "Load built-in prompt templates for core use cases.\n\nHardcodes prompt templates for the four primary use cases:\n- drawing_assessment: Quality and complexity evaluation\n- ocr_verification: OCR error correction\n- entity_extraction: Structured data extraction\n- shape_validation: Detection validation\n\nThis method is called during __init__ and should not be called directly.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        }
      },
      "functions": []
    },
    "src.drawing_intelligence.llm": {
      "file_path": "C:\\00Projects\\engineering_items_attributes_enrichment\\src\\drawing_intelligence\\llm\\__init__.py",
      "module_docstring": "LLM integration modules for the Drawing Intelligence System.\n\nThis package contains LLM gateway, providers, and cost tracking.",
      "classes": {},
      "functions": []
    },
    "src.drawing_intelligence.models.data_structures": {
      "file_path": "C:\\00Projects\\engineering_items_attributes_enrichment\\src\\drawing_intelligence\\models\\data_structures.py",
      "module_docstring": "Core data structures for the Drawing Intelligence System.\n\nThis module defines all data classes and enums used throughout the system\nfor representing PDF pages, OCR results, entities, shape detections,\nvalidation reports, LLM usage tracking, and processing results.\n\nAll spatial information is preserved using BoundingBox structures, and\nconfidence scores are tracked at multiple levels to support the hybrid\nprocessing architecture (open-source + optional LLM enhancement).",
      "classes": {
        "EntityType": {
          "line": 29,
          "docstring": "Types of entities that can be extracted from engineering drawings.\n\nAttributes:\n    PART_NUMBER: Unique part identifier.\n    OEM: Original Equipment Manufacturer information.\n    MATERIAL: Material specification.\n    DIMENSION: Measurement values (length, diameter, etc.).\n    WEIGHT: Component weight specification.\n    THREAD_SPEC: Threading specifications (M10x1.5, etc.).\n    TOLERANCE: Manufacturing tolerance values.\n    SURFACE_FINISH: Surface finish requirements (Ra, Rz).\n    SCALE: Drawing scale ratio.\n    DATE: Drawing date or revision date.\n    REVISION: Revision identifier.\n    DRAFTER: Person who created the drawing.\n    TITLE: Drawing title or description.",
          "bases": [
            "Enum"
          ],
          "methods": [],
          "nested_classes": []
        },
        "ProcessingStage": {
          "line": 63,
          "docstring": "Processing pipeline stages.\n\nRepresents the sequential stages in the drawing processing pipeline.\nUsed for tracking progress and checkpoint/resumption functionality.",
          "bases": [
            "Enum"
          ],
          "methods": [],
          "nested_classes": []
        },
        "PipelineType": {
          "line": 80,
          "docstring": "Type of processing pipeline.\n\nAttributes:\n    BASELINE_ONLY: Uses only open-source tools (90-95% of drawings).\n    HYBRID: Baseline processing with selective LLM enhancement.\n    LLM_ENHANCED: Full LLM-assisted processing (5-10% of drawings).",
          "bases": [
            "Enum"
          ],
          "methods": [],
          "nested_classes": []
        },
        "Priority": {
          "line": 94,
          "docstring": "Drawing processing priority levels.\n\nUsed for queue management in batch processing operations.",
          "bases": [
            "Enum"
          ],
          "methods": [],
          "nested_classes": []
        },
        "FlagType": {
          "line": 106,
          "docstring": "Types of review flags for quality control.\n\nIndicates why a drawing has been flagged for human review.",
          "bases": [
            "Enum"
          ],
          "methods": [],
          "nested_classes": []
        },
        "Severity": {
          "line": 120,
          "docstring": "Severity levels for validation issues and review flags.\n\nUsed to prioritize human review and determine processing actions.",
          "bases": [
            "Enum"
          ],
          "methods": [],
          "nested_classes": []
        },
        "PDFPage": {
          "line": 138,
          "docstring": "Represents a single PDF page with extracted content.\n\nAttributes:\n    page_number: 1-indexed page number from source PDF.\n    image: Rendered page image as numpy array (RGB or grayscale).\n    dimensions: Tuple of (width, height) in pixels.\n    embedded_text_blocks: Text extracted from PDF structure.\n    dpi: Dots per inch used for rendering (minimum 300).\n    metadata: Additional page metadata (rotation, colorspace, etc.).",
          "bases": [],
          "methods": [],
          "nested_classes": []
        },
        "QualityMetrics": {
          "line": 159,
          "docstring": "Image quality assessment metrics for preprocessing validation.\n\nAttributes:\n    blur_metric: Laplacian variance score (higher = sharper).\n    contrast_score: RMS contrast measurement.\n    brightness_mean: Mean pixel intensity value.\n    is_acceptable: Whether image meets quality thresholds.\n    rejection_reason: Explanation if image rejected.",
          "bases": [],
          "methods": [],
          "nested_classes": []
        },
        "TextBlock": {
          "line": 183,
          "docstring": "Single OCR-extracted text block with spatial information.\n\nAttributes:\n    text_id: Unique identifier for this text block.\n    content: Extracted text content.\n    bbox: Bounding box coordinates.\n    confidence: OCR confidence score [0.0, 1.0].\n    ocr_engine: Engine that extracted this text.\n    region_type: Semantic region classification.",
          "bases": [],
          "methods": [],
          "nested_classes": []
        },
        "LayoutRegion": {
          "line": 204,
          "docstring": "Classified layout region from document structure analysis.\n\nAttributes:\n    region_id: Unique identifier for this region.\n    region_type: Region classification.\n    bbox: Bounding box of the region.\n    confidence: Classification confidence score [0.0, 1.0].",
          "bases": [],
          "methods": [],
          "nested_classes": []
        },
        "OCRResult": {
          "line": 221,
          "docstring": "Complete OCR extraction result for a drawing page.\n\nAttributes:\n    text_blocks: All extracted text blocks with spatial info.\n    language_detected: Primary language code (en, it, de, fr).\n    layout_regions: Classified document regions.\n    average_confidence: Mean confidence across all text blocks.\n\nProperties:\n    full_text: Concatenated text from all blocks.",
          "bases": [],
          "methods": [
            {
              "name": "full_text",
              "line": 240,
              "docstring": "Get all text content concatenated.\n\nReturns:\n    Space-separated concatenation of all text block contents.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "str"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        },
        "Entity": {
          "line": 255,
          "docstring": "Extracted entity with metadata and provenance.\n\nAttributes:\n    entity_id: Unique identifier for this entity.\n    entity_type: Classification of entity.\n    value: Extracted value as string.\n    original_text: Original text before normalization.\n    normalized_value: Structured parsed value with units/format.\n    confidence: Extraction confidence score [0.0, 1.0].\n    extraction_method: Method used (regex, spacy, llm).\n    source_text_id: Reference to source TextBlock.\n    bbox: Spatial location (if available).",
          "bases": [],
          "methods": [],
          "nested_classes": []
        },
        "TitleBlock": {
          "line": 282,
          "docstring": "Structured title block data from engineering drawing.\n\nContains standardized metadata typically found in drawing title blocks.\nAll fields are optional as not all drawings contain complete blocks.\n\nAttributes:\n    part_number: Part or drawing number.\n    title: Drawing title or description.\n    oem: Original Equipment Manufacturer.\n    revision: Revision level or version.\n    date: Drawing date or last revision date.\n    drafter: Person who created/modified the drawing.\n    scale: Drawing scale (1:1, 1:2, etc.).\n    material: Material specification.",
          "bases": [],
          "methods": [],
          "nested_classes": []
        },
        "ExtractionStats": {
          "line": 310,
          "docstring": "Statistics about entity extraction results.\n\nAttributes:\n    total_entities: Total number of entities extracted.\n    entities_by_type: Count of entities per EntityType.\n    entities_by_method: Count of entities per extraction method.\n    average_confidence: Mean confidence across all entities.",
          "bases": [],
          "methods": [],
          "nested_classes": []
        },
        "EntityExtractionResult": {
          "line": 327,
          "docstring": "Complete entity extraction result with statistics.\n\nAttributes:\n    entities: All extracted entities.\n    title_block: Structured title block data (if found).\n    extraction_statistics: Summary statistics.\n    validation_report: Optional validation results.",
          "bases": [],
          "methods": [],
          "nested_classes": []
        },
        "Detection": {
          "line": 349,
          "docstring": "Single shape detection from YOLOv8 model.\n\nAttributes:\n    detection_id: Unique identifier for this detection.\n    class_name: Detected object class (e.g., 'bolt', 'shaft').\n    confidence: Detection confidence score [0.0, 1.0].\n    bbox: Bounding box in pixel coordinates.\n    bbox_normalized: Normalized bounding box [0.0, 1.0].\n    model_version: YOLOv8 model version used.",
          "bases": [],
          "methods": [],
          "nested_classes": []
        },
        "DetectionSummary": {
          "line": 370,
          "docstring": "Summary statistics for shape detection results.\n\nAttributes:\n    total_detections: Total number of detections.\n    detections_by_class: Count of detections per class.\n    average_confidence: Mean confidence across all detections.\n    confidence_distribution: Proportion of high/medium/low confidence.",
          "bases": [],
          "methods": [],
          "nested_classes": []
        },
        "DetectionResult": {
          "line": 387,
          "docstring": "Complete shape detection result from YOLOv8.\n\nAttributes:\n    detections: All detected shapes.\n    summary: Summary statistics.\n    inference_time_ms: Model inference time in milliseconds.\n    model_version: YOLOv8 model version identifier.",
          "bases": [],
          "methods": [],
          "nested_classes": []
        },
        "Association": {
          "line": 409,
          "docstring": "Text-to-shape spatial association.\n\nLinks text entities (dimensions, labels) to detected shapes based on\nspatial proximity and heuristics.\n\nAttributes:\n    association_id: Unique identifier.\n    text_id: Reference to TextBlock ID.\n    shape_id: Reference to Detection ID.\n    relationship_type: Type of relationship.\n    confidence: Association confidence score [0.0, 1.0].\n    distance_pixels: Spatial distance between text and shape.",
          "bases": [],
          "methods": [],
          "nested_classes": []
        },
        "ViewGroup": {
          "line": 433,
          "docstring": "Multi-view component grouping for orthographic projections.\n\nGroups related shapes that represent different views of the same\ncomponent.\n\nAttributes:\n    group_id: Unique identifier for the view group.\n    component_class: Component classification.\n    shape_ids: List of detection IDs in this group.\n    views: View types included.\n    primary_shape_id: Main/representative shape ID.",
          "bases": [],
          "methods": [],
          "nested_classes": []
        },
        "DimensionLink": {
          "line": 455,
          "docstring": "Links dimension entity to specific shape feature.\n\nAttributes:\n    entity_id: Reference to dimension Entity.\n    shape_id: Reference to Detection.\n    feature_type: Feature being dimensioned.\n    confidence: Link confidence score [0.0, 1.0].",
          "bases": [],
          "methods": [],
          "nested_classes": []
        },
        "Assembly": {
          "line": 472,
          "docstring": "Component assembly relationship.\n\nRepresents hierarchical or functional relationships between components.\n\nAttributes:\n    parent_shape_id: Parent component detection ID.\n    child_shape_ids: Child component detection IDs.\n    relationship_type: Nature of relationship.\n    confidence: Relationship confidence [0.0, 1.0].",
          "bases": [],
          "methods": [],
          "nested_classes": []
        },
        "ComponentHierarchy": {
          "line": 491,
          "docstring": "Assembly hierarchy structure for complex drawings.\n\nAttributes:\n    root_component_id: Top-level component in hierarchy.\n    assemblies: All assembly relationships.\n    hierarchy_tree: Nested dictionary representation of hierarchy.",
          "bases": [],
          "methods": [],
          "nested_classes": []
        },
        "ValidationIssue": {
          "line": 511,
          "docstring": "Single validation issue found during data quality checks.\n\nAttributes:\n    severity: Issue severity level.\n    type: Issue classification/category.\n    message: Human-readable description.\n    entity_id: Related entity ID (if applicable).\n    shape_id: Related detection ID (if applicable).\n    suggested_fix: Recommended corrective action.",
          "bases": [],
          "methods": [],
          "nested_classes": []
        },
        "ValidationReport": {
          "line": 532,
          "docstring": "Data validation report from quality checks.\n\nAttributes:\n    is_valid: Whether data passes validation.\n    issues: List of all validation issues found.\n    confidence_adjustment: Adjustment factor for overall confidence.\n    requires_human_review: Whether manual review is needed.",
          "bases": [],
          "methods": [],
          "nested_classes": []
        },
        "ReviewFlag": {
          "line": 554,
          "docstring": "Flag marking drawing for human review.\n\nAttributes:\n    flag_id: Unique identifier.\n    flag_type: Reason for flagging.\n    severity: Issue severity level.\n    reason: Human-readable explanation.\n    details: Additional structured information.\n    suggested_action: Recommended next steps.\n    affected_entities: Entity IDs involved in the issue.\n    affected_shapes: Detection IDs involved in the issue.",
          "bases": [],
          "methods": [],
          "nested_classes": []
        },
        "CompletenessScore": {
          "line": 579,
          "docstring": "Data completeness assessment for quality scoring.\n\nEvaluates whether critical fields and data categories are present.\n\nAttributes:\n    overall_score: Overall completeness [0.0, 1.0].\n    has_part_number: Whether part number was found.\n    has_dimensions: Whether dimensions were extracted.\n    has_shapes: Whether shapes were detected.\n    has_title_block: Whether title block was found.\n    missing_critical_fields: List of missing required fields.\n    completeness_by_category: Scores per data category.",
          "bases": [],
          "methods": [],
          "nested_classes": []
        },
        "TokenUsage": {
          "line": 609,
          "docstring": "LLM token usage for a single API call.\n\nAttributes:\n    input_tokens: Number of input tokens consumed.\n    output_tokens: Number of output tokens generated.\n    image_count: Number of images included in request.",
          "bases": [],
          "methods": [],
          "nested_classes": []
        },
        "LLMUsageRecord": {
          "line": 624,
          "docstring": "Single LLM usage record for cost tracking.\n\nStored in database for budget monitoring and reporting.\n\nAttributes:\n    usage_id: Unique identifier.\n    drawing_id: Associated drawing identifier.\n    use_case: Purpose of LLM call.\n    provider: LLM provider (openai, anthropic, google).\n    model: Specific model used.\n    tokens_input: Input tokens consumed.\n    tokens_output: Output tokens generated.\n    cost_usd: Total cost in USD for this call.\n    timestamp: When the call was made.",
          "bases": [],
          "methods": [],
          "nested_classes": []
        },
        "DrawingAssessment": {
          "line": 653,
          "docstring": "Drawing quality assessment from LLM vision model.\n\nUsed to determine optimal processing pipeline.\n\nAttributes:\n    overall_quality: Overall quality score [0.0, 1.0].\n    complexity_score: Drawing complexity [0.0, 1.0].\n    text_clarity: Text legibility score [0.0, 1.0].\n    shape_clarity: Shape definition clarity [0.0, 1.0].\n    recommended_pipeline: Recommended pipeline type.\n    reasoning: Natural language explanation of assessment.",
          "bases": [],
          "methods": [],
          "nested_classes": []
        },
        "OCRVerification": {
          "line": 676,
          "docstring": "OCR verification/correction result from LLM.\n\nUsed to verify and correct OCR output for low-confidence text.\n\nAttributes:\n    corrected_text: LLM-corrected text.\n    corrections_made: List of specific corrections applied.\n    confidence: LLM confidence in corrections [0.0, 1.0].",
          "bases": [],
          "methods": [],
          "nested_classes": []
        },
        "ProcessingResult": {
          "line": 698,
          "docstring": "Complete result from drawing processing pipeline.\n\nThis is the primary output structure containing all extracted data,\nmetadata, quality scores, and processing information for a single\ndrawing.\n\nAttributes:\n    drawing_id: Unique drawing identifier.\n    source_file: Original PDF filename.\n    processing_timestamp: When processing completed.\n    pipeline_type: Pipeline used.\n    pipeline_version: Software version identifier.\n    pdf_pages: Extracted PDF pages.\n    ocr_result: OCR extraction results.\n    entities: All extracted entities.\n    title_block: Structured title block data.\n    detections: All shape detections.\n    associations: Text-to-shape associations.\n    hierarchy: Component assembly hierarchy.\n    validation_report: Data validation results.\n    overall_confidence: Overall extraction confidence [0.0, 1.0].\n    confidence_scores: Detailed confidence breakdown.\n    review_flags: Issues requiring review.\n    completeness_score: Data completeness assessment.\n    llm_usage: LLM API usage records.\n    processing_times: Duration of each stage (seconds).\n    status: Processing status.",
          "bases": [],
          "methods": [
            {
              "name": "get_entities_by_type",
              "line": 749,
              "docstring": "Get all entities of a specific type.\n\nArgs:\n    entity_type: The EntityType to filter by.\n\nReturns:\n    List of entities matching the specified type.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "entity_type",
                    "type": "EntityType"
                  }
                ],
                "return_type": "List[Entity]"
              },
              "method_type": "instance"
            },
            {
              "name": "get_shape_classes",
              "line": 760,
              "docstring": "Get list of unique detected shape classes.\n\nReturns:\n    List of unique class names from all detections.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "List[str]"
              },
              "method_type": "instance"
            },
            {
              "name": "needs_human_review",
              "line": 768,
              "docstring": "Determine if drawing requires human review.\n\nChecks multiple criteria:\n- Overall confidence below threshold (0.75)\n- Presence of critical severity flags\n- Validation report review requirement\n\nReturns:\n    True if human review is needed, False otherwise.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "bool"
              },
              "method_type": "instance"
            },
            {
              "name": "get_llm_total_cost",
              "line": 787,
              "docstring": "Calculate total LLM cost for this drawing.\n\nReturns:\n    Total cost in USD from all LLM API calls.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "float"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        },
        "ConfidenceScores": {
          "line": 802,
          "docstring": "Multi-dimensional confidence scores for routing decisions.\n\nUsed by the routing engine to determine optimal processing pipeline.\n\nAttributes:\n    ocr_quality: OCR extraction quality [0.0, 1.0].\n    entity_completeness: Entity extraction completeness [0.0, 1.0].\n    shape_detection_quality: Shape detection quality [0.0, 1.0].\n    critical_field_presence: Presence of critical fields [0.0, 1.0].\n    data_consistency: Internal data consistency [0.0, 1.0].",
          "bases": [],
          "methods": [
            {
              "name": "__post_init__",
              "line": 821,
              "docstring": "Validate confidence scores are in valid range [0.0, 1.0].",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "overall_weighted",
              "line": 834,
              "docstring": "Calculate weighted overall score for routing decisions.\n\nUses predefined weights optimized for routing:\n- OCR quality: 20%\n- Entity completeness: 35%\n- Shape detection: 25%\n- Critical fields: 15%\n- Data consistency: 5%\n\nReturns:\n    Weighted confidence score [0.0, 1.0].",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "float"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        },
        "DrawingRecord": {
          "line": 862,
          "docstring": "Complete drawing record from database.\n\nDatabase representation of a processed drawing with all related data.\n\nAttributes:\n    drawing_id: Unique identifier.\n    source_file: Original PDF filename.\n    processing_timestamp: Processing completion time.\n    pipeline_version: Software version used.\n    overall_confidence: Overall extraction confidence.\n    needs_review: Whether flagged for review.\n    status: Processing status.\n    text_blocks: All OCR text blocks.\n    entities: All extracted entities.\n    detections: All shape detections.\n    associations: All text-to-shape associations.\n    hierarchy: Assembly hierarchy (if applicable).\n    review_flags: All review flags.",
          "bases": [],
          "methods": [],
          "nested_classes": []
        },
        "DatabaseStats": {
          "line": 899,
          "docstring": "Database-wide statistics for monitoring and reporting.\n\nAttributes:\n    total_drawings: Total number of processed drawings.\n    drawings_needs_review: Number flagged for review.\n    total_entities: Total entities across all drawings.\n    total_detections: Total detections across all drawings.\n    total_llm_calls: Total LLM API calls made.\n    total_llm_cost: Total LLM cost in USD.\n    database_size_mb: Database file size in megabytes.\n    oldest_drawing: Timestamp of oldest drawing.\n    newest_drawing: Timestamp of newest drawing.",
          "bases": [],
          "methods": [],
          "nested_classes": []
        },
        "AuditEntry": {
          "line": 926,
          "docstring": "Processing audit entry for tracking and debugging.\n\nAttributes:\n    audit_id: Unique audit entry identifier.\n    drawing_id: Associated drawing identifier.\n    stage: Processing stage name.\n    status: Stage completion status.\n    duration_seconds: Stage execution time.\n    error_message: Error details (if status is error).\n    timestamp: When stage completed.",
          "bases": [],
          "methods": [],
          "nested_classes": []
        },
        "DailyCost": {
          "line": 954,
          "docstring": "Daily LLM cost aggregation.\n\nAttributes:\n    date: Date of costs.\n    total_cost: Total cost in USD for the day.\n    call_count: Number of API calls made.",
          "bases": [],
          "methods": [],
          "nested_classes": []
        },
        "TokenUsageSummary": {
          "line": 969,
          "docstring": "Aggregate token usage statistics.\n\nAttributes:\n    total_input_tokens: Sum of all input tokens.\n    total_output_tokens: Sum of all output tokens.\n    total_images: Total images processed by LLM.\n    average_input_per_call: Mean input tokens per API call.\n    average_output_per_call: Mean output tokens per API call.",
          "bases": [],
          "methods": [],
          "nested_classes": []
        },
        "CostReport": {
          "line": 988,
          "docstring": "Comprehensive LLM cost report for budget tracking.\n\nSupports the project requirement to track and limit LLM usage to\n5-10% of drawings due to budget constraints.\n\nAttributes:\n    period: Report period description.\n    start_date: Report start date.\n    end_date: Report end date.\n    total_cost: Total cost in USD.\n    total_calls: Total number of API calls.\n    cost_by_use_case: Costs broken down by use case.\n    cost_by_provider: Costs broken down by provider.\n    cost_by_model: Costs broken down by model.\n    daily_costs: Daily cost breakdown.\n    top_drawings_by_cost: Highest cost drawings (ID, cost).\n    average_cost_per_drawing: Mean cost per drawing using LLM.\n    token_usage_summary: Aggregate token statistics.",
          "bases": [],
          "methods": [],
          "nested_classes": []
        }
      },
      "functions": []
    },
    "src.drawing_intelligence.models.model_registry": {
      "file_path": "C:\\00Projects\\engineering_items_attributes_enrichment\\src\\drawing_intelligence\\models\\model_registry.py",
      "module_docstring": "Centralized model registry with canonical names and version management.\n\nThis module provides a type-safe registry for managing LLM model specifications\nacross multiple providers (OpenAI, Anthropic, Google). It supports:\n- Cost calculation with token and image-based pricing\n- Tier-based model organization for budget step-down strategies\n- Vision capability tracking\n- Model validation and lookup by canonical name or full model ID\n\nConstants:\n    TOKENS_PER_MILLION: Divisor for token cost calculations.\n    ANTHROPIC_IMAGE_TOKEN_EQUIVALENT: Estimated tokens per image for Claude models.",
      "classes": {
        "ModelProvider": {
          "line": 25,
          "docstring": "Enumeration of supported LLM providers.\n\nAttributes:\n    OPENAI: OpenAI provider (GPT models).\n    ANTHROPIC: Anthropic provider (Claude models).\n    GOOGLE: Google provider (Gemini models).",
          "bases": [
            "Enum"
          ],
          "methods": [],
          "nested_classes": []
        },
        "ModelTier": {
          "line": 39,
          "docstring": "Model cost tiers for budget step-down strategies.\n\nThese tiers enable automatic downgrading to cheaper models when budgets\nare constrained. Lower numeric values indicate lower cost and are used\nfor comparison operations in step-down logic.\n\nAttributes:\n    TIER_0_CHEAP: Lowest cost models (e.g., GPT-4o-mini, Claude Haiku).\n    TIER_1_BALANCED: Mid-tier models balancing cost and capability.\n    TIER_2_PREMIUM: Most capable and expensive models.",
          "bases": [
            "Enum"
          ],
          "methods": [],
          "nested_classes": []
        },
        "ModelSpec": {
          "line": 58,
          "docstring": "Complete specification for an LLM model.\n\nAttributes:\n    provider: The LLM provider (OpenAI, Anthropic, Google).\n    model_id: Full model identifier including version (e.g., 'gpt-4o-2024-08-06').\n    canonical_name: Short name for configuration files (e.g., 'gpt-4o').\n    tier: Cost tier for budget management.\n    supports_vision: Whether the model can process images.\n    max_tokens: Maximum output tokens supported.\n    input_cost_per_1m: Cost in USD per 1 million input tokens.\n    output_cost_per_1m: Cost in USD per 1 million output tokens.\n    image_cost: Optional cost in USD per image for explicit pricing models.",
          "bases": [],
          "methods": [
            {
              "name": "calculate_cost",
              "line": 83,
              "docstring": "Calculate total cost for a model inference request.\n\nHandles provider-specific pricing models:\n- OpenAI: Explicit per-image costs\n- Anthropic: Images counted as input token equivalents (~1600 tokens)\n- Google: Currently treated as token-only pricing\n\nArgs:\n    input_tokens: Number of input tokens consumed.\n    output_tokens: Number of output tokens generated.\n    image_count: Number of images processed.\n\nReturns:\n    Total cost in USD.\n\nExamples:\n    >>> model = ModelRegistry.get_model(\"gpt-4o\")\n    >>> cost = model.calculate_cost(2500, 800, image_count=1)\n    >>> print(f\"${cost:.4f}\")\n    $0.0382",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "input_tokens",
                    "type": "int"
                  },
                  {
                    "name": "output_tokens",
                    "type": "int"
                  },
                  {
                    "name": "image_count",
                    "type": "int"
                  }
                ],
                "return_type": "float"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        },
        "ModelRegistry": {
          "line": 127,
          "docstring": "Central registry of all supported LLM models.\n\nThis class provides a singleton-style registry for model specifications,\nenabling consistent model management across the application. All models\nare stored in the MODELS class attribute.\n\nClass Attributes:\n    MODELS: Dictionary mapping canonical names to ModelSpec instances.\n\nExamples:\n    >>> # Get a model by canonical name\n    >>> model = ModelRegistry.get_model(\"claude-3-sonnet\")\n    >>> print(model.tier)\n    ModelTier.TIER_1_BALANCED\n\n    >>> # Find all cheap vision models sorted by cost\n    >>> cheap_vision = ModelRegistry.get_models_by_tier(\n    ...     ModelTier.TIER_0_CHEAP,\n    ...     supports_vision=True,\n    ...     sort_by_cost=True\n    ... )\n\n    >>> # Get the single cheapest model for budget step-down\n    >>> fallback = ModelRegistry.get_cheapest_model(\n    ...     ModelTier.TIER_0_CHEAP,\n    ...     supports_vision=True\n    ... )",
          "bases": [],
          "methods": [
            {
              "name": "get_model",
              "line": 269,
              "docstring": "Retrieve a model specification by name or ID.\n\nSearches first by canonical name, then by full model_id if not found.\n\nArgs:\n    name: Canonical name (e.g., 'gpt-4o') or full model_id\n        (e.g., 'gpt-4o-2024-08-06').\n\nReturns:\n    ModelSpec instance matching the provided name.\n\nRaises:\n    ValueError: If the model name is not found in the registry.\n        Includes available model names in the error message.\n\nExamples:\n    >>> model = ModelRegistry.get_model(\"claude-3-haiku\")\n    >>> model = ModelRegistry.get_model(\"claude-3-haiku-20240307\")",
              "signature": {
                "parameters": [
                  {
                    "name": "cls"
                  },
                  {
                    "name": "name",
                    "type": "str"
                  }
                ],
                "return_type": "ModelSpec"
              },
              "method_type": "class"
            },
            {
              "name": "get_models_by_tier",
              "line": 305,
              "docstring": "Retrieve all models matching a specific tier and optional vision filter.\n\nArgs:\n    tier: The ModelTier to filter by.\n    supports_vision: Optional filter for vision capability.\n        If None, returns all models in the tier.\n        If True, returns only vision-capable models.\n        If False, returns only non-vision models.\n    sort_by_cost: If True, sort results by input_cost_per_1m ascending\n        (cheapest first). Useful for budget step-down strategies.\n\nReturns:\n    List of ModelSpec instances matching the criteria, optionally sorted.\n\nExamples:\n    >>> # Get all cheap models\n    >>> cheap = ModelRegistry.get_models_by_tier(ModelTier.TIER_0_CHEAP)\n\n    >>> # Get premium vision models sorted by cost\n    >>> premium_vision = ModelRegistry.get_models_by_tier(\n    ...     ModelTier.TIER_2_PREMIUM,\n    ...     supports_vision=True,\n    ...     sort_by_cost=True\n    ... )",
              "signature": {
                "parameters": [
                  {
                    "name": "cls"
                  },
                  {
                    "name": "tier",
                    "type": "ModelTier"
                  },
                  {
                    "name": "supports_vision",
                    "type": "Optional[bool]"
                  },
                  {
                    "name": "sort_by_cost",
                    "type": "bool"
                  }
                ],
                "return_type": "List[ModelSpec]"
              },
              "method_type": "class"
            },
            {
              "name": "get_cheapest_model",
              "line": 346,
              "docstring": "Get the single cheapest model in a tier for budget step-down.\n\nThis is a critical helper for the routing engine's budget management logic.\nAlways returns the model with the lowest input_cost_per_1m.\n\nArgs:\n    tier: The ModelTier to search within.\n    supports_vision: Optional filter for vision capability.\n        If None, considers all models in the tier.\n        If True, only considers vision-capable models.\n        If False, only considers non-vision models.\n\nReturns:\n    The ModelSpec with the lowest input cost matching the criteria.\n\nRaises:\n    ValueError: If no models match the specified tier and vision criteria.\n\nExamples:\n    >>> # Get cheapest model in TIER_0 for fallback\n    >>> fallback = ModelRegistry.get_cheapest_model(\n    ...     ModelTier.TIER_0_CHEAP,\n    ...     supports_vision=True\n    ... )\n    >>> print(fallback.canonical_name)\n    'gemini-1.5-flash'",
              "signature": {
                "parameters": [
                  {
                    "name": "cls"
                  },
                  {
                    "name": "tier",
                    "type": "ModelTier"
                  },
                  {
                    "name": "supports_vision",
                    "type": "Optional[bool]"
                  }
                ],
                "return_type": "ModelSpec"
              },
              "method_type": "class"
            },
            {
              "name": "validate_model_exists",
              "line": 391,
              "docstring": "Check whether a model exists in the registry.\n\nArgs:\n    name: Model canonical name or full model_id to validate.\n\nReturns:\n    True if the model exists, False otherwise.\n\nExamples:\n    >>> ModelRegistry.validate_model_exists(\"gpt-4o\")\n    True\n    >>> ModelRegistry.validate_model_exists(\"nonexistent-model\")\n    False",
              "signature": {
                "parameters": [
                  {
                    "name": "cls"
                  },
                  {
                    "name": "name",
                    "type": "str"
                  }
                ],
                "return_type": "bool"
              },
              "method_type": "class"
            }
          ],
          "nested_classes": []
        }
      },
      "functions": []
    },
    "src.drawing_intelligence.models": {
      "file_path": "C:\\00Projects\\engineering_items_attributes_enrichment\\src\\drawing_intelligence\\models\\__init__.py",
      "module_docstring": "Data models and structures.",
      "classes": {},
      "functions": []
    },
    "src.drawing_intelligence.orchestration.checkpoint_manager": {
      "file_path": "C:\\00Projects\\engineering_items_attributes_enrichment\\src\\drawing_intelligence\\orchestration\\checkpoint_manager.py",
      "module_docstring": "Dual checkpoint system for drawing processing pipeline.\n\nThis module provides checkpoint management at two levels:\n1. Intra-drawing: Save state after each processing stage within a single\n   drawing\n2. Batch: Save state periodically during batch processing of multiple\n   drawings\n\nThe checkpoint system enables graceful recovery from failures and supports\nresuming long-running operations from the last known good state.\n\nFeatures:\n    - Atomic writes with checksums for data integrity\n    - File locking for concurrent access safety\n    - Automatic checkpoint rotation and cleanup\n    - Schema versioning and migration support\n    - Optional compression for large checkpoints\n    - Retry logic for transient failures\n\nExample:\n    Basic usage for intra-drawing checkpoints::\n\n        manager = CheckpointManager(checkpoint_dir=\"./checkpoints\")\n\n        # Save checkpoint after completing a stage\n        checkpoint_id = manager.save_intra_drawing_checkpoint(\n            drawing_id=\"DWG-001\",\n            source_file=\"drawing.pdf\",\n            current_stage=ProcessingStage.OCR_EXTRACTION,\n            completed_stages=[ProcessingStage.PDF_PROCESSING],\n            intermediate_results={\"text_blocks\": 45}\n        )\n\n        # Resume from checkpoint\n        checkpoint = manager.load_intra_drawing_checkpoint(\"DWG-001\")\n        if checkpoint:\n            print(f\"Resume from: {checkpoint.current_stage}\")",
      "classes": {
        "IntraDrawingCheckpoint": {
          "line": 126,
          "docstring": "Checkpoint for a single drawing's processing state.\n\nCaptures the complete state of a drawing at a specific processing stage,\nenabling recovery if processing is interrupted. Stores both metadata\nand intermediate processing results.\n\nAttributes:\n    drawing_id: Unique identifier for the drawing.\n    source_file: Original PDF filename.\n    current_stage: The most recently completed processing stage.\n    completed_stages: List of all stages completed so far.\n    intermediate_results: Stage-specific data (OCR results, detections).\n    timestamp: UTC ISO format timestamp when checkpoint was created.\n    checkpoint_id: Unique identifier for this checkpoint instance.\n    schema_version: Checkpoint format version for future compatibility.\n    checksum: SHA256 checksum of checkpoint data for integrity.\n\nExample:\n    >>> checkpoint = IntraDrawingCheckpoint(\n    ...     drawing_id=\"DWG-001\",\n    ...     source_file=\"drawing.pdf\",\n    ...     current_stage=ProcessingStage.OCR_EXTRACTION,\n    ...     completed_stages=[ProcessingStage.PDF_PROCESSING],\n    ...     intermediate_results={\"text_blocks\": 45},\n    ...     timestamp=\"2025-11-08T10:30:00.000000+00:00\",\n    ...     checkpoint_id=\"550e8400-e29b-41d4-a716-446655440000\",\n    ...     schema_version=\"1.0\",\n    ...     checksum=\"abc123...\"\n    ... )",
          "bases": [],
          "methods": [
            {
              "name": "to_dict",
              "line": 168,
              "docstring": "Convert checkpoint to dictionary format for serialization.\n\nConverts enum values to strings to ensure JSON compatibility.\nExcludes checksum field from serialization (computed separately).\n\nReturns:\n    Dictionary representation of the checkpoint with all enums\n    converted to string values.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "Dict[str, Any]"
              },
              "method_type": "instance"
            },
            {
              "name": "from_dict",
              "line": 187,
              "docstring": "Reconstruct checkpoint from dictionary data.\n\nConverts string values back to enum types during deserialization.\nHandles schema migration for older versions.\n\nArgs:\n    data: Dictionary containing checkpoint data with string enum\n        values.\n\nReturns:\n    Reconstructed IntraDrawingCheckpoint instance.\n\nRaises:\n    ValueError: If enum conversion fails or required fields missing.",
              "signature": {
                "parameters": [
                  {
                    "name": "cls"
                  },
                  {
                    "name": "data",
                    "type": "Dict[str, Any]"
                  }
                ],
                "return_type": "'IntraDrawingCheckpoint'"
              },
              "method_type": "class"
            }
          ],
          "nested_classes": []
        },
        "BatchCheckpoint": {
          "line": 240,
          "docstring": "Checkpoint for batch processing state across multiple drawings.\n\nTracks progress through a batch of drawings, including completion status,\nfailures, and cost metrics. Enables resuming batch jobs after\ninterruptions.\n\nAttributes:\n    batch_id: Unique identifier for this batch processing run.\n    total_drawings: Total number of drawings in the batch.\n    completed_count: Number of drawings successfully processed.\n    failed_count: Number of drawings that failed processing.\n    completed_drawing_ids: List of successfully processed drawing IDs.\n    failed_drawing_ids: List of failed drawing IDs.\n    pending_drawing_ids: List of drawings not yet processed.\n    current_drawing_id: ID of drawing currently being processed (if any).\n    timestamp: UTC ISO format timestamp when checkpoint was created.\n    checkpoint_id: Unique identifier for this checkpoint instance.\n    total_llm_cost: Cumulative LLM API cost in USD for this batch.\n    average_processing_time_seconds: Mean processing time per drawing.\n    schema_version: Checkpoint format version for future compatibility.\n    checksum: SHA256 checksum of checkpoint data for integrity.",
          "bases": [],
          "methods": [
            {
              "name": "__post_init__",
              "line": 279,
              "docstring": "Validate internal consistency after initialization.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "to_dict",
              "line": 294,
              "docstring": "Convert checkpoint to dictionary format for serialization.\n\nExcludes checksum field from serialization (computed separately).\n\nReturns:\n    Dictionary representation of the checkpoint.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "Dict[str, Any]"
              },
              "method_type": "instance"
            },
            {
              "name": "from_dict",
              "line": 308,
              "docstring": "Reconstruct checkpoint from dictionary data.\n\nHandles schema migration for older versions.\n\nArgs:\n    data: Dictionary containing checkpoint data.\n\nReturns:\n    Reconstructed BatchCheckpoint instance.\n\nRaises:\n    ValueError: If required fields missing or validation fails.",
              "signature": {
                "parameters": [
                  {
                    "name": "cls"
                  },
                  {
                    "name": "data",
                    "type": "Dict[str, Any]"
                  }
                ],
                "return_type": "'BatchCheckpoint'"
              },
              "method_type": "class"
            }
          ],
          "nested_classes": []
        },
        "CheckpointManager": {
          "line": 356,
          "docstring": "Manages persistence and recovery of processing checkpoints.\n\nProvides checkpoint management at two granularities:\n- Intra-drawing: Stage-level checkpoints within a single drawing\n- Batch: Periodic checkpoints during batch processing\n\nCheckpoints are stored as JSON files (optionally compressed) in separate\nsubdirectories with automatic cleanup, file locking, checksums, and\nretry logic for robustness.\n\nAttributes:\n    checkpoint_dir: Root directory for checkpoint storage.\n    intra_drawing_dir: Subdirectory for intra-drawing checkpoints.\n    batch_dir: Subdirectory for batch checkpoints.\n    max_checkpoints_per_id: Maximum checkpoints to keep per ID.\n    checkpoint_ttl_days: Time-to-live for checkpoints in days.\n    enable_compression: Whether to compress large checkpoints.\n\nExample:\n    >>> manager = CheckpointManager(\n    ...     checkpoint_dir=\"./checkpoints\",\n    ...     max_checkpoints_per_id=5,\n    ...     checkpoint_ttl_days=7\n    ... )\n    >>> checkpoint_id = manager.save_intra_drawing_checkpoint(\n    ...     drawing_id=\"DWG-001\",\n    ...     source_file=\"drawing.pdf\",\n    ...     current_stage=ProcessingStage.OCR_EXTRACTION,\n    ...     completed_stages=[ProcessingStage.PDF_PROCESSING],\n    ...     intermediate_results={\"text_blocks\": 45}\n    ... )",
          "bases": [],
          "methods": [
            {
              "name": "__init__",
              "line": 390,
              "docstring": "Initialize the checkpoint manager.\n\nCreates the checkpoint directory structure if it doesn't exist.\n\nArgs:\n    checkpoint_dir: Root directory path for storing checkpoints.\n        If None, uses system temp directory + 'checkpoints'.\n    max_checkpoints_per_id: Maximum number of checkpoints to keep\n        per drawing_id or batch_id. Older ones are deleted.\n    checkpoint_ttl_days: Time-to-live for checkpoints in days.\n        Checkpoints older than this are cleaned up.\n    enable_compression: Enable gzip compression for large\n        checkpoints (>10KB).",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "checkpoint_dir",
                    "type": "Optional[str]"
                  },
                  {
                    "name": "max_checkpoints_per_id",
                    "type": "int"
                  },
                  {
                    "name": "checkpoint_ttl_days",
                    "type": "int"
                  },
                  {
                    "name": "enable_compression",
                    "type": "bool"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "_acquire_lock",
              "line": 429,
              "docstring": "Acquire file lock for safe concurrent access.\n\nArgs:\n    file_path: Path to the file to lock.\n\nReturns:\n    Lock context manager or dummy context if portalocker unavailable.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "file_path",
                    "type": "Path"
                  }
                ],
                "return_type": "Any"
              },
              "method_type": "instance"
            },
            {
              "name": "_atomic_write_json",
              "line": 454,
              "docstring": "Write JSON data atomically with checksum.\n\nUses a temporary file and atomic rename to ensure the checkpoint\nfile is never left in a partially written state. Computes checksum\nfor data integrity verification.\n\nArgs:\n    target_path: Destination path for the JSON file.\n    data: Dictionary to serialize as JSON.\n    compress: Whether to gzip compress the output.\n\nReturns:\n    Checksum (SHA256 hex) of the written data.\n\nRaises:\n    IOError: If file write or rename fails.\n    OSError: If permissions or disk space issues occur.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "target_path",
                    "type": "Path"
                  },
                  {
                    "name": "data",
                    "type": "Dict[str, Any]"
                  },
                  {
                    "name": "compress",
                    "type": "bool"
                  }
                ],
                "return_type": "str"
              },
              "method_type": "instance"
            },
            {
              "name": "_read_json_with_verification",
              "line": 538,
              "docstring": "Read JSON file and verify checksum.\n\nArgs:\n    file_path: Path to JSON file (may be gzipped).\n\nReturns:\n    Parsed JSON data dictionary.\n\nRaises:\n    ValueError: If checksum verification fails or invalid JSON.\n    IOError: If file cannot be read.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "file_path",
                    "type": "Path"
                  }
                ],
                "return_type": "Dict[str, Any]"
              },
              "method_type": "instance"
            },
            {
              "name": "_retry_operation",
              "line": 587,
              "docstring": "Retry an operation with exponential backoff.\n\nArgs:\n    operation: Callable to retry.\n    operation_name: Name for logging.\n\nReturns:\n    Result of the operation.\n\nRaises:\n    Exception: Re-raises last exception if all retries fail.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "operation",
                    "type": "callable"
                  },
                  {
                    "name": "operation_name",
                    "type": "str"
                  }
                ],
                "return_type": "Any"
              },
              "method_type": "instance"
            },
            {
              "name": "_cleanup_old_checkpoints",
              "line": 621,
              "docstring": "Remove old checkpoints based on TTL and max count.\n\nArgs:\n    directory: Directory to clean up.\n    id_pattern: Glob pattern for checkpoint files.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "directory",
                    "type": "Path"
                  },
                  {
                    "name": "id_pattern",
                    "type": "str"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "_extract_timestamp_from_filename",
              "line": 666,
              "docstring": "Extract timestamp from checkpoint filename.\n\nArgs:\n    filename: Checkpoint filename (without extension).\n\nReturns:\n    Timestamp string in TIMESTAMP_FORMAT.\n\nRaises:\n    ValueError: If timestamp cannot be extracted.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "filename",
                    "type": "str"
                  }
                ],
                "return_type": "str"
              },
              "method_type": "instance"
            },
            {
              "name": "_get_latest_checkpoint_path",
              "line": 691,
              "docstring": "Find latest checkpoint file by parsing embedded timestamp.\n\nArgs:\n    directory: Directory to search.\n    id_prefix: Prefix to match (drawing_id or batch_id).\n\nReturns:\n    Path to latest checkpoint file, or None if not found.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "directory",
                    "type": "Path"
                  },
                  {
                    "name": "id_prefix",
                    "type": "str"
                  }
                ],
                "return_type": "Optional[Path]"
              },
              "method_type": "instance"
            },
            {
              "name": "save_intra_drawing_checkpoint",
              "line": 732,
              "docstring": "Save checkpoint after completing a processing stage.\n\nCreates a timestamped checkpoint file containing the complete\nprocessing state. Useful for resuming drawings that crash\nmid-processing. Uses atomic writes with checksums and file locking.\nAutomatically includes current_stage in completed_stages.\n\nArgs:\n    drawing_id: Unique identifier for the drawing.\n    source_file: Original PDF filename.\n    current_stage: The stage just completed.\n    completed_stages: List of stages completed before current stage.\n    intermediate_results: Stage-specific processing results and data.\n\nReturns:\n    Unique checkpoint_id (UUID) for the saved checkpoint.\n\nRaises:\n    ValueError: If drawing_id is invalid.\n    IOError: If checkpoint file cannot be written after retries.\n\nExample:\n    >>> manager.save_intra_drawing_checkpoint(\n    ...     drawing_id=\"DWG-001\",\n    ...     source_file=\"drawing.pdf\",\n    ...     current_stage=ProcessingStage.OCR_EXTRACTION,\n    ...     completed_stages=[ProcessingStage.PDF_PROCESSING],\n    ...     intermediate_results={\"text_blocks\": 45, \"pages\": 3}\n    ... )\n    '550e8400-e29b-41d4-a716-446655440000'",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "drawing_id",
                    "type": "str"
                  },
                  {
                    "name": "source_file",
                    "type": "str"
                  },
                  {
                    "name": "current_stage",
                    "type": "ProcessingStage"
                  },
                  {
                    "name": "completed_stages",
                    "type": "List[ProcessingStage]"
                  },
                  {
                    "name": "intermediate_results",
                    "type": "Dict[str, Any]"
                  }
                ],
                "return_type": "str"
              },
              "method_type": "instance"
            },
            {
              "name": "load_intra_drawing_checkpoint",
              "line": 833,
              "docstring": "Load the most recent checkpoint for a drawing.\n\nSearches for all checkpoints matching the drawing_id and returns\nthe most recently created one based on embedded timestamp.\nVerifies checksum for data integrity.\n\nArgs:\n    drawing_id: Unique identifier for the drawing.\n\nReturns:\n    The most recent IntraDrawingCheckpoint for this drawing,\n    or None if no checkpoint exists.\n\nExample:\n    >>> checkpoint = manager.load_intra_drawing_checkpoint(\n    ...     \"DWG-001\"\n    ... )\n    >>> if checkpoint:\n    ...     print(f\"Resume from: {checkpoint.current_stage}\")",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "drawing_id",
                    "type": "str"
                  }
                ],
                "return_type": "Optional[IntraDrawingCheckpoint]"
              },
              "method_type": "instance"
            },
            {
              "name": "delete_intra_drawing_checkpoints",
              "line": 893,
              "docstring": "Delete all checkpoints for a drawing.\n\nShould be called after successful completion of drawing processing\nto clean up checkpoint files and free disk space.\n\nArgs:\n    drawing_id: Unique identifier for the drawing.\n\nExample:\n    >>> manager.delete_intra_drawing_checkpoints(\"DWG-001\")",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "drawing_id",
                    "type": "str"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "save_batch_checkpoint",
              "line": 927,
              "docstring": "Save batch processing state.\n\nCreates a checkpoint capturing the current state of batch processing,\nincluding progress, failures, and cost metrics. Typically called\nperiodically (e.g., every N drawings) or before shutdown.\nUses atomic writes with checksums and file locking.\n\nArgs:\n    batch_id: Unique identifier for this batch.\n    total_drawings: Total number of drawings in batch.\n    completed_drawing_ids: List of successfully processed drawing IDs.\n    failed_drawing_ids: List of failed drawing IDs.\n    pending_drawing_ids: List of drawings not yet processed.\n    current_drawing_id: ID of drawing currently being processed\n        (if any).\n    total_llm_cost: Cumulative LLM API cost in USD.\n    average_processing_time_seconds: Mean processing time per drawing\n        in seconds.\n\nReturns:\n    Unique checkpoint_id (UUID) for the saved checkpoint.\n\nRaises:\n    ValueError: If batch_id is invalid or data inconsistent.\n    IOError: If checkpoint file cannot be written after retries.\n\nExample:\n    >>> manager.save_batch_checkpoint(\n    ...     batch_id=\"batch_20251108\",\n    ...     total_drawings=100,\n    ...     completed_drawing_ids=[\"DWG-001\", \"DWG-002\"],\n    ...     failed_drawing_ids=[\"DWG-003\"],\n    ...     pending_drawing_ids=[\"DWG-004\", \"DWG-005\"],\n    ...     current_drawing_id=\"DWG-004\",\n    ...     total_llm_cost=1.25,\n    ...     average_processing_time_seconds=45.3\n    ... )\n    '550e8400-e29b-41d4-a716-446655440000'",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "batch_id",
                    "type": "str"
                  },
                  {
                    "name": "total_drawings",
                    "type": "int"
                  },
                  {
                    "name": "completed_drawing_ids",
                    "type": "List[str]"
                  },
                  {
                    "name": "failed_drawing_ids",
                    "type": "List[str]"
                  },
                  {
                    "name": "pending_drawing_ids",
                    "type": "List[str]"
                  },
                  {
                    "name": "current_drawing_id",
                    "type": "Optional[str]"
                  },
                  {
                    "name": "total_llm_cost",
                    "type": "float"
                  },
                  {
                    "name": "average_processing_time_seconds",
                    "type": "float"
                  }
                ],
                "return_type": "str"
              },
              "method_type": "instance"
            },
            {
              "name": "load_batch_checkpoint",
              "line": 1035,
              "docstring": "Load the most recent batch checkpoint.\n\nSearches for all checkpoints matching the batch_id and returns\nthe most recently created one based on embedded timestamp.\nVerifies checksum for data integrity.\n\nArgs:\n    batch_id: Unique identifier for the batch.\n\nReturns:\n    The most recent BatchCheckpoint for this batch,\n    or None if no checkpoint exists.\n\nExample:\n    >>> checkpoint = manager.load_batch_checkpoint(\n    ...     \"batch_20251108\"\n    ... )\n    >>> if checkpoint:\n    ...     print(f\"Resume: {checkpoint.pending_drawing_ids[0]}\")",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "batch_id",
                    "type": "str"
                  }
                ],
                "return_type": "Optional[BatchCheckpoint]"
              },
              "method_type": "instance"
            },
            {
              "name": "delete_batch_checkpoints",
              "line": 1092,
              "docstring": "Delete all checkpoints for a batch.\n\nShould be called after successful completion of batch processing\nto clean up checkpoint files and free disk space.\n\nArgs:\n    batch_id: Unique identifier for the batch.\n\nExample:\n    >>> manager.delete_batch_checkpoints(\"batch_20251108\")",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "batch_id",
                    "type": "str"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "list_available_checkpoints",
              "line": 1123,
              "docstring": "List all available checkpoints with metadata.\n\nScans both intra-drawing and batch checkpoint directories\nand returns metadata (ID, timestamp, stage) without loading\nfull checkpoint data.\n\nReturns:\n    Dictionary with two keys:\n    - 'intra_drawing': List of dicts with checkpoint metadata\n    - 'batch': List of dicts with checkpoint metadata\n\n    Each metadata dict contains:\n    - 'checkpoint_id': Full checkpoint ID\n    - 'id': Drawing ID or batch ID\n    - 'timestamp': ISO format timestamp string\n    - 'stage': Processing stage (intra-drawing only)\n    - 'file_size_bytes': Size of checkpoint file\n\nExample:\n    >>> checkpoints = manager.list_available_checkpoints()\n    >>> for cp in checkpoints['batch']:\n    ...     print(f\"{cp['id']}: {cp['timestamp']}\")",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "Dict[str, List[Dict[str, Any]]]"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        }
      },
      "functions": [
        {
          "name": "_validate_identifier",
          "line": 73,
          "docstring": "Validate that an identifier is safe (no path traversal).\n\nArgs:\n    identifier: The string to validate.\n    name: Name of the parameter (for error messages).\n\nRaises:\n    ValueError: If identifier contains unsafe characters.",
          "signature": {
            "parameters": [
              {
                "name": "identifier",
                "type": "str"
              },
              {
                "name": "name",
                "type": "str"
              }
            ],
            "return_type": "None"
          }
        },
        {
          "name": "_compute_checksum",
          "line": 98,
          "docstring": "Compute SHA256 checksum of data.\n\nArgs:\n    data: String data to checksum.\n\nReturns:\n    Hexadecimal checksum string.",
          "signature": {
            "parameters": [
              {
                "name": "data",
                "type": "str"
              }
            ],
            "return_type": "str"
          }
        },
        {
          "name": "_validate_json_structure",
          "line": 110,
          "docstring": "Validate that JSON data has required fields.\n\nArgs:\n    data: Dictionary to validate.\n    required_fields: List of required field names.\n\nRaises:\n    ValueError: If required fields are missing.",
          "signature": {
            "parameters": [
              {
                "name": "data",
                "type": "Dict[str, Any]"
              },
              {
                "name": "required_fields",
                "type": "List[str]"
              }
            ],
            "return_type": "None"
          }
        }
      ]
    },
    "src.drawing_intelligence.orchestration.pipeline_orchestrator": {
      "file_path": "C:\\00Projects\\engineering_items_attributes_enrichment\\src\\drawing_intelligence\\orchestration\\pipeline_orchestrator.py",
      "module_docstring": "Pipeline Orchestrator Module\n\nManages end-to-end workflow execution, error handling, and checkpointing.",
      "classes": {
        "OrchestratorConfig": {
          "line": 65,
          "docstring": "Configuration constants for pipeline orchestrator.",
          "bases": [],
          "methods": [],
          "nested_classes": []
        },
        "StageResult": {
          "line": 82,
          "docstring": "Result from a single processing stage.\n\nAttributes:\n    stage: The processing stage that was executed.\n    success: Whether the stage completed successfully.\n    data: Output data from the stage (type varies by stage).\n    confidence: Confidence score for this stage (0.0-1.0).\n    duration_seconds: Wall-clock execution time in seconds.\n    error_message: Error details if the stage failed.",
          "bases": [],
          "methods": [],
          "nested_classes": []
        },
        "InitialRoutingResult": {
          "line": 103,
          "docstring": "Initial processing results for routing decisions.\n\nAttributes:\n    entities: List of extracted entities.\n    detections: List of detected shapes.\n    ocr_avg_confidence: Average OCR confidence score.\n    text_block_count: Number of text blocks extracted.",
          "bases": [],
          "methods": [],
          "nested_classes": []
        },
        "DrawingResultSummary": {
          "line": 120,
          "docstring": "Lightweight summary of drawing processing results.\n\nUsed to reduce memory footprint in batch processing.\n\nAttributes:\n    drawing_id: Unique drawing identifier.\n    source_file: Path to source PDF.\n    status: Processing status (complete/failed).\n    overall_confidence: Overall confidence score.\n    needs_review: Whether human review is required.\n    llm_cost: LLM API cost for this drawing.\n    processing_time: Total processing time in seconds.\n    error_message: Error message if failed.",
          "bases": [],
          "methods": [],
          "nested_classes": []
        },
        "BatchResult": {
          "line": 147,
          "docstring": "Result from batch processing.\n\nAttributes:\n    batch_id: Unique identifier for this batch.\n    total_drawings: Total number of drawings in the batch.\n    successful: Number of successfully processed drawings.\n    failed: Number of failed drawings.\n    needs_review: Number of drawings flagged for human review.\n    success_rate: Percentage of successful drawings (0.0-1.0).\n    review_rate: Percentage requiring review (0.0-1.0).\n    total_llm_cost: Total cost of LLM API calls in USD.\n    average_processing_time: Average time per drawing in seconds.\n    drawing_summaries: List of lightweight result summaries.",
          "bases": [],
          "methods": [],
          "nested_classes": []
        },
        "PipelineOrchestrator": {
          "line": 175,
          "docstring": "Manages end-to-end workflow execution.\n\nCoordinates all processing stages, error handling, and checkpointing\nfor both single drawing and batch processing operations.\n\nAttributes:\n    config: System configuration object.\n    db: Database manager for persistence.\n    checkpoint_manager: Manages processing checkpoints.\n    routing_engine: Determines pipeline routing decisions.",
          "bases": [],
          "methods": [
            {
              "name": "__init__",
              "line": 188,
              "docstring": "Initialize pipeline orchestrator with dependency injection.\n\nArgs:\n    config: System configuration object.\n    db: Database manager instance.\n    checkpoint_manager: Checkpoint manager instance.\n    routing_engine: Routing engine instance.\n    pdf_processor: Optional PDF processor (created if None).\n    image_preprocessor: Optional image preprocessor.\n    ocr_pipeline: Optional OCR pipeline.\n    entity_extractor: Optional entity extractor.\n    shape_detector: Optional shape detector.\n    data_associator: Optional data associator.\n    data_validator: Optional data validator.\n    hierarchy_builder: Optional hierarchy builder.\n    quality_scorer: Optional quality scorer.\n    llm_gateway: Optional LLM gateway.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "config",
                    "type": "Config"
                  },
                  {
                    "name": "db",
                    "type": "DatabaseManager"
                  },
                  {
                    "name": "checkpoint_manager",
                    "type": "CheckpointManager"
                  },
                  {
                    "name": "routing_engine",
                    "type": "RoutingEngine"
                  },
                  {
                    "name": "pdf_processor",
                    "type": "Optional[PDFProcessor]"
                  },
                  {
                    "name": "image_preprocessor",
                    "type": "Optional[ImagePreprocessor]"
                  },
                  {
                    "name": "ocr_pipeline",
                    "type": "Optional[OCRPipeline]"
                  },
                  {
                    "name": "entity_extractor",
                    "type": "Optional[EntityExtractor]"
                  },
                  {
                    "name": "shape_detector",
                    "type": "Optional[ShapeDetector]"
                  },
                  {
                    "name": "data_associator",
                    "type": "Optional[DataAssociator]"
                  },
                  {
                    "name": "data_validator",
                    "type": "Optional[DataValidator]"
                  },
                  {
                    "name": "hierarchy_builder",
                    "type": "Optional[HierarchyBuilder]"
                  },
                  {
                    "name": "quality_scorer",
                    "type": "Optional[QualityScorer]"
                  },
                  {
                    "name": "llm_gateway",
                    "type": "Optional[LLMGateway]"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "_build_stage_processor_map",
              "line": 285,
              "docstring": "Build mapping of stages to processor functions.\n\nReturns:\n    Dictionary mapping ProcessingStage to processor callables.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "Dict[ProcessingStage, Callable[[Any, WorkflowState], Tuple[Any, float]]]"
              },
              "method_type": "instance"
            },
            {
              "name": "_get_pipeline_stages",
              "line": 304,
              "docstring": "Get configurable pipeline stage sequence.\n\nReturns:\n    Ordered list of processing stages.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "List[ProcessingStage]"
              },
              "method_type": "instance"
            },
            {
              "name": "process_drawing",
              "line": 328,
              "docstring": "Process a single drawing through the complete pipeline.\n\nArgs:\n    pdf_path: Path to PDF file.\n    force_llm: Force LLM enhancement regardless of routing decision.\n\nReturns:\n    ProcessingResult with all extracted data and metadata.\n\nRaises:\n    DrawingProcessingError: If processing fails.\n    PDFProcessingError: If PDF extraction fails.\n    OCRError: If OCR extraction fails.\n    ShapeDetectionError: If shape detection fails.\n    BudgetExceededException: If LLM budget is exceeded.\n    FileNotFoundError: If PDF file doesn't exist.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "pdf_path",
                    "type": "str"
                  },
                  {
                    "name": "force_llm",
                    "type": "bool"
                  }
                ],
                "return_type": "ProcessingResult"
              },
              "method_type": "instance"
            },
            {
              "name": "process_batch",
              "line": 471,
              "docstring": "Process multiple drawings with parallelization and checkpointing.\n\nArgs:\n    pdf_paths: List of PDF file paths to process.\n    batch_id: Optional batch identifier. Generated if not provided.\n    parallel_workers: Number of parallel worker threads.\n    checkpoint_every_n: Save checkpoint every N drawings.\n\nReturns:\n    BatchResult with aggregated statistics and summaries.\n\nRaises:\n    ValueError: If pdf_paths is empty.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "pdf_paths",
                    "type": "List[str]"
                  },
                  {
                    "name": "batch_id",
                    "type": "Optional[str]"
                  },
                  {
                    "name": "parallel_workers",
                    "type": "int"
                  },
                  {
                    "name": "checkpoint_every_n",
                    "type": "int"
                  }
                ],
                "return_type": "BatchResult"
              },
              "method_type": "instance"
            },
            {
              "name": "resume_batch",
              "line": 629,
              "docstring": "Resume a previously interrupted batch from checkpoint.\n\nArgs:\n    batch_id: Batch identifier for the checkpoint to resume.\n\nReturns:\n    BatchResult for the resumed batch processing.\n\nRaises:\n    ValueError: If no checkpoint exists for the batch_id.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "batch_id",
                    "type": "str"
                  }
                ],
                "return_type": "BatchResult"
              },
              "method_type": "instance"
            },
            {
              "name": "_process_stage_with_retry",
              "line": 663,
              "docstring": "Execute stage with retry logic and exponential backoff.\n\nArgs:\n    stage: Processing stage to execute.\n    input_data: Input data for the stage.\n    state: Current workflow state.\n\nReturns:\n    StageResult from successful execution or final retry attempt.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "stage",
                    "type": "ProcessingStage"
                  },
                  {
                    "name": "input_data",
                    "type": "Union[str, Any, Dict[str, Any]]"
                  },
                  {
                    "name": "state",
                    "type": "WorkflowState"
                  }
                ],
                "return_type": "StageResult"
              },
              "method_type": "instance"
            },
            {
              "name": "_process_stage",
              "line": 720,
              "docstring": "Execute a single processing stage using processor map.\n\nArgs:\n    stage: Processing stage to execute.\n    input_data: Input data for the stage.\n    state: Current workflow state.\n\nReturns:\n    StageResult with stage output.\n\nRaises:\n    ValueError: If stage is not in processor map.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "stage",
                    "type": "ProcessingStage"
                  },
                  {
                    "name": "input_data",
                    "type": "Union[str, Any, Dict[str, Any]]"
                  },
                  {
                    "name": "state",
                    "type": "WorkflowState"
                  }
                ],
                "return_type": "StageResult"
              },
              "method_type": "instance"
            },
            {
              "name": "_process_pdf_extraction",
              "line": 802,
              "docstring": "Process PDF extraction stage.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "input_data",
                    "type": "str"
                  },
                  {
                    "name": "state",
                    "type": "WorkflowState"
                  }
                ],
                "return_type": "Tuple[Any, float]"
              },
              "method_type": "instance"
            },
            {
              "name": "_process_image_preprocessing",
              "line": 809,
              "docstring": "Process image preprocessing for multiple pages.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "input_data",
                    "type": "Any"
                  },
                  {
                    "name": "state",
                    "type": "WorkflowState"
                  }
                ],
                "return_type": "Tuple[Dict[str, Any], float]"
              },
              "method_type": "instance"
            },
            {
              "name": "_process_ocr_extraction",
              "line": 838,
              "docstring": "Process OCR extraction stage.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "input_data",
                    "type": "Any"
                  },
                  {
                    "name": "state",
                    "type": "WorkflowState"
                  }
                ],
                "return_type": "Tuple[OCRResult, float]"
              },
              "method_type": "instance"
            },
            {
              "name": "_process_entity_extraction",
              "line": 845,
              "docstring": "Process entity extraction stage.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "input_data",
                    "type": "OCRResult"
                  },
                  {
                    "name": "state",
                    "type": "WorkflowState"
                  }
                ],
                "return_type": "Tuple[Any, float]"
              },
              "method_type": "instance"
            },
            {
              "name": "_process_shape_detection",
              "line": 853,
              "docstring": "Process shape detection stage.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "input_data",
                    "type": "Any"
                  },
                  {
                    "name": "state",
                    "type": "WorkflowState"
                  }
                ],
                "return_type": "Tuple[DetectionResult, float]"
              },
              "method_type": "instance"
            },
            {
              "name": "_process_data_association",
              "line": 860,
              "docstring": "Process data association stage.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "input_data",
                    "type": "Dict[str, Any]"
                  },
                  {
                    "name": "state",
                    "type": "WorkflowState"
                  }
                ],
                "return_type": "Tuple[List[Any], float]"
              },
              "method_type": "instance"
            },
            {
              "name": "_process_data_validation",
              "line": 869,
              "docstring": "Process data validation stage.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "input_data",
                    "type": "Dict[str, Any]"
                  },
                  {
                    "name": "state",
                    "type": "WorkflowState"
                  }
                ],
                "return_type": "Tuple[Any, float]"
              },
              "method_type": "instance"
            },
            {
              "name": "_process_hierarchy_building",
              "line": 881,
              "docstring": "Process hierarchy building stage.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "input_data",
                    "type": "Dict[str, Any]"
                  },
                  {
                    "name": "state",
                    "type": "WorkflowState"
                  }
                ],
                "return_type": "Tuple[Any, float]"
              },
              "method_type": "instance"
            },
            {
              "name": "_prepare_stage_input",
              "line": 890,
              "docstring": "Prepare input data for a given stage.\n\nArgs:\n    stage: Stage to prepare input for.\n    state: Current workflow state.\n\nReturns:\n    Appropriate input data for the stage.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "stage",
                    "type": "ProcessingStage"
                  },
                  {
                    "name": "state",
                    "type": "WorkflowState"
                  }
                ],
                "return_type": "Any"
              },
              "method_type": "instance"
            },
            {
              "name": "_update_state_from_stage",
              "line": 930,
              "docstring": "Update workflow state with stage results.\n\nArgs:\n    stage: Completed stage.\n    stage_result: Result from the stage.\n    state: Workflow state to update.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "stage",
                    "type": "ProcessingStage"
                  },
                  {
                    "name": "stage_result",
                    "type": "StageResult"
                  },
                  {
                    "name": "state",
                    "type": "WorkflowState"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "_determine_route",
              "line": 960,
              "docstring": "Determine routing decision for LLM enhancement.\n\nArgs:\n    state: Current workflow state.\n    force_llm: Whether to force LLM enhancement.\n    drawing_id: Drawing identifier.\n    pdf_path: Path to PDF file.\n\nReturns:\n    ProcessingRoute with pipeline decision.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "state",
                    "type": "WorkflowState"
                  },
                  {
                    "name": "force_llm",
                    "type": "bool"
                  },
                  {
                    "name": "drawing_id",
                    "type": "str"
                  },
                  {
                    "name": "pdf_path",
                    "type": "str"
                  }
                ],
                "return_type": "ProcessingRoute"
              },
              "method_type": "instance"
            },
            {
              "name": "_handle_stage_failure",
              "line": 986,
              "docstring": "Handle stage failure by raising appropriate exception.\n\nArgs:\n    stage: Failed stage.\n    stage_result: Stage result with error.\n    state: Current workflow state.\n\nRaises:\n    PDFProcessingError: For PDF extraction failures.\n    OCRError: For OCR extraction failures.\n    ShapeDetectionError: For shape detection failures.\n    DrawingProcessingError: For other stage failures.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "stage",
                    "type": "ProcessingStage"
                  },
                  {
                    "name": "stage_result",
                    "type": "StageResult"
                  },
                  {
                    "name": "state",
                    "type": "WorkflowState"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "_apply_llm_enhancement",
              "line": 1024,
              "docstring": "Apply LLM enhancement to low-confidence results.\n\nProcesses specified stages with LLM assistance based on the routing\ndecision. Supports OCR verification, entity extraction, and shape\nlabeling.\n\nArgs:\n    state: Workflow state containing current results. Modified\n        in-place with LLM-enhanced data.\n    route: Routing decision specifying which stages need LLM\n        enhancement.\n\nNote:\n    - Checks budget before each LLM call\n    - Catches BudgetExceededException and continues with baseline\n    - Marks drawing for review if LLM enhancement fails\n    - Only processes text blocks below confidence threshold",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "state",
                    "type": "WorkflowState"
                  },
                  {
                    "name": "route",
                    "type": "ProcessingRoute"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "_apply_llm_ocr_verification",
              "line": 1087,
              "docstring": "Apply LLM OCR verification to low-confidence text blocks.\n\nArgs:\n    state: Workflow state with OCR results to verify.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "state",
                    "type": "WorkflowState"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "_apply_llm_entity_extraction",
              "line": 1135,
              "docstring": "Apply LLM entity extraction for missing critical fields.\n\nArgs:\n    state: Workflow state with entity extraction results.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "state",
                    "type": "WorkflowState"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "_apply_llm_shape_labeling",
              "line": 1180,
              "docstring": "Apply LLM shape labeling/validation.\n\nArgs:\n    state: Workflow state with shape detection results.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "state",
                    "type": "WorkflowState"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "_should_retry",
              "line": 1234,
              "docstring": "Determine if a failed stage should be retried.\n\nEvaluates the error type and current attempt count to decide\nwhether to retry the failed operation. Only retriable errors\n(e.g., transient network issues, database locks) are retried.\n\nArgs:\n    error: Exception that occurred during processing.\n    attempt: Current attempt number (1-indexed).\n\nReturns:\n    True if the operation should be retried, False otherwise.\n\nNote:\n    Always returns False if attempt >= max_retries or if the error\n    is not classified as retriable.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "error",
                    "type": "Exception"
                  },
                  {
                    "name": "attempt",
                    "type": "int"
                  }
                ],
                "return_type": "bool"
              },
              "method_type": "instance"
            },
            {
              "name": "_handle_stage_error",
              "line": 1264,
              "docstring": "Log and handle stage processing errors.\n\nCreates a structured error log entry with context information about\nthe failed stage, drawing, and error details.\n\nArgs:\n    stage: Processing stage that failed.\n    error: Exception that was raised during processing.\n    state: Current workflow state containing drawing context.\n\nNote:\n    Does not raise exceptions; only logs for audit purposes.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "stage",
                    "type": "ProcessingStage"
                  },
                  {
                    "name": "error",
                    "type": "Exception"
                  },
                  {
                    "name": "state",
                    "type": "WorkflowState"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "_create_processing_result",
              "line": 1290,
              "docstring": "Create ProcessingResult from accumulated workflow state.\n\nAssembles all processing artifacts from the workflow state into a\ncomplete ProcessingResult object for storage and analysis.\n\nArgs:\n    state: Workflow state containing all processing results.\n\nReturns:\n    ProcessingResult with all available data. Some fields\n    (confidence_scores, review_flags, completeness_score) are\n    initially None and populated by the quality scorer.\n\nNote:\n    Sets pipeline_type to BASELINE_ONLY initially; updated by\n    routing logic. Status defaults to \"complete\" unless explicitly\n    changed by error handling.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "state",
                    "type": "WorkflowState"
                  }
                ],
                "return_type": "ProcessingResult"
              },
              "method_type": "instance"
            },
            {
              "name": "_create_mock_drawing",
              "line": 1332,
              "docstring": "Create a minimal Drawing object for routing decisions.\n\nConstructs a lightweight Drawing object with default values, used\nby the routing engine to make pipeline selection decisions before\nfull processing completes.\n\nArgs:\n    drawing_id: Unique identifier for the drawing.\n    pdf_path: File path to the source PDF.\n\nReturns:\n    Drawing object with medium priority and empty metadata.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "drawing_id",
                    "type": "str"
                  },
                  {
                    "name": "pdf_path",
                    "type": "str"
                  }
                ],
                "return_type": "Drawing"
              },
              "method_type": "instance"
            },
            {
              "name": "_create_initial_result",
              "line": 1353,
              "docstring": "Create initial result object for routing decisions.\n\nBuilds a simple result object containing early-stage metrics used\nby the routing engine to determine whether LLM enhancement is\nneeded.\n\nArgs:\n    state: Current workflow state with OCR and entity extraction\n        results.\n\nReturns:\n    InitialRoutingResult with attributes: entities, detections,\n    ocr_avg_confidence, text_block_count. Returns default values\n    (empty lists, 0.0) for missing data.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "state",
                    "type": "WorkflowState"
                  }
                ],
                "return_type": "InitialRoutingResult"
              },
              "method_type": "instance"
            },
            {
              "name": "_process_drawing_safe",
              "line": 1380,
              "docstring": "Process drawing with error handling for batch processing.\n\nWraps process_drawing() with exception handling to ensure batch\nprocessing continues even if individual drawings fail. Creates a\nminimal failed result instead of propagating exceptions.\n\nArgs:\n    pdf_path: Path to the PDF file to process.\n    batch_id: Identifier for the current batch (for logging\n        context).\n\nReturns:\n    ProcessingResult with status='complete' on success or\n    status='failed' with error_message on failure.\n\nNote:\n    Never raises exceptions; always returns a ProcessingResult\n    object.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "pdf_path",
                    "type": "str"
                  },
                  {
                    "name": "batch_id",
                    "type": "str"
                  }
                ],
                "return_type": "ProcessingResult"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        }
      },
      "functions": []
    },
    "src.drawing_intelligence.orchestration.routing_engine": {
      "file_path": "C:\\00Projects\\engineering_items_attributes_enrichment\\src\\drawing_intelligence\\orchestration\\routing_engine.py",
      "module_docstring": "Routing engine with multi-dimensional confidence assessment.\n\nThis module implements intelligent pipeline routing between baseline (open-source only),\nhybrid (selective LLM), and full LLM-enhanced processing paths based on multi-dimensional\nconfidence scoring with critical PART_NUMBER field validation.",
      "classes": {
        "ConfidenceScores": {
          "line": 34,
          "docstring": "Multi-dimensional confidence assessment for routing decisions.\n\nAll scores must be in range [0.0, 1.0]. Weights for overall_weighted()\nare validated to sum to 1.0 with floating-point tolerance.\n\nAttributes:\n    ocr_quality: OCR confidence score (0.0-1.0).\n    entity_completeness: Entity extraction completeness weighted by importance (0.0-1.0).\n    shape_detection_quality: Shape detection confidence score (0.0-1.0).\n    critical_field_presence: PART_NUMBER presence and confidence (0.0-1.0).\n    data_consistency: Cross-validation consistency score (0.0-1.0).\n    weights: Dimension weights for overall score calculation (must sum to 1.0).",
          "bases": [],
          "methods": [
            {
              "name": "__post_init__",
              "line": 59,
              "docstring": "Validate score ranges and weight sum.\n\nArgs:\n    weights: Optional custom weights dict. If None, uses default weights.\n\nRaises:\n    ValueError: If any score is outside [0.0, 1.0] or weights don't sum to 1.0.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "weights",
                    "type": "Optional[Dict[str, float]]"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "overall_weighted",
              "line": 104,
              "docstring": "Calculate weighted overall score for routing decisions.\n\nDefault weights:\n    - Entity completeness: 35% (highest priority)\n    - Shape detection: 25%\n    - OCR quality: 20%\n    - Critical field: 15%\n    - Data consistency: 5%\n\nReturns:\n    Weighted confidence score from 0.0 to 1.0.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "float"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        },
        "ProcessingRoute": {
          "line": 127,
          "docstring": "Pipeline routing decision with cost estimation.\n\nAttributes:\n    pipeline: Selected pipeline type (baseline/hybrid/LLM-enhanced).\n    llm_stages: List of stages requiring LLM enhancement.\n    reason: Standardized explanation code for routing decision.\n    reason_detail: Human-readable explanation with context.\n    estimated_cost: Estimated USD cost for LLM calls.\n    confidence_scores: Optional multi-dimensional confidence breakdown.\n    forced_by_critical_field: Flag indicating critical field gate triggered decision.",
          "bases": [],
          "methods": [],
          "nested_classes": []
        },
        "RoutingEngine": {
          "line": 149,
          "docstring": "Intelligent routing engine for pipeline selection based on confidence assessment.\n\nDetermines optimal processing path (baseline/hybrid/LLM-enhanced) using\nmulti-dimensional confidence scoring with critical field validation. Enforces\nPART_NUMBER gate and budget constraints per project requirements.\n\nAttributes:\n    config: System configuration containing routing thresholds and sampling rates.\n    budget: Budget controller for cost tracking and LLM call authorization.\n    rng: NumPy random generator for reproducible sampling.\n    entity_weights: Importance weights for entity completeness calculation.\n    confidence_weights: Weights for overall confidence calculation.\n    part_number_min_confidence: Minimum confidence threshold for PART_NUMBER.\n    overall_threshold_high: Confidence threshold for baseline-only processing.\n    overall_threshold_medium: Confidence threshold for hybrid processing.\n    missing_entity_partial_credit: Credit factor for missing non-critical entities.\n    ocr_text_block_norm: Normalization factor for text block count.\n    ocr_confidence_weight: Weight for OCR confidence in quality assessment.\n    shape_count_norm: Normalization factor for shape detection count.\n    shape_confidence_weight: Weight for shape confidence in quality assessment.\n\nExample:\n    >>> config = SystemConfig.load()\n    >>> budget = BudgetController(config)\n    >>> engine = RoutingEngine(config, budget, random_seed=42)\n    >>> route = engine.determine_route(drawing, processing_result)\n    >>> print(f\"Pipeline: {route.pipeline.value}, Reason: {route.reason}\")",
          "bases": [],
          "methods": [
            {
              "name": "__init__",
              "line": 179,
              "docstring": "Initialize routing engine with configuration and budget controller.\n\nArgs:\n    config: System configuration object containing routing parameters.\n    budget_controller: Budget controller for LLM cost management.\n    random_seed: Optional random seed for reproducible sampling (for testing).\n\nRaises:\n    ValueError: If required config sections are missing or invalid.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "config",
                    "type": "SystemConfig"
                  },
                  {
                    "name": "budget_controller",
                    "type": "BudgetController"
                  },
                  {
                    "name": "random_seed",
                    "type": "Optional[int]"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "determine_route",
              "line": 267,
              "docstring": "Evaluate processing result and determine optimal pipeline routing.\n\nWorkflow:\n1. Validate inputs\n2. Calculate all confidence dimensions\n3. Apply routing rules (including critical field gate)\n4. Reserve budget if LLM path selected\n\nArgs:\n    drawing: Drawing record containing ID and priority information.\n    initial_result: Baseline processing result with entities and detections.\n\nReturns:\n    ProcessingRoute object specifying pipeline type, LLM stages, reasoning,\n    and cost estimate.\n\nRaises:\n    ValueError: If inputs are invalid.\n    RuntimeError: If budget controller fails.\n\nExample:\n    >>> result = ProcessingResult(entities=[...], detections=[...], ...)\n    >>> route = engine.determine_route(drawing, result)\n    >>> if route.forced_by_critical_field:\n    ...     logger.warning(\"Critical field issue: %s\", route.reason_detail)",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "drawing",
                    "type": "DrawingRecord"
                  },
                  {
                    "name": "initial_result",
                    "type": "ProcessingResult"
                  }
                ],
                "return_type": "ProcessingRoute"
              },
              "method_type": "instance"
            },
            {
              "name": "_validate_inputs",
              "line": 397,
              "docstring": "Validate input parameters for routing decision.\n\nArgs:\n    drawing: Drawing record to validate.\n    result: Processing result to validate.\n\nRaises:\n    ValueError: If inputs are missing required attributes or invalid.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "drawing",
                    "type": "DrawingRecord"
                  },
                  {
                    "name": "result",
                    "type": "ProcessingResult"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "_check_part_number",
              "line": 433,
              "docstring": "Check PART_NUMBER entity presence and confidence level.\n\nArgs:\n    entities: List of extracted entities to search.\n\nReturns:\n    Dictionary containing:\n        - 'exists': bool indicating if PART_NUMBER was found\n        - 'confidence': float score (0.0 if not found)\n        - 'value': str value of part number or None\n\nExample:\n    >>> result = self._check_part_number(entities)\n    >>> if result['exists'] and result['confidence'] >= 0.70:\n    ...     print(f\"Valid part number: {result['value']}\")",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "entities",
                    "type": "List[Entity]"
                  }
                ],
                "return_type": "Dict[str, Any]"
              },
              "method_type": "instance"
            },
            {
              "name": "_assess_entity_completeness",
              "line": 472,
              "docstring": "Calculate entity completeness score using weighted importance.\n\nEvaluates presence and confidence of expected entity types using\npredefined importance weights (PART_NUMBER: 0.40, OEM: 0.15, etc.).\nMissing critical entities receive zero points; missing optional entities\nreceive partial credit (configurable, default 0.3 * weight).\n\nArgs:\n    entities: List of extracted entities.\n\nReturns:\n    Float score from 0.0 (no entities) to 1.0 (all critical entities\n    present with high confidence).",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "entities",
                    "type": "List[Entity]"
                  }
                ],
                "return_type": "float"
              },
              "method_type": "instance"
            },
            {
              "name": "_assess_ocr_quality",
              "line": 528,
              "docstring": "Assess OCR quality based on confidence and text block density.\n\nArgs:\n    result: Processing result containing OCR metrics.\n\nReturns:\n    Float score from 0.0 to 1.0 combining average confidence (default 70%)\n    and text block count normalized (default 30%).",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "result",
                    "type": "ProcessingResult"
                  }
                ],
                "return_type": "float"
              },
              "method_type": "instance"
            },
            {
              "name": "_assess_shape_quality",
              "line": 549,
              "docstring": "Assess shape detection quality from detection results.\n\nArgs:\n    detections: List of shape detections.\n\nReturns:\n    Float score from 0.0 to 1.0 combining average confidence (default 80%)\n    and detection count normalized (default 20%).",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "detections",
                    "type": "List[Detection]"
                  }
                ],
                "return_type": "float"
              },
              "method_type": "instance"
            },
            {
              "name": "_validate_data_consistency",
              "line": 570,
              "docstring": "Cross-validate data consistency across processing results.\n\nSimplified implementation checking for presence of complementary data types.\nFull implementation would validate entity-shape associations, dimension\ncompatibility, and orphaned entities.\n\nArgs:\n    result: Processing result to validate.\n\nReturns:\n    Float score: 0.9 (all data types present), 0.7 (text + entities),\n    or 0.5 (incomplete data).\n\nNote:\n    This is a placeholder. Production implementation should perform\n    actual cross-validation of entity-shape associations.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "result",
                    "type": "ProcessingResult"
                  }
                ],
                "return_type": "float"
              },
              "method_type": "instance"
            },
            {
              "name": "_apply_routing_rules",
              "line": 599,
              "docstring": "Apply decision tree for pipeline routing based on confidence dimensions.\n\nRouting logic (priority order):\n1. Missing PART_NUMBER \u2192 Force LLM (if budget + not LOW priority)\n2. Low PART_NUMBER confidence \u2192 Hybrid LLM verification\n3. High overall confidence (\u22650.85) + high critical field (\u22650.9) \u2192 Baseline\n4. Low entity completeness (<0.75) \u2192 Hybrid entity extraction\n5. Poor OCR (<0.85) + poor entities (<0.80) \u2192 Hybrid OCR + entity\n6. Medium confidence (0.70-0.85) \u2192 Hybrid on weakest dimension\n7. Fallback \u2192 Baseline (budget exhausted or low sampling)\n\nArgs:\n    scores: Multi-dimensional confidence scores.\n    overall_score: Weighted overall confidence score.\n    drawing: Drawing record for priority/sampling checks.\n    part_number_check: PART_NUMBER validation results.\n\nReturns:\n    ProcessingRoute with pipeline decision and rationale.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "scores",
                    "type": "ConfidenceScores"
                  },
                  {
                    "name": "overall_score",
                    "type": "float"
                  },
                  {
                    "name": "drawing",
                    "type": "DrawingRecord"
                  },
                  {
                    "name": "part_number_check",
                    "type": "Dict[str, Any]"
                  }
                ],
                "return_type": "ProcessingRoute"
              },
              "method_type": "instance"
            },
            {
              "name": "_identify_weakest_stage",
              "line": 784,
              "docstring": "Identify processing stage that would benefit most from LLM enhancement.\n\nConsiders all five confidence dimensions and maps to appropriate\nprocessing stage. Uses deterministic tie-breaking (alphabetical by dimension name).\n\nArgs:\n    scores: Multi-dimensional confidence scores.\n\nReturns:\n    ProcessingStage enum corresponding to weakest confidence dimension.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "scores",
                    "type": "ConfidenceScores"
                  }
                ],
                "return_type": "ProcessingStage"
              },
              "method_type": "instance"
            },
            {
              "name": "_budget_available",
              "line": 824,
              "docstring": "Check if budget allows additional LLM calls.\n\nReturns:\n    True if remaining budget > 0, False otherwise.\n\nRaises:\n    RuntimeError: If budget controller query fails.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "bool"
              },
              "method_type": "instance"
            },
            {
              "name": "_sampling_criteria_met",
              "line": 844,
              "docstring": "Determine if drawing meets sampling criteria for LLM enhancement.\n\nUses numpy random generator for reproducible sampling (testing).\n\nArgs:\n    drawing: Drawing record (used for future priority-based sampling).\n\nReturns:\n    True if random sample falls within sampling rate threshold.\n\nNote:\n    Currently implements simple random sampling. Future enhancement:\n    stratified sampling by drawing priority/complexity.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "drawing",
                    "type": "DrawingRecord"
                  }
                ],
                "return_type": "bool"
              },
              "method_type": "instance"
            },
            {
              "name": "_estimate_cost",
              "line": 872,
              "docstring": "Estimate USD cost for given LLM processing stages.\n\nQueries BudgetController for dynamic, up-to-date pricing based on\nconfigured models and current provider rates.\n\nArgs:\n    stages: List of processing stages requiring LLM calls.\n\nReturns:\n    Estimated total cost in USD.\n\nRaises:\n    RuntimeError: If cost estimation fails.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "stages",
                    "type": "List[ProcessingStage]"
                  }
                ],
                "return_type": "float"
              },
              "method_type": "instance"
            },
            {
              "name": "_reserve_budget",
              "line": 923,
              "docstring": "Reserve budget for upcoming LLM calls.\n\nArgs:\n    cost: Amount to reserve in USD.\n    drawing_id: Drawing identifier for audit logging.\n\nRaises:\n    RuntimeError: If budget reservation fails or insufficient funds.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "cost",
                    "type": "float"
                  },
                  {
                    "name": "drawing_id",
                    "type": "str"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        },
        "MockBudget": {
          "line": 972,
          "docstring": "Mock budget controller for testing.",
          "bases": [],
          "methods": [
            {
              "name": "get_usage_summary",
              "line": 977,
              "docstring": "Return mock usage summary.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "Dict[str, float]"
              },
              "method_type": "instance"
            },
            {
              "name": "estimate_stage_cost",
              "line": 981,
              "docstring": "Return mock stage cost.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "stage",
                    "type": "ProcessingStage"
                  }
                ],
                "return_type": "float"
              },
              "method_type": "instance"
            },
            {
              "name": "reserve_budget",
              "line": 990,
              "docstring": "Mock budget reservation.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "cost",
                    "type": "float"
                  },
                  {
                    "name": "drawing_id",
                    "type": "str"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        },
        "MockConfig": {
          "line": 997,
          "docstring": "Mock config for testing.",
          "bases": [],
          "methods": [
            {
              "name": "get",
              "line": 1000,
              "docstring": "Get config value with default.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "key",
                    "type": "str"
                  },
                  {
                    "name": "default",
                    "type": "Any"
                  }
                ],
                "return_type": "Any"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        }
      },
      "functions": [
        {
          "name": "dataclass_replace",
          "line": 952,
          "docstring": "Helper function to replace fields in frozen dataclass.\n\nArgs:\n    obj: Frozen dataclass instance.\n    changes: Fields to update.\n\nReturns:\n    New dataclass instance with updated fields.",
          "signature": {
            "parameters": [
              {
                "name": "obj"
              }
            ],
            "return_type": null
          }
        }
      ]
    },
    "src.drawing_intelligence.orchestration.workflow_state": {
      "file_path": "C:\\00Projects\\engineering_items_attributes_enrichment\\src\\drawing_intelligence\\orchestration\\workflow_state.py",
      "module_docstring": "Workflow state management for drawing processing pipeline.\n\nThis module provides the WorkflowState dataclass for tracking the current\nstate of a drawing as it progresses through the processing pipeline. It\nmaintains stage information, metadata, checkpoint data, and confidence scores.\n\nTypical usage example:\n    state = WorkflowState(\n        drawing_id=\"DWG-001\",\n        current_stage=ProcessingStage.OCR_EXTRACTION\n    )\n    state.update_stage(ProcessingStage.ENTITY_EXTRACTION)\n    state.save_checkpoint({\"entities_extracted\": 42})\n\nAuthor: GROK AI + Sandeep A (01Nov2025)\nReviewed and refactored: Claude (Nov 2025)",
      "classes": {
        "WorkflowStatus": {
          "line": 27,
          "docstring": "Status values for workflow state lifecycle.\n\nAttributes:\n    INITIALIZED: Workflow created but not yet started.\n    PROCESSING: Actively processing through pipeline stages.\n    PAUSED: Processing temporarily suspended.\n    COMPLETED: Successfully completed all stages.\n    FAILED: Processing failed and cannot continue.",
          "bases": [
            "Enum"
          ],
          "methods": [],
          "nested_classes": []
        },
        "WorkflowState": {
          "line": 46,
          "docstring": "Manages the state of a drawing's processing pipeline.\n\nThis dataclass tracks the current processing stage, metadata, checkpoint\ndata, and confidence scores for a single drawing as it moves through\nthe pipeline. It provides methods to update the stage and save checkpoint\ndata for recovery and monitoring purposes.\n\nCheckpoint data is namespaced by stage to prevent collisions and simplify\nrecovery. Stage transitions are validated to ensure proper pipeline flow.\n\nAttributes:\n    drawing_id: Unique identifier for the drawing (e.g., \"DWG-001\").\n    current_stage: Current processing stage from ProcessingStage enum.\n    metadata: Drawing-level metadata. Expected keys:\n        - source_file: Path to source PDF file\n        - file_size: File size in bytes\n        - page_count: Number of pages in drawing\n    checkpoint_data: Stage-specific checkpoint data, keyed by stage name.\n    timestamp: Last update timestamp (UTC).\n    confidence_scores: Confidence scores by stage or metric name.\n    is_running: Whether processing is currently active.\n    status: Current workflow status from WorkflowStatus enum.\n    schema_version: Schema version for serialization compatibility.\n    stage_history: List of (stage, timestamp) tuples tracking progression.\n    error_history: List of error messages from failed operations.",
          "bases": [],
          "methods": [
            {
              "name": "__post_init__",
              "line": 105,
              "docstring": "Validate initial state after dataclass initialization.\n\nRaises:\n    ValueError: If drawing_id is empty or invalid format.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "__repr__",
              "line": 123,
              "docstring": "Concise string representation for debugging.\n\nReturns:\n    String showing key state information.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "str"
              },
              "method_type": "instance"
            },
            {
              "name": "update_stage",
              "line": 135,
              "docstring": "Update the current processing stage with validation.\n\nUpdates the workflow to a new processing stage, validates that the\ntransition is allowed according to the pipeline flow, and refreshes\nthe timestamp to the current time. Adds the stage transition to the\nstage history for audit purposes.\n\nArgs:\n    stage: The new ProcessingStage to transition to.\n\nRaises:\n    ValueError: If stage is not a valid ProcessingStage enum value\n        or if the transition is not allowed.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "stage",
                    "type": "ProcessingStage"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "save_checkpoint",
              "line": 168,
              "docstring": "Save checkpoint data for the current stage.\n\nStores the provided checkpoint data under the current stage's namespace\nto prevent key collisions across stages. This allows for stage-specific\nrecovery and simplifies debugging. Updates the timestamp to reflect\nthe checkpoint save time.\n\nArgs:\n    data: Dictionary of checkpoint data to save for the current stage.\n\nRaises:\n    ValueError: If data is None or empty.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "data",
                    "type": "Dict[str, Any]"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "mark_running",
              "line": 193,
              "docstring": "Mark the workflow as currently running.\n\nSets is_running to True and updates status to PROCESSING.\nUpdates the timestamp to the current time.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "mark_paused",
              "line": 203,
              "docstring": "Mark the workflow as paused.\n\nSets is_running to False and updates status to PAUSED.\nUpdates the timestamp to the current time.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "mark_completed",
              "line": 213,
              "docstring": "Mark the workflow as completed.\n\nSets is_running to False and updates status to COMPLETED.\nUpdates the timestamp to the current time.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "mark_failed",
              "line": 223,
              "docstring": "Mark the workflow as failed and record the error.\n\nSets is_running to False, updates status to FAILED, and appends\nthe error message to the error history for debugging. Stores\nthe error in checkpoint data for the current stage.\n\nArgs:\n    error_message: Description of the failure reason.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "error_message",
                    "type": "str"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "to_dict",
              "line": 245,
              "docstring": "Serialize workflow state to dictionary.\n\nConverts the workflow state to a dictionary suitable for JSON\nserialization or database storage. Handles enum and datetime\nconversions automatically.\n\nReturns:\n    Dictionary representation of the workflow state.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "Dict[str, Any]"
              },
              "method_type": "instance"
            },
            {
              "name": "from_dict",
              "line": 272,
              "docstring": "Deserialize workflow state from dictionary.\n\nReconstructs a WorkflowState instance from a dictionary, typically\nloaded from a checkpoint or database. Handles enum and datetime\nconversions automatically.\n\nArgs:\n    data: Dictionary representation of workflow state.\n\nReturns:\n    Reconstructed WorkflowState instance.\n\nRaises:\n    ValueError: If required fields are missing or invalid.",
              "signature": {
                "parameters": [
                  {
                    "name": "cls"
                  },
                  {
                    "name": "data",
                    "type": "Dict[str, Any]"
                  }
                ],
                "return_type": "'WorkflowState'"
              },
              "method_type": "class"
            }
          ],
          "nested_classes": []
        }
      },
      "functions": []
    },
    "src.drawing_intelligence.orchestration": {
      "file_path": "C:\\00Projects\\engineering_items_attributes_enrichment\\src\\drawing_intelligence\\orchestration\\__init__.py",
      "module_docstring": "Orchestration module for drawing intelligence pipeline.",
      "classes": {},
      "functions": []
    },
    "src.drawing_intelligence.processing.data_associator": {
      "file_path": "C:\\00Projects\\engineering_items_attributes_enrichment\\src\\drawing_intelligence\\processing\\data_associator.py",
      "module_docstring": "Data association module for the Drawing Intelligence System.\n\nLinks text annotations to detected shapes using spatial relationships, multi-view\ngrouping, and dimension-to-feature linking with configurable confidence scoring.\n\nThis module uses spatial indexing (KD-tree), advanced obstruction detection, and\nclustering algorithms (DBSCAN) for robust association in complex engineering drawings.",
      "classes": {
        "ObstacleDetectionMode": {
          "line": 39,
          "docstring": "Obstacle detection complexity levels.",
          "bases": [
            "Enum"
          ],
          "methods": [],
          "nested_classes": []
        },
        "AssociationConfig": {
          "line": 48,
          "docstring": "Configuration for data association with adaptive thresholds.\n\nAttributes:\n    label_distance_threshold: Maximum distance for label associations (pixels).\n    dimension_distance_threshold: Maximum distance for dimension associations.\n    min_association_confidence: Minimum confidence score for associations.\n    obstacle_detection_mode: Obstacle detection complexity level.\n    alignment_tolerance_px: Tolerance for shape alignment detection.\n    size_similarity_ratio: Minimum size ratio for multi-view grouping.\n    max_dimension_distance_px: Maximum distance for dimension-feature links.\n    confidence_multipliers: Text type confidence multipliers (dimension, label, note).\n    dbscan_eps: DBSCAN epsilon parameter for shape clustering.\n    dbscan_min_samples: DBSCAN minimum samples for cluster formation.\n    adaptive_thresholds: Enable DPI-based threshold scaling.\n    drawing_dpi: Drawing DPI for threshold normalization (if adaptive).",
          "bases": [],
          "methods": [
            {
              "name": "__post_init__",
              "line": 81,
              "docstring": "Normalize thresholds if adaptive mode is enabled.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        },
        "DataAssociator": {
          "line": 102,
          "docstring": "Link text annotations to detected shapes using advanced spatial analysis.\n\nUses KD-tree spatial indexing for efficient nearest-neighbor search,\nconfigurable obstacle detection, DBSCAN clustering for multi-view grouping,\nand multi-factor confidence scoring.\n\nAttributes:\n    config: Association configuration parameters.\n    _dimension_pattern: Compiled regex for dimension detection.\n    _radius_pattern: Compiled regex for radius detection.\n    _diameter_pattern: Compiled regex for diameter detection.\n\nExample:\n    >>> config = AssociationConfig(\n    ...     label_distance_threshold=150,\n    ...     obstacle_detection_mode=ObstacleDetectionMode.ADVANCED\n    ... )\n    >>> associator = DataAssociator(config)\n    >>> associations = associator.associate_text_to_shapes(texts, shapes)",
          "bases": [],
          "methods": [
            {
              "name": "__init__",
              "line": 124,
              "docstring": "Initialize data associator with compiled patterns.\n\nArgs:\n    config: Association configuration parameters.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "config",
                    "type": "AssociationConfig"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "associate_text_to_shapes",
              "line": 144,
              "docstring": "Link text blocks to nearest shapes using spatial indexing.\n\nUses KD-tree for efficient nearest-neighbor search and multi-factor\nconfidence scoring including distance, size ratio, and semantic compatibility.\n\nArgs:\n    text_blocks: OCR-extracted text blocks with entity types.\n    detections: Shape detections from YOLO model.\n\nReturns:\n    List of Association objects with confidence scores and relationship types.\n\nRaises:\n    ValueError: If inputs are invalid or empty.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "text_blocks",
                    "type": "List[TextBlock]"
                  },
                  {
                    "name": "detections",
                    "type": "List[Detection]"
                  }
                ],
                "return_type": "List[Association]"
              },
              "method_type": "instance"
            },
            {
              "name": "_get_entity_type",
              "line": 242,
              "docstring": "Extract entity type from TextBlock (set by EntityExtractor).\n\nArgs:\n    text_block: Text block with entity metadata.\n\nReturns:\n    Entity type string: 'dimension', 'label', 'note', or fallback.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "text_block",
                    "type": "TextBlock"
                  }
                ],
                "return_type": "str"
              },
              "method_type": "instance"
            },
            {
              "name": "_classify_text_type_fallback",
              "line": 261,
              "docstring": "Fallback text classification using regex patterns.\n\nArgs:\n    content: Text string to classify.\n\nReturns:\n    Classification string: 'dimension', 'label', or 'note'.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "content",
                    "type": "str"
                  }
                ],
                "return_type": "str"
              },
              "method_type": "instance"
            },
            {
              "name": "_find_nearest_shape_kdtree",
              "line": 283,
              "docstring": "Find nearest shape using KD-tree spatial index.\n\nCalculates distance from text center to nearest point on shape edge\n(not center-to-center) for improved accuracy.\n\nArgs:\n    text_block: Text block to find nearest shape for.\n    detections: List of all shape detections.\n    kdtree: Pre-built KD-tree of shape centers.\n\nReturns:\n    Tuple containing nearest Detection and edge distance (or None, inf).",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "text_block",
                    "type": "TextBlock"
                  },
                  {
                    "name": "detections",
                    "type": "List[Detection]"
                  },
                  {
                    "name": "kdtree",
                    "type": "KDTree"
                  }
                ],
                "return_type": "Tuple[Optional[Detection], float]"
              },
              "method_type": "instance"
            },
            {
              "name": "_distance_to_bbox_edge",
              "line": 325,
              "docstring": "Calculate minimum distance from point to bounding box edge.\n\nArgs:\n    point: (x, y) coordinates as numpy array.\n    bbox: BoundingBox object.\n\nReturns:\n    Minimum distance to bbox edge in pixels.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "point",
                    "type": "np.ndarray"
                  },
                  {
                    "name": "bbox"
                  }
                ],
                "return_type": "float"
              },
              "method_type": "instance"
            },
            {
              "name": "_get_distance_threshold",
              "line": 353,
              "docstring": "Get distance threshold based on text type.\n\nArgs:\n    text_type: Type of text ('dimension', 'label', 'note').\n\nReturns:\n    Distance threshold in pixels.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "text_type",
                    "type": "str"
                  }
                ],
                "return_type": "int"
              },
              "method_type": "instance"
            },
            {
              "name": "_check_obstacles",
              "line": 370,
              "docstring": "Check if shapes obstruct text-to-shape line of sight.\n\nUses configurable detection mode: simple (midpoint) or advanced\n(line intersection with multiple sample points).\n\nArgs:\n    text_block: Source text block.\n    target_shape: Target shape for association.\n    all_shapes: All shape detections to check as obstacles.\n\nReturns:\n    True if obstruction detected, False otherwise.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "text_block",
                    "type": "TextBlock"
                  },
                  {
                    "name": "target_shape",
                    "type": "Detection"
                  },
                  {
                    "name": "all_shapes",
                    "type": "List[Detection]"
                  }
                ],
                "return_type": "bool"
              },
              "method_type": "instance"
            },
            {
              "name": "_check_obstacles_simple",
              "line": 401,
              "docstring": "Simple obstacle detection using midpoint check.\n\nArgs:\n    text_center: Text block center coordinates.\n    shape_center: Target shape center coordinates.\n    target_shape: Target shape detection.\n    all_shapes: All shapes to check as obstacles.\n\nReturns:\n    True if midpoint falls inside an obstacle bbox.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "text_center",
                    "type": "Tuple[int, int]"
                  },
                  {
                    "name": "shape_center",
                    "type": "Tuple[int, int]"
                  },
                  {
                    "name": "target_shape",
                    "type": "Detection"
                  },
                  {
                    "name": "all_shapes",
                    "type": "List[Detection]"
                  }
                ],
                "return_type": "bool"
              },
              "method_type": "instance"
            },
            {
              "name": "_check_obstacles_advanced",
              "line": 433,
              "docstring": "Advanced obstacle detection using line intersection.\n\nSamples multiple points along text-to-shape line and checks for\nline segment intersection with obstacle bounding boxes.\n\nArgs:\n    text_center: Text block center coordinates.\n    shape_center: Target shape center coordinates.\n    target_shape: Target shape detection.\n    all_shapes: All shapes to check as obstacles.\n\nReturns:\n    True if line intersects any obstacle bbox.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "text_center",
                    "type": "Tuple[int, int]"
                  },
                  {
                    "name": "shape_center",
                    "type": "Tuple[int, int]"
                  },
                  {
                    "name": "target_shape",
                    "type": "Detection"
                  },
                  {
                    "name": "all_shapes",
                    "type": "List[Detection]"
                  }
                ],
                "return_type": "bool"
              },
              "method_type": "instance"
            },
            {
              "name": "_calculate_association_confidence",
              "line": 476,
              "docstring": "Calculate multi-factor confidence score for association.\n\nConsiders:\n1. Distance (exponential decay)\n2. Text-to-shape size ratio\n3. Alignment quality\n4. Semantic compatibility\n\nArgs:\n    text_block: Source text block.\n    shape: Target shape detection.\n    distance: Distance between text and shape edge.\n    threshold: Maximum allowed distance.\n    text_type: Text classification type.\n\nReturns:\n    Confidence score between 0.0 and 1.0.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "text_block",
                    "type": "TextBlock"
                  },
                  {
                    "name": "shape",
                    "type": "Detection"
                  },
                  {
                    "name": "distance",
                    "type": "float"
                  },
                  {
                    "name": "threshold",
                    "type": "float"
                  },
                  {
                    "name": "text_type",
                    "type": "str"
                  }
                ],
                "return_type": "float"
              },
              "method_type": "instance"
            },
            {
              "name": "_calculate_alignment_confidence",
              "line": 532,
              "docstring": "Calculate alignment quality between text and shape.\n\nArgs:\n    text_block: Text block.\n    shape: Shape detection.\n\nReturns:\n    Alignment confidence (0.0-1.0).",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "text_block",
                    "type": "TextBlock"
                  },
                  {
                    "name": "shape",
                    "type": "Detection"
                  }
                ],
                "return_type": "float"
              },
              "method_type": "instance"
            },
            {
              "name": "_calculate_semantic_confidence",
              "line": 562,
              "docstring": "Calculate semantic compatibility between text type and shape class.\n\nArgs:\n    text_type: Text classification type.\n    shape_class: Shape class name.\n\nReturns:\n    Semantic confidence (0.0-1.0).",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "text_type",
                    "type": "str"
                  },
                  {
                    "name": "shape_class",
                    "type": "str"
                  }
                ],
                "return_type": "float"
              },
              "method_type": "instance"
            },
            {
              "name": "identify_multi_view_groups",
              "line": 592,
              "docstring": "Group shapes representing orthographic views using DBSCAN clustering.\n\nUses DBSCAN to cluster shapes of the same class that are spatially\naligned and have similar sizes, indicating multi-view representations.\n\nArgs:\n    detections: All shape detections from drawing.\n\nReturns:\n    List of ViewGroup objects with inferred view types.\n\nNote:\n    DBSCAN parameters (eps, min_samples) are configurable via\n    AssociationConfig for tuning to specific drawing styles.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "detections",
                    "type": "List[Detection]"
                  }
                ],
                "return_type": "List[ViewGroup]"
              },
              "method_type": "instance"
            },
            {
              "name": "_cluster_shapes_dbscan",
              "line": 645,
              "docstring": "Cluster shapes using DBSCAN based on spatial features.\n\nArgs:\n    shapes: List of shapes of same class.\n\nReturns:\n    List of shape clusters (groups).",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "shapes",
                    "type": "List[Detection]"
                  }
                ],
                "return_type": "List[List[Detection]]"
              },
              "method_type": "instance"
            },
            {
              "name": "_shapes_have_similar_size",
              "line": 694,
              "docstring": "Check if shapes in group have similar sizes.\n\nArgs:\n    shapes: List of shapes to check.\n\nReturns:\n    True if all shapes have similar size ratios.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "shapes",
                    "type": "List[Detection]"
                  }
                ],
                "return_type": "bool"
              },
              "method_type": "instance"
            },
            {
              "name": "_infer_view_types",
              "line": 713,
              "docstring": "Infer view types based on relative spatial positions.\n\nArgs:\n    shapes: List of aligned shapes.\n\nReturns:\n    List of view type strings based on positioning.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "shapes",
                    "type": "List[Detection]"
                  }
                ],
                "return_type": "List[str]"
              },
              "method_type": "instance"
            },
            {
              "name": "_select_primary_shape",
              "line": 748,
              "docstring": "Select primary shape from group (largest area).\n\nArgs:\n    shapes: List of shapes in group.\n\nReturns:\n    detection_id of primary shape.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "shapes",
                    "type": "List[Detection]"
                  }
                ],
                "return_type": "str"
              },
              "method_type": "instance"
            },
            {
              "name": "link_dimensions_to_features",
              "line": 760,
              "docstring": "Link dimension entities to shape features with contextual inference.\n\nUses shape geometry, dimension orientation, and spatial context to\ninfer which feature (diameter, radius, length) the dimension describes.\n\nArgs:\n    dimensions: Dimension entities extracted by EntityExtractor.\n    shapes: Shape detections from YOLO model.\n\nReturns:\n    List of DimensionLink objects with confidence scores.\n\nNote:\n    Uses configurable max_dimension_distance_px threshold. Feature\n    type inference considers both dimension text and shape context.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "dimensions",
                    "type": "List[Entity]"
                  },
                  {
                    "name": "shapes",
                    "type": "List[Detection]"
                  }
                ],
                "return_type": "List[DimensionLink]"
              },
              "method_type": "instance"
            },
            {
              "name": "_infer_feature_type_contextual",
              "line": 831,
              "docstring": "Infer feature type using dimension text and shape context.\n\nArgs:\n    dimension: Dimension entity.\n    shape: Associated shape detection.\n\nReturns:\n    Feature type string ('diameter', 'radius', 'length_width', etc.).",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "dimension",
                    "type": "Entity"
                  },
                  {
                    "name": "shape",
                    "type": "Detection"
                  }
                ],
                "return_type": "str"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        }
      },
      "functions": []
    },
    "src.drawing_intelligence.processing.data_validator": {
      "file_path": "C:\\00Projects\\engineering_items_attributes_enrichment\\src\\drawing_intelligence\\processing\\data_validator.py",
      "module_docstring": "Data validation module for the Drawing Intelligence System.\n\nCross-validates extraction results for consistency and completeness.\nImplements configurable validation rules with spatial indexing for performance.",
      "classes": {
        "Severity": {
          "line": 32,
          "docstring": "Validation issue severity levels.",
          "bases": [
            "Enum"
          ],
          "methods": [],
          "nested_classes": []
        },
        "IssueType": {
          "line": 41,
          "docstring": "Specific validation issue types.",
          "bases": [
            "Enum"
          ],
          "methods": [],
          "nested_classes": []
        },
        "ValidationConfig": {
          "line": 56,
          "docstring": "Configuration for data validation checks.\n\nControls which validation rules are enforced, their thresholds, and penalty weights.\n\nAttributes:\n    enforce_part_number: If True, require part number presence (CRITICAL if missing).\n    enforce_material: If True, require material specification (HIGH if missing).\n    warn_on_orphaned_entities: If True, flag entities without source text blocks.\n    check_dimension_compatibility: If True, validate dimension-shape semantic compatibility.\n    check_geometric_overlap: If True, detect overlapping or conflicting entities.\n    unassociated_text_distance_threshold: Maximum distance (px) for unassociated dimension detection.\n    penalty_critical: Confidence penalty per CRITICAL issue (0.0-1.0).\n    penalty_high: Confidence penalty per HIGH issue (0.0-1.0).\n    penalty_medium: Confidence penalty per MEDIUM issue (0.0-1.0).\n    penalty_low: Confidence penalty per LOW issue (0.0-1.0).\n    max_penalty: Maximum cumulative confidence penalty (0.0-1.0).\n    critical_entity_types: Entity types considered critical for validation.\n    cylindrical_shape_classes: Shape classes compatible with diameter dimensions.\n    fastener_shape_classes: Shape classes compatible with thread specifications.",
          "bases": [],
          "methods": [
            {
              "name": "__post_init__",
              "line": 124,
              "docstring": "Validate configuration parameters.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        },
        "DataValidator": {
          "line": 142,
          "docstring": "Cross-validates extraction results for consistency and completeness.\n\nPerforms multi-layer validation across OCR results, shape detections,\nextracted entities, and their associations. Uses spatial indexing for\nefficient proximity queries on large drawing sets.\n\nThe validator implements comprehensive checks:\n    1. Orphaned entities (entities without source text blocks)\n    2. Unassociated critical text (dimensions near shapes but not linked)\n    3. Entity-shape compatibility (dimension types vs. shape types)\n    4. Critical field presence (part numbers, materials, etc.)\n    5. Geometric overlap detection (conflicting annotations)\n    6. Association quality (conflicting or invalid links)\n\nAttributes:\n    config: Validation configuration controlling check behavior and penalties.",
          "bases": [],
          "methods": [
            {
              "name": "__init__",
              "line": 173,
              "docstring": "Initialize the data validator with optional configuration.\n\nArgs:\n    config: Validation configuration. If None, uses default configuration\n        with all standard checks enabled.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "config",
                    "type": "Optional[ValidationConfig]"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "validate_associations",
              "line": 187,
              "docstring": "Cross-validate all extraction layers for consistency.\n\nRuns all configured validation checks and generates a comprehensive\nvalidation report with severity-classified issues and confidence adjustments.\nUses pre-calculated lookup maps for efficient cross-referencing.\n\nArgs:\n    ocr_result: OCR extraction result containing text blocks and metadata.\n    detections: List of shape detections from computer vision pipeline.\n    entities: List of extracted structured entities (part numbers,\n        dimensions, materials, etc.).\n    associations: List of validated text-to-shape associations.\n\nReturns:\n    ValidationReport containing:\n        - is_valid: False if CRITICAL issues found\n        - issues: List of all validation issues with severity levels\n        - confidence_adjustment: Penalty factor (0.5-1.0) based on issue severity\n        - requires_human_review: True if HIGH or CRITICAL issues exist\n\nExample:\n    >>> validator = DataValidator()\n    >>> report = validator.validate_associations(\n    ...     ocr_result, detections, entities, associations\n    ... )\n    >>> if report.requires_human_review:\n    ...     logger.warning(f\"Found {len(report.issues)} validation issues\")",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "ocr_result",
                    "type": "OCRResult"
                  },
                  {
                    "name": "detections",
                    "type": "List[Detection]"
                  },
                  {
                    "name": "entities",
                    "type": "List[Entity]"
                  },
                  {
                    "name": "associations",
                    "type": "List[Association]"
                  }
                ],
                "return_type": "ValidationReport"
              },
              "method_type": "instance"
            },
            {
              "name": "_check_orphaned_entities",
              "line": 302,
              "docstring": "Identify entities without corresponding source text blocks.\n\nOrphaned entities indicate extraction logic errors where entities\nwere created without valid text sources.\n\nArgs:\n    entities: List of extracted entities to validate.\n    text_block_by_id: Lookup map of text blocks by ID.\n\nReturns:\n    List of HIGH severity validation issues for orphaned entities.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "entities",
                    "type": "List[Entity]"
                  },
                  {
                    "name": "text_block_by_id",
                    "type": "Dict[str, TextBlock]"
                  }
                ],
                "return_type": "List[ValidationIssue]"
              },
              "method_type": "instance"
            },
            {
              "name": "_check_unassociated_text",
              "line": 336,
              "docstring": "Find dimension-like text near shapes that lack associations.\n\nUses spatial indexing (KD-tree) for efficient nearest-neighbor search.\nApplies semantic filtering to reduce false positives.\n\nArgs:\n    text_blocks: List of all OCR text blocks.\n    detections: List of detected shapes.\n    associations: List of existing text-shape associations.\n\nReturns:\n    List of MEDIUM severity issues for unassociated dimensions.\n\nNote:\n    Uses config.unassociated_text_distance_threshold for proximity\n    detection (default: 500px). Complexity: O(n log m) vs O(n*m).",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "text_blocks",
                    "type": "List[TextBlock]"
                  },
                  {
                    "name": "detections",
                    "type": "List[Detection]"
                  },
                  {
                    "name": "associations",
                    "type": "List[Association]"
                  }
                ],
                "return_type": "List[ValidationIssue]"
              },
              "method_type": "instance"
            },
            {
              "name": "_check_entity_shape_consistency",
              "line": 407,
              "docstring": "Validate dimension entity compatibility with associated shapes.\n\nImplements semantic checks:\n    - Diameter dimensions only for cylindrical shapes\n    - Thread specs only for fasteners\n    - General dimensional compatibility\n\nArgs:\n    associations: Text-shape associations with relationship types.\n    entity_by_text: Lookup map of entities grouped by source text ID.\n    detection_by_id: Lookup map of detections by ID.\n\nReturns:\n    List of LOW severity issues for incompatible pairings.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "associations",
                    "type": "List[Association]"
                  },
                  {
                    "name": "entity_by_text",
                    "type": "Dict[str, List[Entity]]"
                  },
                  {
                    "name": "detection_by_id",
                    "type": "Dict[str, Detection]"
                  }
                ],
                "return_type": "List[ValidationIssue]"
              },
              "method_type": "instance"
            },
            {
              "name": "_check_dimension_shape_compatibility",
              "line": 457,
              "docstring": "Check semantic compatibility between dimension entities and shape.\n\nValidates that dimension types match shape geometry:\n    - Diameter (\u00d8) dimensions only for cylindrical shapes\n    - Thread dimensions only for fasteners\n    - Other dimensions are generally compatible\n\nArgs:\n    dimension_entities: List of dimension entities from associated text.\n    shape: Shape detection to validate against.\n\nReturns:\n    ValidationIssue if incompatibility detected, None otherwise.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "dimension_entities",
                    "type": "List[Entity]"
                  },
                  {
                    "name": "shape",
                    "type": "Detection"
                  }
                ],
                "return_type": "Optional[ValidationIssue]"
              },
              "method_type": "instance"
            },
            {
              "name": "_check_critical_fields",
              "line": 518,
              "docstring": "Verify presence of mandatory entity types.\n\nChecks for critical fields required for database enrichment based on\nconfiguration settings.\n\nArgs:\n    entities: List of extracted entities to check.\n\nReturns:\n    List of validation issues for missing critical fields.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "entities",
                    "type": "List[Entity]"
                  }
                ],
                "return_type": "List[ValidationIssue]"
              },
              "method_type": "instance"
            },
            {
              "name": "_check_geometric_overlaps",
              "line": 570,
              "docstring": "Detect overlapping or conflicting entity annotations.\n\nIdentifies entities with source text blocks that significantly overlap,\nwhich may indicate duplicate or conflicting annotations.\n\nArgs:\n    entities: List of extracted entities.\n    text_block_by_id: Lookup map of text blocks by ID.\n\nReturns:\n    List of MEDIUM severity issues for overlapping entities.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "entities",
                    "type": "List[Entity]"
                  },
                  {
                    "name": "text_block_by_id",
                    "type": "Dict[str, TextBlock]"
                  }
                ],
                "return_type": "List[ValidationIssue]"
              },
              "method_type": "instance"
            },
            {
              "name": "_check_association_quality",
              "line": 618,
              "docstring": "Validate association quality for conflicts and anomalies.\n\nDetects:\n    - Multiple associations from same text to different shapes\n    - Circular/self-referential associations\n    - Unusually low confidence associations\n\nArgs:\n    associations: List of text-shape associations.\n\nReturns:\n    List of LOW severity issues for association quality problems.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "associations",
                    "type": "List[Association]"
                  }
                ],
                "return_type": "List[ValidationIssue]"
              },
              "method_type": "instance"
            },
            {
              "name": "_looks_like_dimension",
              "line": 659,
              "docstring": "Heuristic pattern matching to identify dimensional text.\n\nUses compiled regex patterns for efficiency and semantic filtering\nto exclude non-dimensional text (notes, labels, etc.).\n\nArgs:\n    content: Text string to evaluate.\n\nReturns:\n    True if text contains numbers, dimensional indicators, and\n    does not match exclusion patterns.\n\nExamples:\n    >>> validator._looks_like_dimension(\"\u00d825 \u00b10.1mm\")\n    True\n    >>> validator._looks_like_dimension(\"NOTE: See detail A\")\n    False",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "content",
                    "type": "str"
                  }
                ],
                "return_type": "bool"
              },
              "method_type": "instance"
            },
            {
              "name": "_calculate_bbox_overlap",
              "line": 685,
              "docstring": "Calculate intersection-over-union ratio for two bounding boxes.\n\nArgs:\n    bbox1: First bounding box.\n    bbox2: Second bounding box.\n\nReturns:\n    Overlap ratio (0.0 to 1.0), where 1.0 means complete overlap.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "bbox1"
                  },
                  {
                    "name": "bbox2"
                  }
                ],
                "return_type": "float"
              },
              "method_type": "instance"
            },
            {
              "name": "_group_issues_by_severity",
              "line": 716,
              "docstring": "Group validation issues by severity level.\n\nArgs:\n    issues: List of validation issues.\n\nReturns:\n    Dictionary mapping severity levels to issue lists.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "issues",
                    "type": "List[ValidationIssue]"
                  }
                ],
                "return_type": "Dict[Severity, List[ValidationIssue]]"
              },
              "method_type": "instance"
            },
            {
              "name": "_calculate_confidence_penalty",
              "line": 740,
              "docstring": "Calculate confidence reduction factor from validation issues.\n\nApplies configurable severity-weighted penalties with early termination\nwhen maximum penalty is reached.\n\nArgs:\n    issues: List of validation issues with severity classifications.\n\nReturns:\n    Confidence adjustment factor between (1-max_penalty) and 1.0, where:\n        - 1.0 = no issues, no penalty\n        - (1-max_penalty) = maximum penalty applied\n\nExample:\n    >>> config = ValidationConfig(penalty_high=0.15, penalty_medium=0.05)\n    >>> issues = [\n    ...     ValidationIssue(severity=\"HIGH\", ...),\n    ...     ValidationIssue(severity=\"MEDIUM\", ...)\n    ... ]\n    >>> penalty = validator._calculate_confidence_penalty(issues)\n    >>> # Returns 0.80 (20% penalty: 0.15 + 0.05)",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "issues",
                    "type": "List[ValidationIssue]"
                  }
                ],
                "return_type": "float"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        }
      },
      "functions": []
    },
    "src.drawing_intelligence.processing.entity_extractor": {
      "file_path": "C:\\00Projects\\engineering_items_attributes_enrichment\\src\\drawing_intelligence\\processing\\entity_extractor.py",
      "module_docstring": "Entity extraction module for the Drawing Intelligence System.\n\nThis module provides multi-layer entity extraction from OCR text using:\n1. Regex patterns for fast, precise extraction (~95% of entities)\n2. spaCy EntityRuler for context-aware extraction (~4% of entities)\n3. Optional LLM enhancement for difficult cases (~1% of entities, cost-controlled)\n\nPerformance Characteristics:\n    - Regex: ~50ms per page (fastest, deterministic)\n    - spaCy: ~200ms per page (context-aware, requires model loading)\n    - LLM: ~2-5s per page (most accurate, highest cost)\n\nThreading Safety:\n    WARNING: This class is NOT thread-safe due to shared spaCy model state.\n    Create separate instances per thread or implement external locking.\n\nTypical usage example:\n    >>> config = EntityConfig(\n    ...     use_llm=False,\n    ...     confidence_threshold=0.80,\n    ...     normalize_units=True\n    ... )\n    >>> with EntityExtractor(config, llm_gateway=None) as extractor:\n    ...     result = extractor.extract_entities(ocr_result)\n    ...     print(f\"Found {len(result.entities)} entities\")",
      "classes": {
        "LLMGatewayProtocol": {
          "line": 57,
          "docstring": "Protocol defining the interface for LLM gateway implementations.",
          "bases": [
            "Protocol"
          ],
          "methods": [
            {
              "name": "extract_entities_llm",
              "line": 60,
              "docstring": "Extract entities using LLM.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "text",
                    "type": "str"
                  },
                  {
                    "name": "context",
                    "type": "str"
                  },
                  {
                    "name": "entity_types",
                    "type": "List[str]"
                  }
                ],
                "return_type": "List[Entity]"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        },
        "EntityConfig": {
          "line": 68,
          "docstring": "Configuration for entity extraction behavior.\n\nAttributes:\n    use_regex: Enable regex-based extraction for fast pattern matching.\n    use_spacy: Enable spaCy-based extraction for context-aware NER.\n    use_llm: Enable LLM-based extraction for complex cases (increases cost).\n    confidence_threshold: Minimum confidence score (0.0-1.0) to accept entities.\n    normalize_units: Convert units to standard format (e.g., all lengths to mm).\n    pattern_file: Optional path to custom regex pattern definitions.\n    oem_dictionary_path: Optional path to file containing OEM manufacturer names.\n    regex_part_number_confidence: Confidence score for regex-extracted part numbers.\n    regex_dimension_confidence: Confidence score for regex-extracted dimensions.\n    regex_weight_confidence: Confidence score for regex-extracted weights.\n    regex_thread_confidence: Confidence score for regex-extracted thread specs.\n    regex_material_confidence: Confidence score for regex-extracted materials.\n    regex_finish_confidence: Confidence score for regex-extracted surface finishes.\n    regex_tolerance_confidence: Confidence score for regex-extracted tolerances.\n    spacy_confidence: Confidence score for spaCy-extracted entities.\n    enable_entity_types: List of entity types to extract (empty = all types).\n    max_llm_retries: Maximum retry attempts for LLM API failures.\n    llm_timeout: Timeout in seconds for LLM API calls.\n    spacy_model: spaCy model name to use (default: blank English).\n    fuzzy_match_threshold: Similarity threshold (0.0-1.0) for text block matching.\n    spatial_dedup_iou_threshold: IoU threshold for spatial deduplication.",
          "bases": [],
          "methods": [
            {
              "name": "__post_init__",
              "line": 122,
              "docstring": "Validate configuration parameters.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        },
        "EntityExtractor": {
          "line": 160,
          "docstring": "Extracts structured entities from OCR text using a cascading approach.\n\nThe extractor uses three layers in sequence:\n1. Regex patterns: Fast, deterministic extraction for well-structured data\n2. spaCy NER: Context-aware extraction for ambiguous cases\n3. LLM enhancement: Optional fallback for missing critical entities\n\nThis class implements the context manager protocol for proper resource cleanup.\n\nAttributes:\n    config: Entity extraction configuration settings.\n    llm_gateway: Optional LLM gateway for enhanced extraction.\n    patterns: Dictionary of regex patterns for entity types.\n    oem_names: Set of known OEM manufacturer names.\n\nExample:\n    >>> config = EntityConfig(use_llm=False)\n    >>> with EntityExtractor(config) as extractor:\n    ...     result = extractor.extract_entities(ocr_result)\n    ...     print(f\"Found {len(result.entities)} entities\")",
          "bases": [],
          "methods": [
            {
              "name": "__init__",
              "line": 184,
              "docstring": "Initialize entity extractor.\n\nArgs:\n    config: Entity extraction configuration.\n    llm_gateway: Optional LLM gateway for enhancement.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "config",
                    "type": "EntityConfig"
                  },
                  {
                    "name": "llm_gateway",
                    "type": "Optional[LLMGatewayProtocol]"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "__enter__",
              "line": 213,
              "docstring": "Enter context manager.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "'EntityExtractor'"
              },
              "method_type": "instance"
            },
            {
              "name": "__exit__",
              "line": 217,
              "docstring": "Exit context manager and cleanup resources.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "exc_type"
                  },
                  {
                    "name": "exc_val"
                  },
                  {
                    "name": "exc_tb"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "cleanup",
              "line": 221,
              "docstring": "Release resources (spaCy model, caches).",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "check_dependencies",
              "line": 232,
              "docstring": "Check if optional dependencies are installed.\n\nReturns:\n    Dictionary mapping dependency names to availability status.",
              "signature": {
                "parameters": [],
                "return_type": "Dict[str, bool]"
              },
              "method_type": "static"
            },
            {
              "name": "extract_entities",
              "line": 250,
              "docstring": "Extracts all entities from OCR text using multi-layer approach.\n\nThis method orchestrates the three-layer extraction process:\n1. Applies regex patterns to all text blocks\n2. Uses spaCy NER on full text (if enabled)\n3. Calls LLM for missing critical entities (if enabled and needed)\n\nArgs:\n    ocr_result: OCR extraction result containing text blocks and layout\n        regions.\n\nReturns:\n    EntityExtractionResult containing:\n        - List of all extracted entities\n        - Extracted title block data (if found)\n        - Extraction statistics (counts, confidence scores)\n        - Placeholder for validation report (added by validator)\n\nExample:\n    >>> result = extractor.extract_entities(ocr_result)\n    >>> part_numbers = [e for e in result.entities\n    ...                 if e.entity_type == EntityType.PART_NUMBER]",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "ocr_result",
                    "type": "OCRResult"
                  }
                ],
                "return_type": "EntityExtractionResult"
              },
              "method_type": "instance"
            },
            {
              "name": "_extract_with_regex",
              "line": 326,
              "docstring": "Performs fast regex-based entity extraction (Layer 1).\n\nApplies predefined regex patterns to extract:\n- Part numbers (various formats: PN-123, 12345-AB, etc.)\n- Dimensions (with units: mm, cm, m, in, inch)\n- Weights (kg, g, lbs, oz)\n- Thread specifications (M10x1.5, #8-32 UNC, etc.)\n- Materials (Steel AISI 304, Aluminum 6061, etc.)\n- Surface finishes (Ra 3.2, N7, etc.)\n- Tolerances (\u00b10.1 mm, \u00b10.005 in, etc.)\n\nArgs:\n    ocr_result: OCR result containing text blocks with content and\n        bounding boxes.\n\nReturns:\n    List of Entity objects with configurable confidence scores.\n\nNote:\n    Regex extraction is deterministic but may produce false positives.\n    Confidence scores are user-configurable via EntityConfig.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "ocr_result",
                    "type": "OCRResult"
                  }
                ],
                "return_type": "List[Entity]"
              },
              "method_type": "instance"
            },
            {
              "name": "_extract_with_spacy",
              "line": 479,
              "docstring": "Performs spaCy-based entity extraction with EntityRuler (Layer 2).\n\nUses spaCy's EntityRuler to extract:\n- OEM manufacturer names from predefined dictionary\n- Other context-aware entities (currently limited)\n\nThe spaCy model is lazy-loaded on first use and cached for subsequent\ncalls.\n\nArgs:\n    ocr_result: OCR result containing full text and individual text\n        blocks.\n\nReturns:\n    List of Entity objects extracted by spaCy. Returns empty list if:\n    - spaCy is not installed\n    - spaCy initialization fails\n    - No entities are found\n\nNote:\n    This method maps extracted entities back to their source text blocks\n    using enhanced matching (exact, then fuzzy).",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "ocr_result",
                    "type": "OCRResult"
                  }
                ],
                "return_type": "List[Entity]"
              },
              "method_type": "instance"
            },
            {
              "name": "_extract_with_llm",
              "line": 558,
              "docstring": "Performs LLM-based entity extraction for missing critical entities\n(Layer 3).\n\nThis method is called only when:\n1. LLM enhancement is enabled (config.use_llm=True)\n2. An LLM gateway is configured\n3. Critical entities (PART_NUMBER, OEM) are missing after regex/spaCy\n   extraction\n\nImplements retry logic for transient API failures.\n\nArgs:\n    text: Full concatenated text from OCR result.\n    failed_types: List of entity types that weren't found in previous\n        layers.\n\nReturns:\n    List of Entity objects extracted by LLM. Returns empty list on\n    failure.\n\nWarning:\n    This method incurs LLM API costs. Use sparingly (5-10% of drawings).",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "text",
                    "type": "str"
                  },
                  {
                    "name": "failed_types",
                    "type": "List[EntityType]"
                  }
                ],
                "return_type": "List[Entity]"
              },
              "method_type": "instance"
            },
            {
              "name": "extract_title_block",
              "line": 619,
              "docstring": "Extracts structured title block data from designated layout region.\n\nSearches for a layout region marked as 'title_block' and extracts:\n- Part number\n- OEM manufacturer name\n- Scale (e.g., 1:1, 2:1)\n- Date (various formats: MM/DD/YYYY, DD-MM-YYYY)\n- Revision (e.g., A, Rev B, R01)\n\nArgs:\n    ocr_result: OCR result with layout regions and text blocks.\n\nReturns:\n    TitleBlock object with extracted fields (may have None values), or\n    None if no title block region is found or it contains no text.\n\nNote:\n    Title block extraction assumes bottom-right positioning and uses\n    simple regex patterns. Complex layouts may require LLM enhancement.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "ocr_result",
                    "type": "OCRResult"
                  }
                ],
                "return_type": "Optional[TitleBlock]"
              },
              "method_type": "instance"
            },
            {
              "name": "_create_entity",
              "line": 695,
              "docstring": "Creates an Entity object with proper normalization and metadata.\n\nArgs:\n    entity_type: Type of entity being created (from EntityType enum).\n    value: Extracted entity value (may be cleaned/processed).\n    original_text: Raw text exactly as it appeared in the source.\n    confidence: Confidence score (0.0-1.0) for this extraction.\n    method: Extraction method used ('regex', 'spacy', or 'llm').\n    text_block: Source text block containing this entity.\n    normalized: Optional pre-computed normalized value dictionary.\n\nReturns:\n    Entity object with unique ID, bounding box, and normalized values.\n\nNote:\n    If normalized is None, calls _normalize_entity() to compute it.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "entity_type",
                    "type": "EntityType"
                  },
                  {
                    "name": "value",
                    "type": "str"
                  },
                  {
                    "name": "original_text",
                    "type": "str"
                  },
                  {
                    "name": "confidence",
                    "type": "float"
                  },
                  {
                    "name": "method",
                    "type": "str"
                  },
                  {
                    "name": "text_block",
                    "type": "TextBlock"
                  },
                  {
                    "name": "normalized",
                    "type": "Optional[Dict[str, Any]]"
                  }
                ],
                "return_type": "Entity"
              },
              "method_type": "instance"
            },
            {
              "name": "_normalize_entity",
              "line": 744,
              "docstring": "Normalizes entity values to standard formats for consistent storage.\n\nNormalization rules by entity type:\n- DIMENSION: Extracts numeric value, unit, tolerance; converts to mm\n  if configured\n- WEIGHT: Extracts numeric value and unit (lowercase)\n- Other types: Stores raw value only\n\nArgs:\n    entity_type: Type of entity to normalize.\n    value: Raw extracted value string.\n\nReturns:\n    Dictionary containing:\n    - 'raw': Original value (always present)\n    - Additional keys depending on entity_type (value, unit,\n      tolerance, etc.)\n\nExample:\n    >>> result = extractor._normalize_entity(\n    ...     EntityType.DIMENSION, \"25.4mm \u00b10.1\"\n    ... )\n    >>> print(result)\n    {'raw': '25.4mm \u00b10.1', 'value': 25.4, 'unit': 'mm',\n     'tolerance': 0.1}",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "entity_type",
                    "type": "EntityType"
                  },
                  {
                    "name": "value",
                    "type": "str"
                  }
                ],
                "return_type": "Dict[str, Any]"
              },
              "method_type": "instance"
            },
            {
              "name": "_load_patterns",
              "line": 803,
              "docstring": "Loads regex patterns from file or returns defaults.\n\nReturns:\n    Dictionary mapping pattern names to regex strings. Currently\n    returns empty dict as patterns are embedded in extraction methods.\n\nTodo:\n    Implement pattern file loading when config.pattern_file is\n    provided to allow external pattern customization.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "Dict[str, str]"
              },
              "method_type": "instance"
            },
            {
              "name": "_load_oem_dictionary",
              "line": 819,
              "docstring": "Loads OEM manufacturer names from dictionary file or uses defaults.\n\nReturns:\n    Set of OEM manufacturer names (case-preserved). Includes 11\n    built-in names plus any loaded from config.oem_dictionary_path.\n\nNote:\n    Logs warning if file path is provided but loading fails.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "Set[str]"
              },
              "method_type": "instance"
            },
            {
              "name": "_deduplicate_entities",
              "line": 863,
              "docstring": "Removes duplicate entities using type, value, and spatial matching.\n\nThis method checks for duplicates by:\n1. Type and value matching (case-insensitive)\n2. Spatial proximity (using IoU if bounding boxes overlap significantly)\n\nArgs:\n    new_entities: List of newly extracted entities to check.\n    existing_entities: List of already-accepted entities.\n\nReturns:\n    Filtered list containing only entities that don't match any\n    existing entity.\n\nNote:\n    Spatial deduplication prevents discarding valid but spatially\n    distinct entities with the same value (e.g., repeated dimensions).",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "new_entities",
                    "type": "List[Entity]"
                  },
                  {
                    "name": "existing_entities",
                    "type": "List[Entity]"
                  }
                ],
                "return_type": "List[Entity]"
              },
              "method_type": "instance"
            },
            {
              "name": "_calculate_iou",
              "line": 911,
              "docstring": "Calculate Intersection over Union (IoU) between two bounding boxes.\n\nArgs:\n    bbox1: First bounding box.\n    bbox2: Second bounding box.\n\nReturns:\n    IoU score between 0.0 (no overlap) and 1.0 (complete overlap).",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "bbox1",
                    "type": "BoundingBox"
                  },
                  {
                    "name": "bbox2",
                    "type": "BoundingBox"
                  }
                ],
                "return_type": "float"
              },
              "method_type": "instance"
            },
            {
              "name": "_identify_missing_critical",
              "line": 941,
              "docstring": "Identifies critical entity types that are missing from extraction\nresults.\n\nCritical entities are defined as:\n- PART_NUMBER: Required for database indexing\n- OEM: Required for manufacturer attribution\n\nArgs:\n    entities: List of extracted entities to check.\n\nReturns:\n    List of EntityType values that are critical but not present in\n    entities.\n\nNote:\n    Used to determine whether LLM enhancement should be triggered.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "entities",
                    "type": "List[Entity]"
                  }
                ],
                "return_type": "List[EntityType]"
              },
              "method_type": "instance"
            },
            {
              "name": "_find_text_block_for_text",
              "line": 966,
              "docstring": "Finds the text block containing a given text string using enhanced\nmatching.\n\nUses a three-step approach:\n1. Exact substring match\n2. Fuzzy matching (for OCR errors)\n3. Returns None if no match found\n\nArgs:\n    text: String to search for within text blocks.\n    text_blocks: List of text blocks to search.\n\nReturns:\n    First TextBlock whose content contains or closely matches the\n    search text, or None if not found.\n\nNote:\n    Fuzzy matching threshold is configurable via\n    config.fuzzy_match_threshold.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "text",
                    "type": "str"
                  },
                  {
                    "name": "text_blocks",
                    "type": "List[TextBlock]"
                  }
                ],
                "return_type": "Optional[TextBlock]"
              },
              "method_type": "instance"
            },
            {
              "name": "_is_entity_type_enabled",
              "line": 1015,
              "docstring": "Check if a specific entity type is enabled for extraction.\n\nArgs:\n    entity_type: Entity type to check.\n\nReturns:\n    True if entity type should be extracted, False otherwise.\n\nNote:\n    If config.enable_entity_types is empty, all types are enabled.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "entity_type",
                    "type": "EntityType"
                  }
                ],
                "return_type": "bool"
              },
              "method_type": "instance"
            },
            {
              "name": "_calculate_statistics",
              "line": 1032,
              "docstring": "Calculates extraction statistics for reporting and quality assessment.\n\nArgs:\n    entities: List of all extracted entities.\n    extraction_methods: Dictionary mapping method names ('regex',\n        'spacy', 'llm') to count of entities extracted by each method.\n\nReturns:\n    ExtractionStats containing:\n    - total_entities: Total count\n    - entities_by_type: Dict mapping entity type names to counts\n    - entities_by_method: Copy of input extraction_methods dict\n    - average_confidence: Mean confidence across all entities\n\nNote:\n    Returns 0.0 average confidence if entities list is empty.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "entities",
                    "type": "List[Entity]"
                  },
                  {
                    "name": "extraction_methods",
                    "type": "Dict[str, int]"
                  }
                ],
                "return_type": "ExtractionStats"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        }
      },
      "functions": []
    },
    "src.drawing_intelligence.processing.hierarchy_builder": {
      "file_path": "C:\\00Projects\\engineering_items_attributes_enrichment\\src\\drawing_intelligence\\processing\\hierarchy_builder.py",
      "module_docstring": "Hierarchy builder module for the Drawing Intelligence System.\n\nThis module provides functionality for inferring assembly relationships and\ncomponent hierarchies from detected shapes in engineering drawings. It identifies\ncontainment, fastening, and spatial relationships between components.",
      "classes": {
        "HierarchyNode": {
          "line": 26,
          "docstring": "Type definition for hierarchy tree node structure.\n\nAttributes:\n    id: Unique identifier for the component.\n    class_name: Component class name (e.g., 'housing', 'bolt').\n    confidence: Confidence score for this node's placement in hierarchy.\n    relationship: Type of relationship to parent (omitted for root).\n        Valid values: 'contains', 'fastens', 'orphaned'.\n    children: List of child nodes in the hierarchy.",
          "bases": [
            "TypedDict"
          ],
          "methods": [],
          "nested_classes": []
        },
        "HierarchyConfig": {
          "line": 46,
          "docstring": "Configuration for hierarchy building.\n\nAttributes:\n    fastener_proximity_px: Maximum distance (pixels) between fastener and\n        connected components. Should be adjusted based on drawing resolution.\n    size_weight: Weight for component size in root selection (0.0-1.0).\n    association_weight: Weight for association count in root selection (0.0-1.0).\n    centrality_weight: Weight for spatial centrality in root selection (0.0-1.0).\n    containment_confidence_base: Base confidence score for containment relationships.\n    fastening_confidence_base: Base confidence score for fastening relationships.\n    orphaned_confidence: Confidence score for orphaned component attachments.\n    max_tree_depth: Maximum depth for hierarchy tree to prevent stack overflow.\n    fastener_types: Set of component class names considered fasteners.\n    min_containment_overlap: Minimum bbox overlap ratio to consider containment (0.0-1.0).\n    weight_sum_tolerance: Tolerance for weight sum validation.",
          "bases": [],
          "methods": [
            {
              "name": "__post_init__",
              "line": 78,
              "docstring": "Validates configuration parameters.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        },
        "SpatialIndex": {
          "line": 112,
          "docstring": "Simple spatial index for fast bounding box queries.\n\nUses R-tree-like structure for efficient proximity and containment queries.",
          "bases": [],
          "methods": [
            {
              "name": "__init__",
              "line": 118,
              "docstring": "Initializes spatial index from detections.\n\nArgs:\n    detections: List of detections to index.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "detections",
                    "type": "List[Detection]"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "_build_index",
              "line": 127,
              "docstring": "Builds simple dictionary index (can be replaced with R-tree).\n\nReturns:\n    Dictionary mapping detection IDs to Detection objects.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "Dict[str, Detection]"
              },
              "method_type": "instance"
            },
            {
              "name": "find_containing",
              "line": 135,
              "docstring": "Finds all detections that contain the given detection.\n\nArgs:\n    detection: Detection to find containers for.\n\nReturns:\n    List of detections that contain the given detection, sorted by area\n    (smallest first to find immediate parent).",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "detection",
                    "type": "Detection"
                  }
                ],
                "return_type": "List[Detection]"
              },
              "method_type": "instance"
            },
            {
              "name": "find_within_distance",
              "line": 157,
              "docstring": "Finds detections within specified distance.\n\nArgs:\n    detection: Reference detection.\n    max_distance: Maximum distance in pixels.\n\nReturns:\n    List of (detection, distance) tuples within max_distance.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "detection",
                    "type": "Detection"
                  },
                  {
                    "name": "max_distance",
                    "type": "float"
                  }
                ],
                "return_type": "List[Tuple[Detection, float]]"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        },
        "HierarchyBuilder": {
          "line": 185,
          "docstring": "Builds component hierarchy from detected shapes in engineering drawings.\n\nThis class analyzes spatial relationships between detected shapes to infer\nassembly hierarchies including containment (housings, enclosures), fastening\n(bolts, screws connecting components), and nested component structures.\n\nAttributes:\n    config: Configuration parameters for hierarchy building.\n\nExample:\n    >>> config = HierarchyConfig(fastener_proximity_px=250)\n    >>> builder = HierarchyBuilder(config)\n    >>> hierarchy = builder.build_hierarchy(detections, associations)\n    >>> print(hierarchy.root_component_id)",
          "bases": [],
          "methods": [
            {
              "name": "__init__",
              "line": 202,
              "docstring": "Initializes the hierarchy builder with optional configuration.\n\nArgs:\n    config: Configuration parameters. If None, uses default configuration.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "config",
                    "type": "Optional[HierarchyConfig]"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "build_hierarchy",
              "line": 214,
              "docstring": "Builds component hierarchy from shape detections and associations.\n\nAnalyzes spatial relationships to create a hierarchical tree structure\nrepresenting component assemblies. Identifies containment relationships\n(parent contains child), fastening relationships (fastener connects\ncomponents), and builds a navigable tree structure.\n\nRelationship types in output:\n    - 'contains': Parent component physically contains child\n    - 'fastens': Fastener connects multiple components\n    - 'orphaned': Component has no explicit relationship, attached to root\n\nArgs:\n    detections: List of shape detections from the drawing. Must not be empty.\n    associations: Text-shape associations providing additional context for\n        relationship inference. Used to identify important components.\n\nReturns:\n    ComponentHierarchy object containing the root component ID, list of\n    assembly relationships, and hierarchical tree structure.\n\nRaises:\n    ValueError: If detections list is empty.\n\nExample:\n    >>> detections = [Detection(...), Detection(...)]\n    >>> associations = [Association(...)]\n    >>> hierarchy = builder.build_hierarchy(detections, associations)",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "detections",
                    "type": "List[Detection]"
                  },
                  {
                    "name": "associations",
                    "type": "List[Association]"
                  }
                ],
                "return_type": "ComponentHierarchy"
              },
              "method_type": "instance"
            },
            {
              "name": "_compute_association_counts",
              "line": 304,
              "docstring": "Computes association counts per detection (cached).\n\nArgs:\n    associations: List of text-shape associations.\n\nReturns:\n    Dictionary mapping detection IDs to association counts.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "associations",
                    "type": "List[Association]"
                  }
                ],
                "return_type": "Dict[str, int]"
              },
              "method_type": "instance"
            },
            {
              "name": "_find_root_component",
              "line": 320,
              "docstring": "Identifies the root component of the assembly.\n\nSelects the root based on a weighted score combining component size,\nnumber of text associations, and spatial centrality. Larger components\nwith more labels and central positioning are preferred.\n\nArgs:\n    detections: List of all shape detections. Must contain at least one item.\n    associations: List of text-shape associations for scoring.\n    association_counts: Precomputed association counts per detection.\n\nReturns:\n    Detection object identified as the root component.\n\nNote:\n    Scoring formula:\n    (size * size_weight) + (assoc_count * assoc_weight) + (centrality * centrality_weight)\n    where weights are configured in HierarchyConfig and sum to 1.0.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "detections",
                    "type": "List[Detection]"
                  },
                  {
                    "name": "associations",
                    "type": "List[Association]"
                  },
                  {
                    "name": "association_counts",
                    "type": "Dict[str, int]"
                  }
                ],
                "return_type": "Detection"
              },
              "method_type": "instance"
            },
            {
              "name": "_infer_containment_assemblies",
              "line": 414,
              "docstring": "Infers containment relationships between components.\n\nPerforms complete nested containment analysis where each component\nis checked against all larger components to find the smallest,\nmost immediate enclosing parent.\n\nArgs:\n    detections: All shape detections.\n    spatial_index: Spatial index for efficient queries.\n    root: Root component.\n    processed: Set to track processed detection IDs.\n    parent_child_map: Map to track parent-child relationships for cycle detection.\n\nReturns:\n    List of Assembly objects representing containment relationships.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "detections",
                    "type": "List[Detection]"
                  },
                  {
                    "name": "spatial_index",
                    "type": "SpatialIndex"
                  },
                  {
                    "name": "root",
                    "type": "Detection"
                  },
                  {
                    "name": "processed",
                    "type": "Set[str]"
                  },
                  {
                    "name": "parent_child_map",
                    "type": "Dict[str, Set[str]]"
                  }
                ],
                "return_type": "List[Assembly]"
              },
              "method_type": "instance"
            },
            {
              "name": "_infer_fastening_assemblies",
              "line": 485,
              "docstring": "Infers fastening relationships between components.\n\nIdentifies fastener components and determines which components\nthey connect based on proximity and geometric alignment.\n\nArgs:\n    detections: All shape detections.\n    spatial_index: Spatial index for efficient queries.\n    processed: Set to track processed detection IDs.\n    parent_child_map: Map to track parent-child relationships for cycle detection.\n\nReturns:\n    List of Assembly objects representing fastening relationships.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "detections",
                    "type": "List[Detection]"
                  },
                  {
                    "name": "spatial_index",
                    "type": "SpatialIndex"
                  },
                  {
                    "name": "processed",
                    "type": "Set[str]"
                  },
                  {
                    "name": "parent_child_map",
                    "type": "Dict[str, Set[str]]"
                  }
                ],
                "return_type": "List[Assembly]"
              },
              "method_type": "instance"
            },
            {
              "name": "_handle_orphaned_components",
              "line": 559,
              "docstring": "Handles components not part of any explicit relationship.\n\nAttaches orphaned components to the root with an 'orphaned' relationship.\n\nArgs:\n    detections: All shape detections.\n    root: Root component.\n    processed: Set of processed detection IDs.\n\nReturns:\n    List of Assembly objects for orphaned components.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "detections",
                    "type": "List[Detection]"
                  },
                  {
                    "name": "root",
                    "type": "Detection"
                  },
                  {
                    "name": "processed",
                    "type": "Set[str]"
                  }
                ],
                "return_type": "List[Assembly]"
              },
              "method_type": "instance"
            },
            {
              "name": "_would_create_cycle",
              "line": 594,
              "docstring": "Checks if adding a parent-child relationship would create a cycle.\n\nArgs:\n    parent_id: Proposed parent detection ID.\n    child_id: Proposed child detection ID.\n    parent_child_map: Current parent-child relationships.\n\nReturns:\n    True if adding this relationship would create a cycle.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "parent_id",
                    "type": "str"
                  },
                  {
                    "name": "child_id",
                    "type": "str"
                  },
                  {
                    "name": "parent_child_map",
                    "type": "Dict[str, Set[str]]"
                  }
                ],
                "return_type": "bool"
              },
              "method_type": "instance"
            },
            {
              "name": "_calculate_containment_confidence",
              "line": 628,
              "docstring": "Calculates confidence score for containment relationship.\n\nBased on how well the child fits within the parent (overlap ratio).\n\nArgs:\n    parent_bbox: Parent bounding box.\n    child_bbox: Child bounding box.\n\nReturns:\n    Confidence score between 0.0 and 1.0.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "parent_bbox",
                    "type": "Any"
                  },
                  {
                    "name": "child_bbox",
                    "type": "Any"
                  }
                ],
                "return_type": "float"
              },
              "method_type": "instance"
            },
            {
              "name": "_calculate_fastening_confidence",
              "line": 656,
              "docstring": "Calculates confidence score for fastening relationship.\n\nBased on number of connected components and their proximity.\n\nArgs:\n    fastener: Fastener detection.\n    connected: List of connected component detections.\n\nReturns:\n    Confidence score between 0.0 and 1.0.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "fastener",
                    "type": "Detection"
                  },
                  {
                    "name": "connected",
                    "type": "List[Detection]"
                  }
                ],
                "return_type": "float"
              },
              "method_type": "instance"
            },
            {
              "name": "_find_connected_components",
              "line": 694,
              "docstring": "Finds components connected by a specific fastener.\n\nIdentifies components within proximity threshold of the fastener's center\npoint. Excludes other fasteners and applies geometric alignment checks.\n\nArgs:\n    fastener: Detection object representing a fastener (bolt, screw, etc.).\n    spatial_index: Spatial index for efficient proximity queries.\n\nReturns:\n    List of Detection objects for components connected by this fastener.\n    May be empty if no components are within proximity threshold.\n\nNote:\n    Proximity threshold is configurable via HierarchyConfig.fastener_proximity_px.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "fastener",
                    "type": "Detection"
                  },
                  {
                    "name": "spatial_index",
                    "type": "SpatialIndex"
                  }
                ],
                "return_type": "List[Detection]"
              },
              "method_type": "instance"
            },
            {
              "name": "_build_tree",
              "line": 741,
              "docstring": "Constructs hierarchical tree structure from assembly relationships.\n\nBuilds a nested dictionary representing the component hierarchy starting\nfrom the root. Each node contains the component ID, class name, and\nlist of child nodes with relationship types.\n\nArgs:\n    root: Root component detection to start tree traversal.\n    assemblies: List of assembly relationships defining parent-child connections.\n    detection_by_id: Dictionary mapping detection IDs to Detection objects.\n\nReturns:\n    HierarchyNode representing the root and all descendants.\n\nNote:\n    Uses depth-first traversal with cycle detection via visited set.\n    Tree depth is limited by max_tree_depth configuration.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "root",
                    "type": "Detection"
                  },
                  {
                    "name": "assemblies",
                    "type": "List[Assembly]"
                  },
                  {
                    "name": "detection_by_id",
                    "type": "Dict[str, Detection]"
                  }
                ],
                "return_type": "HierarchyNode"
              },
              "method_type": "instance"
            },
            {
              "name": "find_children",
              "line": 829,
              "docstring": "Finds all direct children of a component in the hierarchy.\n\nArgs:\n    hierarchy: ComponentHierarchy to search.\n    component_id: ID of the parent component.\n\nReturns:\n    List of child HierarchyNode objects.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "hierarchy",
                    "type": "ComponentHierarchy"
                  },
                  {
                    "name": "component_id",
                    "type": "str"
                  }
                ],
                "return_type": "List[HierarchyNode]"
              },
              "method_type": "instance"
            },
            {
              "name": "get_subtree",
              "line": 857,
              "docstring": "Gets the complete subtree rooted at a specific component.\n\nArgs:\n    hierarchy: ComponentHierarchy to search.\n    component_id: ID of the component to use as subtree root.\n\nReturns:\n    HierarchyNode representing the subtree, or None if not found.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "hierarchy",
                    "type": "ComponentHierarchy"
                  },
                  {
                    "name": "component_id",
                    "type": "str"
                  }
                ],
                "return_type": "Optional[HierarchyNode]"
              },
              "method_type": "instance"
            },
            {
              "name": "get_path_to_root",
              "line": 883,
              "docstring": "Gets the path from a component to the root.\n\nArgs:\n    hierarchy: ComponentHierarchy to search.\n    component_id: ID of the component to find path for.\n\nReturns:\n    List of component IDs from root to target (inclusive).\n    Empty list if component not found.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "hierarchy",
                    "type": "ComponentHierarchy"
                  },
                  {
                    "name": "component_id",
                    "type": "str"
                  }
                ],
                "return_type": "List[str]"
              },
              "method_type": "instance"
            },
            {
              "name": "get_all_components",
              "line": 914,
              "docstring": "Gets all component IDs in the hierarchy.\n\nArgs:\n    hierarchy: ComponentHierarchy to traverse.\n\nReturns:\n    List of all component IDs in depth-first order.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "hierarchy",
                    "type": "ComponentHierarchy"
                  }
                ],
                "return_type": "List[str]"
              },
              "method_type": "instance"
            },
            {
              "name": "get_components_by_relationship",
              "line": 933,
              "docstring": "Gets all component pairs with a specific relationship type.\n\nArgs:\n    hierarchy: ComponentHierarchy to search.\n    relationship_type: Type of relationship to filter by\n        ('contains', 'fastens', 'orphaned').\n\nReturns:\n    List of (parent_id, child_id) tuples.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "hierarchy",
                    "type": "ComponentHierarchy"
                  },
                  {
                    "name": "relationship_type",
                    "type": "str"
                  }
                ],
                "return_type": "List[Tuple[str, str]]"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        }
      },
      "functions": []
    },
    "src.drawing_intelligence.processing.image_preprocessor": {
      "file_path": "C:\\00Projects\\engineering_items_attributes_enrichment\\src\\drawing_intelligence\\processing\\image_preprocessor.py",
      "module_docstring": "Image preprocessing module for the Drawing Intelligence System.\n\nThis module provides specialized image preprocessing pipelines optimized for\nOCR and shape detection tasks on engineering drawings. It handles common image\nquality issues including skew, noise, poor contrast, and blur.\n\nClasses:\n    PreprocessConfig: Configuration container for preprocessing parameters.\n    ImagePreprocessor: Main preprocessing engine with dual-mode operation.\n\nTypical usage example:\n    config = PreprocessConfig(skew_threshold_degrees=1.0)\n    preprocessor = ImagePreprocessor(config)\n    ocr_image = preprocessor.preprocess_for_ocr(raw_image)\n    detection_image = preprocessor.preprocess_for_detection(raw_image)",
      "classes": {
        "PreprocessConfig": {
          "line": 33,
          "docstring": "Configuration for image preprocessing operations.\n\nThis configuration supports two distinct preprocessing modes: OCR-optimized\n(high contrast, aggressive noise reduction) and detection-optimized (edge\npreservation, mild enhancement). Each mode has its own preset dictionary.\n\nAttributes:\n    ocr_preset: Dictionary containing OCR preprocessing parameters. Keys include:\n        - adaptive_threshold_block_size (int): Block size for adaptive thresholding\n        - median_blur_kernel (int): Kernel size for median blur (must be odd)\n        - morphology_kernel_size (int): Kernel size for morphological operations\n        - apply_clahe (bool): Whether to apply CLAHE enhancement\n        - clahe_clip_limit (float): Clipping limit for CLAHE\n        - clahe_grid_size (Tuple[int, int]): Tile grid size for CLAHE\n    detection_preset: Dictionary containing detection preprocessing parameters.\n        Similar keys as ocr_preset but optimized for shape detection.\n    skew_threshold_degrees: Minimum rotation angle (in degrees) to trigger skew\n        correction. Values below this threshold are ignored to avoid unnecessary\n        processing. Default: 0.5\n    blur_threshold: Laplacian variance threshold for blur detection. Images with\n        variance below this value are considered too blurry. Default: 100.0\n    contrast_threshold: Minimum acceptable contrast score (std dev). Default: 20.0\n    brightness_min: Minimum acceptable mean brightness. Default: 30.0\n    brightness_max: Maximum acceptable mean brightness. Default: 225.0\n\nNote:\n    If ocr_preset or detection_preset are None, default values are set in\n    __post_init__. These defaults are tuned for standard engineering drawings\n    at 300 DPI.",
          "bases": [],
          "methods": [
            {
              "name": "__post_init__",
              "line": 74,
              "docstring": "Initialize default presets if not provided and validate configurations.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "_validate_preset",
              "line": 98,
              "docstring": "Validate that preset contains all required keys.\n\nArgs:\n    preset: Preset dictionary to validate.\n    preset_name: Name of preset for error messages.\n\nRaises:\n    ValueError: If required keys are missing.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "preset",
                    "type": "Dict[str, Any]"
                  },
                  {
                    "name": "preset_name",
                    "type": "str"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        },
        "ImagePreprocessor": {
          "line": 119,
          "docstring": "Image quality enhancement engine for OCR and shape detection.\n\nThis class provides two specialized preprocessing pipelines:\n1. OCR Pipeline: Optimized for text recognition with high contrast and\n   aggressive noise reduction.\n2. Detection Pipeline: Optimized for shape detection with edge preservation\n   and balanced enhancement.\n\nThe preprocessor handles common image quality issues including:\n- Skew/rotation correction using Hough line detection\n- Noise reduction via median filtering and morphological operations\n- Contrast enhancement using CLAHE and histogram equalization\n- Quality assessment (blur, contrast, brightness)\n\nAttributes:\n    config: Preprocessing configuration containing presets and thresholds.\n\nExample:\n    >>> config = PreprocessConfig(blur_threshold=150.0)\n    >>> preprocessor = ImagePreprocessor(config)\n    >>>\n    >>> # For OCR\n    >>> ocr_ready = preprocessor.preprocess_for_ocr(image)\n    >>>\n    >>> # For shape detection\n    >>> detection_ready = preprocessor.preprocess_for_detection(image)\n    >>>\n    >>> # Quality check\n    >>> quality = preprocessor.assess_image_quality(image)\n    >>> if not quality.is_acceptable:\n    >>>     print(f\"Quality issue: {quality.rejection_reason}\")",
          "bases": [],
          "methods": [
            {
              "name": "__init__",
              "line": 154,
              "docstring": "Initialize the image preprocessor with configuration.\n\nArgs:\n    config: Preprocessing configuration containing presets and thresholds.\n\nRaises:\n    ValueError: If config is None or invalid.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "config",
                    "type": "PreprocessConfig"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "preprocess_for_ocr",
              "line": 169,
              "docstring": "Apply preprocessing pipeline optimized for OCR.\n\nThis pipeline maximizes text clarity through aggressive enhancement:\n1. Grayscale conversion (if needed)\n2. Skew detection and correction using Hough line transform\n3. CLAHE contrast enhancement (optional, based on preset)\n4. Adaptive thresholding for binarization\n5. Noise reduction via median blur and morphological operations\n\nThe OCR preset uses smaller kernel sizes and higher contrast settings\ncompared to the detection preset.\n\nArgs:\n    image: Input image as numpy array. Can be BGR (3-channel) or\n        grayscale (single channel). Must be uint8 dtype.\n\nReturns:\n    Preprocessed grayscale image optimized for OCR, as uint8 numpy array.\n    The output is typically binary (0 or 255) after adaptive thresholding.\n\nRaises:\n    ValueError: If image is invalid (wrong dtype, empty, or contains NaN/Inf).\n\nExample:\n    >>> preprocessor = ImagePreprocessor(PreprocessConfig())\n    >>> bgr_image = cv2.imread('drawing.png')\n    >>> ocr_image = preprocessor.preprocess_for_ocr(bgr_image)\n    >>> # ocr_image is now ready for PaddleOCR or EasyOCR",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "image",
                    "type": "np.ndarray"
                  }
                ],
                "return_type": "np.ndarray"
              },
              "method_type": "instance"
            },
            {
              "name": "preprocess_for_detection",
              "line": 237,
              "docstring": "Apply preprocessing pipeline optimized for shape detection.\n\nThis pipeline balances enhancement with edge preservation:\n1. Grayscale conversion (if needed)\n2. Skew detection and correction\n3. Mild noise reduction using Non-Local Means denoising\n4. Histogram equalization for contrast\n\nThe detection preset avoids aggressive thresholding to preserve subtle\nedges needed for YOLO-based shape detection.\n\nArgs:\n    image: Input image as numpy array. Can be BGR (3-channel) or\n        grayscale (single channel). Must be uint8 dtype.\n\nReturns:\n    Preprocessed grayscale image optimized for detection, as uint8 numpy array.\n    The output maintains grayscale values (0-255) rather than binary.\n\nRaises:\n    ValueError: If image is invalid (wrong dtype, empty, or contains NaN/Inf).\n\nExample:\n    >>> preprocessor = ImagePreprocessor(PreprocessConfig())\n    >>> bgr_image = cv2.imread('drawing.png')\n    >>> detection_image = preprocessor.preprocess_for_detection(bgr_image)\n    >>> # detection_image is now ready for YOLOv8 inference",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "image",
                    "type": "np.ndarray"
                  }
                ],
                "return_type": "np.ndarray"
              },
              "method_type": "instance"
            },
            {
              "name": "detect_and_correct_skew",
              "line": 292,
              "docstring": "Detect and correct image skew/rotation using Hough line transform.\n\nThis method identifies the dominant angle of lines in the image and\nrotates the image to correct skew. It uses:\n1. Canny edge detection to find edges\n2. Hough line transform to detect lines\n3. Median angle calculation (robust to outliers)\n4. Rotation matrix with dimension adjustment to prevent cropping\n\nOnly applies correction if the detected skew exceeds the configured\nthreshold (skew_threshold_degrees).\n\nArgs:\n    image: Input grayscale image as numpy array (uint8).\n\nReturns:\n    Tuple containing:\n        - corrected_image: Rotated image if skew > threshold, else original\n        - skew_angle_degrees: Detected skew angle in degrees (negative = CW,\n          positive = CCW). Returns 0.0 if no lines detected or skew below\n          threshold.\n\nNote:\n    - Angles are filtered to [-45, 45] degrees to avoid 90\u00b0 misdetection\n    - Uses median instead of mean for robustness against outliers\n    - Rotation matrix is adjusted to prevent edge cropping\n    - Uses BORDER_REPLICATE to fill new areas after rotation\n\nExample:\n    >>> preprocessor = ImagePreprocessor(PreprocessConfig())\n    >>> corrected, angle = preprocessor.detect_and_correct_skew(gray_image)\n    >>> if abs(angle) > 0.1:\n    >>>     print(f\"Corrected skew of {angle:.2f} degrees\")",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "image",
                    "type": "np.ndarray"
                  }
                ],
                "return_type": "Tuple[np.ndarray, float]"
              },
              "method_type": "instance"
            },
            {
              "name": "_rotate_image",
              "line": 361,
              "docstring": "Rotate image by specified angle without cropping.\n\nCalculates the new bounding dimensions needed to contain the rotated\nimage and adjusts the rotation matrix accordingly\n\nimage and adjusts the rotation matrix accordingly. Uses cubic\ninterpolation for smooth results.\n\nArgs:\n    image: Input image as numpy array.\n    angle: Rotation angle in degrees. Positive values rotate\n        counterclockwise, negative values rotate clockwise.\n\nReturns:\n    Rotated image as numpy array with expanded dimensions to prevent cropping.\n\nNote:\n    - Uses INTER_CUBIC for high-quality interpolation\n    - Uses BORDER_REPLICATE to fill new border areas\n    - New dimensions calculated to fit entire rotated image",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "image",
                    "type": "np.ndarray"
                  },
                  {
                    "name": "angle",
                    "type": "float"
                  }
                ],
                "return_type": "np.ndarray"
              },
              "method_type": "instance"
            },
            {
              "name": "assess_image_quality",
              "line": 424,
              "docstring": "Evaluate image quality metrics for preprocessing pipeline decisions.\n\nComputes three key quality indicators:\n1. Blur metric: Laplacian variance (higher = sharper)\n2. Contrast score: Standard deviation of pixel intensities\n3. Brightness mean: Average pixel intensity\n\nImages failing quality thresholds are flagged as unacceptable with a\ndescriptive rejection reason. This helps route low-quality images to\nthe LLM-enhanced pipeline or reject them entirely.\n\nArgs:\n    image: Input image as numpy array. Can be BGR or grayscale (uint8).\n\nReturns:\n    QualityMetrics object containing:\n        - blur_metric: Laplacian variance (float)\n        - contrast_score: Std dev of pixel intensities (float)\n        - brightness_mean: Mean pixel intensity (float, 0-255)\n        - is_acceptable: Boolean indicating if quality meets thresholds\n        - rejection_reason: String describing failure reason (None if acceptable)\n\nRaises:\n    ValueError: If image is invalid (wrong dtype, empty, or contains NaN/Inf).\n\nNote:\n    Quality thresholds used:\n    - Blur: Must be >= blur_threshold (default 100.0)\n    - Contrast: Must be >= contrast_threshold (default 20.0)\n    - Brightness: Must be in range [brightness_min, brightness_max]\n\nExample:\n    >>> preprocessor = ImagePreprocessor(PreprocessConfig(blur_threshold=150))\n    >>> quality = preprocessor.assess_image_quality(image)\n    >>> if not quality.is_acceptable:\n    >>>     logger.warning(f\"Low quality: {quality.rejection_reason}\")\n    >>>     # Route to LLM-enhanced pipeline",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "image",
                    "type": "np.ndarray"
                  }
                ],
                "return_type": "QualityMetrics"
              },
              "method_type": "instance"
            },
            {
              "name": "_apply_adaptive_threshold",
              "line": 518,
              "docstring": "Apply adaptive thresholding for image binarization.\n\nUses Gaussian-weighted adaptive thresholding where each pixel's\nthreshold is calculated from the weighted mean of its neighborhood.\n\nArgs:\n    image: Input grayscale image as numpy array (uint8).\n    block_size: Size of pixel neighborhood for threshold calculation.\n        Must be odd and >= 3. If even, it will be incremented by 1.\n\nReturns:\n    Binary image (0 or 255 values) as uint8 numpy array.\n\nRaises:\n    ValueError: If block_size is too small or too large.\n\nNote:\n    - Uses Gaussian weighting (ADAPTIVE_THRESH_GAUSSIAN_C)\n    - Subtracts constant 2 from computed threshold\n    - Automatically adjusts even block_size to odd",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "image",
                    "type": "np.ndarray"
                  },
                  {
                    "name": "block_size",
                    "type": "int"
                  }
                ],
                "return_type": "np.ndarray"
              },
              "method_type": "instance"
            },
            {
              "name": "_apply_noise_reduction",
              "line": 572,
              "docstring": "Apply noise reduction using median filtering and morphological operations.\n\nTwo-stage noise reduction:\n1. Median blur to remove salt-and-pepper noise\n2. Morphological opening (removes small white noise) followed by\n   closing (fills small black holes)\n\nArgs:\n    image: Input image as numpy array (uint8).\n    median_kernel: Kernel size for median blur. Must be odd and >= 1.\n        If <= 1, median blur is skipped.\n    morphology_kernel: Kernel size for morphological operations.\n        If <= 0, morphological operations are skipped.\n\nReturns:\n    Denoised image as uint8 numpy array.\n\nNote:\n    Morphological operations use rectangular structuring elements.\n\nRaises:\n    ValueError: If median_kernel is even and > 1.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "image",
                    "type": "np.ndarray"
                  },
                  {
                    "name": "median_kernel",
                    "type": "int"
                  },
                  {
                    "name": "morphology_kernel",
                    "type": "int"
                  }
                ],
                "return_type": "np.ndarray"
              },
              "method_type": "instance"
            },
            {
              "name": "enhance_contrast",
              "line": 622,
              "docstring": "Enhance image contrast using linear transformation.\n\nApplies the formula: output = alpha * input + beta\nwhere beta is calculated to maintain mean brightness.\n\nThis is a global contrast adjustment, simpler than CLAHE but less\neffective for images with varying local contrast.\n\nArgs:\n    image: Input image as numpy array (uint8).\n    alpha: Contrast multiplier. Values > 1 increase contrast,\n        values < 1 decrease contrast. Default: 1.5\n\nReturns:\n    Enhanced image as uint8 numpy array with adjusted contrast.\n\nExample:\n    >>> preprocessor = ImagePreprocessor(PreprocessConfig())\n    >>> high_contrast = preprocessor.enhance_contrast(image, alpha=2.0)",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "image",
                    "type": "np.ndarray"
                  },
                  {
                    "name": "alpha",
                    "type": "float"
                  }
                ],
                "return_type": "np.ndarray"
              },
              "method_type": "instance"
            },
            {
              "name": "sharpen_image",
              "line": 651,
              "docstring": "Sharpen image using unsharp masking technique.\n\nCreates a sharpened version by subtracting a Gaussian-blurred version\nfrom the original image. This enhances edges and fine details.\n\nThe formula used: sharpened = 1.5 * original - 0.5 * blurred\n\nArgs:\n    image: Input image as numpy array (uint8).\n\nReturns:\n    Sharpened image as uint8 numpy array.\n\nNote:\n    Uses Gaussian blur with sigma=2.0. The enhancement is relatively\n    aggressive (1.5x original) which may amplify noise in low-quality images.\n\nExample:\n    >>> preprocessor = ImagePreprocessor(PreprocessConfig())\n    >>> sharp_image = preprocessor.sharpen_image(blurry_image)",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "image",
                    "type": "np.ndarray"
                  }
                ],
                "return_type": "np.ndarray"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        }
      },
      "functions": []
    },
    "src.drawing_intelligence.processing.ocr_pipeline": {
      "file_path": "C:\\00Projects\\engineering_items_attributes_enrichment\\src\\drawing_intelligence\\processing\\ocr_pipeline.py",
      "module_docstring": "OCR pipeline module for the Drawing Intelligence System.\n\nThis module provides a dual-engine OCR pipeline optimized for technical drawings.\nIt uses PaddleOCR as the primary engine for speed and accuracy, with EasyOCR\nas a fallback for low-confidence regions. Supports layout analysis to identify\ntitle blocks, tables, and text regions.\n\nTypical usage example:\n\n    config = OCRConfig(\n        primary_engine=\"paddleocr\",\n        confidence_threshold=0.85,\n        languages=[\"en\"]\n    )\n    pipeline = OCRPipeline(config)\n    result = pipeline.extract_text(image)\n    print(f\"Found {len(result.text_blocks)} text blocks\")",
      "classes": {
        "OCRConfig": {
          "line": 39,
          "docstring": "Configuration for OCR pipeline behavior and thresholds.\n\nControls the OCR engine selection, confidence thresholds for fallback\nprocessing, and performance options like GPU acceleration.\n\nAttributes:\n    primary_engine: Primary OCR engine name ('paddleocr' or 'easyocr').\n        Default: 'paddleocr'.\n    fallback_engine: Fallback OCR engine for low-confidence regions.\n        Default: 'easyocr'.\n    confidence_threshold: Minimum confidence (0.0-1.0) to avoid fallback\n        processing. Blocks below this threshold are reprocessed. Default: 0.85.\n    languages: List of ISO 639-1 language codes for OCR (e.g., ['en', 'de']).\n        If None, defaults to ['en'] in __post_init__.\n    layout_analysis: Whether to perform layout region classification\n        (title blocks, tables, etc.). Default: True.\n    use_gpu: Whether to use GPU acceleration if available. Will fall back\n        to CPU if GPU initialization fails. Default: True.\n\nRaises:\n    ValueError: If engine names are invalid or configuration is inconsistent.\n\nNote:\n    Different OCR engines have different language support. PaddleOCR supports\n    80+ languages, EasyOCR supports 80+ languages. Validate language codes\n    against engine capabilities before use.",
          "bases": [],
          "methods": [
            {
              "name": "__post_init__",
              "line": 75,
              "docstring": "Initialize and validate configuration.\n\nRaises:\n    ValueError: If engine names are invalid or threshold out of range.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        },
        "OCRPipeline": {
          "line": 108,
          "docstring": "Dual-engine OCR pipeline with intelligent fallback processing.\n\nThis class implements a two-stage OCR strategy:\n1. Primary OCR (PaddleOCR) processes the entire image for speed\n2. Low-confidence regions are cropped and reprocessed with fallback (EasyOCR)\n3. Results are merged, keeping the highest confidence text for each region\n\nThe pipeline also performs optional layout analysis to classify regions\nas title blocks, tables, or general text areas.\n\nAttributes:\n    config: OCR configuration object controlling engine behavior.\n    _primary_ocr: Lazily-initialized PaddleOCR instance (None until first use).\n    _fallback_ocr: Lazily-initialized EasyOCR Reader instance (None until first use).\n\nExample:\n    >>> config = OCRConfig(confidence_threshold=0.80)\n    >>> pipeline = OCRPipeline(config)\n    >>> result = pipeline.extract_text(image)\n    >>> print(f\"Extracted {len(result.text_blocks)} text blocks\")\n    >>> print(f\"Average confidence: {result.average_confidence:.2f}\")",
          "bases": [],
          "methods": [
            {
              "name": "__init__",
              "line": 132,
              "docstring": "Initialize OCR pipeline with configuration.\n\nOCR engines are not loaded immediately (lazy initialization) to save\nmemory and startup time. They are loaded on first use.\n\nArgs:\n    config: OCR configuration specifying engines, thresholds, and options.\n\nNote:\n    This method does not validate that OCR engines are installed.\n    Installation errors will be raised on first use during lazy loading.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "config",
                    "type": "OCRConfig"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "_primary_language",
              "line": 157,
              "docstring": "Get primary language for OCR engines.\n\nReturns:\n    First language from config.languages, or 'en' if list is empty.\n\nNote:\n    PaddleOCR only supports one language at initialization. This property\n    provides safe access to the primary language with a fallback default.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "str"
              },
              "method_type": "instance"
            },
            {
              "name": "extract_text",
              "line": 169,
              "docstring": "Extract text from image with bounding boxes and confidence scores.\n\nProcesses the image with the primary OCR engine, identifies low-confidence\nregions, and reprocesses them with the fallback engine. Performs layout\nanalysis if enabled in configuration.\n\nArgs:\n    image: Input image as numpy array. Can be grayscale (H, W) or\n        color (H, W, 3) in BGR format (OpenCV convention).\n\nReturns:\n    OCRResult containing:\n        - text_blocks: List of TextBlock objects with content and positions\n        - language_detected: Language code (from config.languages[0])\n        - layout_regions: List of classified layout regions (if enabled)\n        - average_confidence: Mean confidence across all text blocks\n\nRaises:\n    OCRError: If OCR extraction fails due to engine errors, invalid input,\n        or missing dependencies.\n\nExample:\n    >>> result = pipeline.extract_text(image)\n    >>> for block in result.text_blocks:\n    ...     if block.confidence < 0.9:\n    ...         print(f\"Low confidence: {block.content}\")\n\nNote:\n    Language is determined from config.languages, not auto-detected.\n    Auto-detection is not currently implemented.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "image",
                    "type": "np.ndarray"
                  }
                ],
                "return_type": "OCRResult"
              },
              "method_type": "instance"
            },
            {
              "name": "_run_primary_ocr",
              "line": 261,
              "docstring": "Run primary OCR engine (PaddleOCR) on full image.\n\nLazily initializes PaddleOCR if not already loaded. Converts PaddleOCR's\noutput format (bbox points + text + confidence) to standardized TextBlock\nobjects.\n\nArgs:\n    image: Input image (grayscale or BGR).\n\nReturns:\n    List of TextBlock objects extracted from the image. Empty list if no\n    text detected.\n\nRaises:\n    OCRError: If PaddleOCR is not installed, initialization fails, or\n        execution encounters an error.\n\nNote:\n    PaddleOCR returns bounding boxes as 4-point polygons which are\n    converted to axis-aligned rectangles (may lose rotation info).\n    Language is determined by initialization, not per-call.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "image",
                    "type": "np.ndarray"
                  }
                ],
                "return_type": "List[TextBlock]"
              },
              "method_type": "instance"
            },
            {
              "name": "_apply_fallback_ocr",
              "line": 326,
              "docstring": "Reprocess low-confidence regions with fallback OCR engine (EasyOCR).\n\nFor each low-confidence block, crops the region (with 5px padding),\nruns EasyOCR, and keeps the result only if confidence improved.\n\nArgs:\n    image: Full source image for cropping regions.\n    low_confidence_blocks: List of TextBlock objects below the confidence\n        threshold that need reprocessing.\n\nReturns:\n    List of TextBlock objects with either improved results (from EasyOCR)\n    or original results (if fallback didn't improve confidence). Length\n    always matches input list.\n\nNote:\n    - Each block is processed independently (no batching)\n    - If fallback OCR fails or finds no text, original block is kept\n    - Bounding box coordinates are preserved from original detection",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "image",
                    "type": "np.ndarray"
                  },
                  {
                    "name": "low_confidence_blocks",
                    "type": "List[TextBlock]"
                  }
                ],
                "return_type": "List[TextBlock]"
              },
              "method_type": "instance"
            },
            {
              "name": "_initialize_primary_ocr",
              "line": 404,
              "docstring": "Lazy initialization of PaddleOCR engine.\n\nCreates PaddleOCR instance with configuration from self.config. Uses\nangle classification for better text orientation handling. Attempts\nGPU initialization first, falls back to CPU if GPU unavailable.\n\nRaises:\n    OCRError: If PaddleOCR package is not installed or initialization\n        fails on both GPU and CPU.\n\nNote:\n    PaddleOCR models are downloaded automatically on first use (~100MB).\n    Language is set from config.languages[0].",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "_initialize_fallback_ocr",
              "line": 469,
              "docstring": "Lazy initialization of EasyOCR engine.\n\nCreates EasyOCR Reader instance with languages from self.config. Models\nare downloaded automatically if not cached. Attempts GPU initialization\nfirst, falls back to CPU if GPU unavailable.\n\nRaises:\n    OCRError: If EasyOCR package is not installed or initialization fails\n        on both GPU and CPU.\n\nNote:\n    EasyOCR downloads language models on first use (~100MB per language).",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "_points_to_bbox",
              "line": 527,
              "docstring": "Convert OCR polygon points to axis-aligned bounding box.\n\nTakes a list of 2D points (typically 4 corners of a quadrilateral) and\ncomputes the minimal axis-aligned rectangle containing all points.\nCoordinates are rounded to nearest integer pixels.\n\nArgs:\n    points: List of [x, y] coordinate pairs, typically 4 corners from\n        OCR engine output.\n\nReturns:\n    BoundingBox with top-left corner (x, y) and dimensions (width, height)\n    in integer pixel coordinates.\n\nNote:\n    This conversion loses rotation information. A rotated text region\n    will have a larger bounding box than its tight oriented bounding box.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "points",
                    "type": "List[List[float]]"
                  }
                ],
                "return_type": "BoundingBox"
              },
              "method_type": "instance"
            },
            {
              "name": "_normalize_text",
              "line": 558,
              "docstring": "Normalize OCR output text by fixing common errors.\n\nApplies whitespace normalization and corrects common OCR misrecognitions\n(e.g., pipe character '|' misread as letter 'I').\n\nArgs:\n    text: Raw text string from OCR engine.\n\nReturns:\n    Normalized text with whitespace cleaned and artifacts corrected.\n\nNote:\n    Uses text_utils.normalize_whitespace() for consistent whitespace handling.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "text",
                    "type": "str"
                  }
                ],
                "return_type": "str"
              },
              "method_type": "instance"
            },
            {
              "name": "_classify_layout_regions",
              "line": 581,
              "docstring": "Classify layout regions using position-based heuristics.\n\nIdentifies title blocks (bottom-right corner heuristic) and updates\ntext_blocks region_type in place. Table detection is mentioned but\nnot yet implemented.\n\nArgs:\n    image: Input image for dimension calculations.\n    text_blocks: List of TextBlock objects to classify. region_type\n        attributes are modified in place.\n\nReturns:\n    List of LayoutRegion objects for identified regions (currently\n    only title blocks). Empty list if no regions identified.\n\nNote:\n    - Title block heuristic: x > 60% width AND y > 70% height\n    - This is simplified; production should use ISO/ANSI drawing standards\n    - Table detection is not implemented (TODO)",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "image",
                    "type": "np.ndarray"
                  },
                  {
                    "name": "text_blocks",
                    "type": "List[TextBlock]"
                  }
                ],
                "return_type": "List[LayoutRegion]"
              },
              "method_type": "instance"
            },
            {
              "name": "_merge_bboxes_simple",
              "line": 640,
              "docstring": "Merge multiple bounding boxes into a single encompassing box.\n\nComputes the minimal axis-aligned bounding box that contains all\ninput bounding boxes.\n\nArgs:\n    bboxes: List of BoundingBox objects to merge.\n\nReturns:\n    BoundingBox that encompasses all input boxes.\n\nRaises:\n    ValueError: If bboxes list is empty.\n\nNote:\n    This is a simple implementation that replaces the missing\n    merge_bboxes utility function from geometry_utils.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "bboxes",
                    "type": "List[BoundingBox]"
                  }
                ],
                "return_type": "BoundingBox"
              },
              "method_type": "instance"
            },
            {
              "name": "_crop_region",
              "line": 670,
              "docstring": "Crop a region from image with padding, handling boundary conditions.\n\nArgs:\n    image: Source image to crop from.\n    bbox: Bounding box defining the region to crop.\n    padding: Pixels to add around the bbox (default: 5).\n\nReturns:\n    Cropped image region as numpy array.\n\nNote:\n    Automatically clips coordinates to image boundaries.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "image",
                    "type": "np.ndarray"
                  },
                  {
                    "name": "bbox",
                    "type": "BoundingBox"
                  },
                  {
                    "name": "padding",
                    "type": "int"
                  }
                ],
                "return_type": "np.ndarray"
              },
              "method_type": "instance"
            },
            {
              "name": "_calculate_average_confidence",
              "line": 693,
              "docstring": "Calculate average confidence across text blocks.\n\nArgs:\n    text_blocks: List of TextBlock objects.\n\nReturns:\n    Average confidence (0.0-1.0), or 0.0 if list is empty.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "text_blocks",
                    "type": "List[TextBlock]"
                  }
                ],
                "return_type": "float"
              },
              "method_type": "instance"
            },
            {
              "name": "_merge_improved_blocks",
              "line": 706,
              "docstring": "Merge original and improved blocks, replacing by text_id.\n\nUses dictionary lookup for O(1) replacement efficiency.\n\nArgs:\n    original_blocks: All text blocks from primary OCR.\n    improved_blocks: Blocks that were reprocessed with fallback OCR.\n\nReturns:\n    Merged list with improved blocks replacing their originals.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "original_blocks",
                    "type": "List[TextBlock]"
                  },
                  {
                    "name": "improved_blocks",
                    "type": "List[TextBlock]"
                  }
                ],
                "return_type": "List[TextBlock]"
              },
              "method_type": "instance"
            },
            {
              "name": "detect_language",
              "line": 736,
              "docstring": "Detect language from text sample using langdetect library.\n\nUses statistical language detection on text content. Requires langdetect\npackage to be installed.\n\nArgs:\n    text_sample: Sample text string for language detection. Longer samples\n        (100+ characters) provide more accurate results.\n\nReturns:\n    ISO 639-1 language code (e.g., 'en', 'de', 'fr'). Returns 'en' if\n    detection fails or text_sample is too short.\n\nNote:\n    Detection accuracy improves with longer text samples. Very short\n    samples may produce incorrect results.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "text_sample",
                    "type": "str"
                  }
                ],
                "return_type": "str"
              },
              "method_type": "instance"
            },
            {
              "name": "cleanup",
              "line": 768,
              "docstring": "Clean up OCR engine resources.\n\nExplicitly releases OCR engine instances to free memory. Useful for\nlong-running processes or when processing is complete.\n\nNote:\n    After calling cleanup(), the engines will be reinitialized on next use.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        }
      },
      "functions": []
    },
    "src.drawing_intelligence.processing.pdf_processor": {
      "file_path": "C:\\00Projects\\engineering_items_attributes_enrichment\\src\\drawing_intelligence\\processing\\pdf_processor.py",
      "module_docstring": "PDF processing module for the Drawing Intelligence System.\n\nThis module provides functionality to extract pages as images and embedded text\nfrom PDF files using PyMuPDF (fitz). It supports configurable DPI rendering,\npage limits, grayscale conversion, parallel processing, and comprehensive validation.\n\nThe module implements resource management best practices using context managers\nand provides both high-level batch processing and low-level page extraction APIs.\n\nClasses:\n    PDFConfig: Immutable configuration dataclass for PDF processing parameters.\n    PDFProcessor: Main processor class for PDF extraction operations.\n\nExceptions:\n    PDFEncryptionError: Raised when PDF is password-protected or encrypted.\n    PDFPageRenderError: Raised when page rendering fails.\n    PDFCorruptedError: Raised when PDF file is corrupted or invalid.\n\nTypical usage example:\n    config = PDFConfig(dpi=300, max_pages=10)\n    processor = PDFProcessor(config)\n\n    # Extract pages with progress tracking\n    def on_progress(current, total):\n        print(f\"Processing page {current}/{total}\")\n\n    pages = processor.extract_pages(\"drawing.pdf\", progress_callback=on_progress)\n\n    # Or use generator for memory efficiency\n    for page in processor.extract_pages_iter(\"drawing.pdf\"):\n        process_page(page)",
      "classes": {
        "PDFEncryptionError": {
          "line": 77,
          "docstring": "Raised when attempting to process encrypted or password-protected PDFs.",
          "bases": [
            "PDFProcessingError"
          ],
          "methods": [
            {
              "name": "__init__",
              "line": 80,
              "docstring": null,
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "message",
                    "type": "str"
                  }
                ],
                "return_type": null
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        },
        "PDFPageRenderError": {
          "line": 84,
          "docstring": "Raised when PDF page rendering fails.",
          "bases": [
            "PDFProcessingError"
          ],
          "methods": [
            {
              "name": "__init__",
              "line": 87,
              "docstring": null,
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "message",
                    "type": "str"
                  },
                  {
                    "name": "page_number",
                    "type": "Optional[int]"
                  },
                  {
                    "name": "recoverable",
                    "type": "bool"
                  }
                ],
                "return_type": null
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        },
        "PDFCorruptedError": {
          "line": 93,
          "docstring": "Raised when PDF file is corrupted or has invalid structure.",
          "bases": [
            "PDFProcessingError"
          ],
          "methods": [
            {
              "name": "__init__",
              "line": 96,
              "docstring": null,
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "message",
                    "type": "str"
                  }
                ],
                "return_type": null
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        },
        "TextBlock": {
          "line": 106,
          "docstring": "Represents a text block extracted from PDF with spatial coordinates.\n\nAttributes:\n    text: The extracted text content (whitespace-stripped).\n    bbox: Bounding box in pixels (x0, y0, x1, y1) where (x0, y0) is\n        top-left corner and (x1, y1) is bottom-right corner.",
          "bases": [],
          "methods": [],
          "nested_classes": []
        },
        "PDFConfig": {
          "line": 125,
          "docstring": "Immutable configuration for PDF processing operations.\n\nControls rendering quality, file size limits, and output format preferences\nfor PDF page extraction and text processing. Once created, configuration\ncannot be modified to ensure thread safety.\n\nAttributes:\n    dpi: Resolution for page rendering in dots per inch. Higher values\n        produce better quality but increase memory usage quadratically.\n        Default is 300 DPI (standard for document processing).\n        Must be between 72-1200.\n    max_file_size_mb: Maximum allowed PDF file size in megabytes. Files\n        exceeding this limit are rejected to prevent resource exhaustion.\n        Default is 50 MB. Must be positive.\n    max_pages: Maximum number of pages to process from a PDF. Prevents\n        processing of extremely large documents. Default is 20 pages.\n        Must be positive.\n    convert_to_grayscale: If True, convert rendered images to grayscale.\n        Reduces memory usage (~66% reduction) and may improve OCR\n        performance. Default is True.\n    parallel_workers: Number of worker threads for parallel page processing.\n        Default is 1 (sequential). Set to None for auto-detection based on\n        CPU count. Use with caution on memory-constrained systems.\n\nRaises:\n    ValueError: If DPI is outside acceptable range or other parameters\n        are invalid.\n\nNote:\n    Memory usage scales with DPI\u00b2: 300 DPI uses 4x memory vs 150 DPI.\n    Parallel processing multiplies memory usage by worker count.",
          "bases": [],
          "methods": [
            {
              "name": "__post_init__",
              "line": 165,
              "docstring": "Validate configuration parameters after initialization.\n\nRaises:\n    ValueError: If any parameter is outside acceptable range.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "with_overrides",
              "line": 187,
              "docstring": "Create new config with specified parameter overrides.\n\nArgs:\n    **kwargs: Parameters to override (dpi, max_pages, etc.).\n\nReturns:\n    New PDFConfig instance with overridden parameters.\n\nExample:\n    >>> config = PDFConfig(dpi=300)\n    >>> high_res_config = config.with_overrides(dpi=600)",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "PDFConfig"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        },
        "PDFProcessor": {
          "line": 216,
          "docstring": "Extracts pages and embedded text from PDF files.\n\nUses PyMuPDF (fitz) for high-performance PDF processing with configurable\nrendering parameters. Supports page-by-page extraction with embedded text\nblock coordinates, metadata extraction, parallel processing, and\ncomprehensive validation.\n\nThe processor handles PDF coordinate system conversion (points to pixels),\nmultiple color formats (grayscale, RGB, RGBA), and includes safeguards\nagainst corrupted or encrypted files.\n\nAttributes:\n    config: Immutable PDF processing configuration controlling DPI, limits,\n        and format preferences.\n\nExample:\n    >>> config = PDFConfig(dpi=300, max_pages=10)\n    >>> processor = PDFProcessor(config)\n    >>> pages = processor.extract_pages(\"drawing.pdf\")\n    >>> print(f\"Extracted {len(pages)} pages\")",
          "bases": [],
          "methods": [
            {
              "name": "__init__",
              "line": 239,
              "docstring": "Initialize PDF processor with specified configuration.\n\nArgs:\n    config: PDF processing configuration object controlling rendering\n        parameters, file size limits, and format preferences.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "config",
                    "type": "PDFConfig"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "_open_pdf_validated",
              "line": 253,
              "docstring": "Context manager for validated PDF document handling.\n\nPerforms comprehensive validation checks and safely opens/closes\nthe PDF document. Eliminates code duplication across methods.\n\nArgs:\n    pdf_path: Path to PDF file to open.\n\nYields:\n    Opened fitz.Document object ready for processing.\n\nRaises:\n    PDFProcessingError: If validation fails.\n    PDFEncryptionError: If PDF is encrypted or password-protected.\n    PDFCorruptedError: If PDF structure is invalid.\n    IOError: If file cannot be read.\n\nExample:\n    >>> with self._open_pdf_validated(pdf_path) as doc:\n    ...     pages = len(doc)",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "pdf_path",
                    "type": "PathType"
                  }
                ],
                "return_type": "Generator[fitz.Document, None, None]"
              },
              "method_type": "instance"
            },
            {
              "name": "extract_pages",
              "line": 318,
              "docstring": "Extract all pages from PDF as images with embedded text blocks.\n\nRenders each page to a numpy image array at the configured DPI and\nextracts embedded text blocks with bounding box coordinates. Validates\nfile before processing and enforces page count limits.\n\nArgs:\n    pdf_path: Path to the PDF file to process. Must be a valid,\n        non-encrypted PDF file within size limits.\n    progress_callback: Optional callback function(current, total) called\n        after each page is processed. Useful for progress bars.\n    **config_overrides: Temporary config overrides (e.g., dpi=600).\n\nReturns:\n    List of PDFPage objects, each containing:\n        - Rendered page image as numpy array\n        - Page dimensions (width, height) in pixels\n        - Embedded text blocks with bounding boxes\n        - Page metadata (rotation, media box)\n\nRaises:\n    PDFProcessingError: If file validation fails or processing fails.\n    PDFEncryptionError: If PDF is encrypted.\n    PDFCorruptedError: If PDF structure is invalid.\n    PDFPageRenderError: If page rendering fails.\n\nNote:\n    Processing stops at max_pages limit (configured in PDFConfig).\n    Pages beyond this limit are logged but not processed. If all pages\n    fail, raises PDFProcessingError with details.\n\nExample:\n    >>> def progress(current, total):\n    ...     print(f\"{current}/{total}\")\n    >>> pages = processor.extract_pages(\"doc.pdf\", progress_callback=progress)",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "pdf_path",
                    "type": "PathType"
                  },
                  {
                    "name": "progress_callback",
                    "type": "Optional[ProgressCallback]"
                  }
                ],
                "return_type": "List[PDFPage]"
              },
              "method_type": "instance"
            },
            {
              "name": "_extract_pages_sequential",
              "line": 408,
              "docstring": "Extract pages sequentially (single-threaded).\n\nArgs:\n    doc: Opened PDF document.\n    num_pages: Number of pages to extract.\n    config: Configuration to use.\n    progress_callback: Optional progress callback.\n\nReturns:\n    Tuple of (successfully extracted pages, list of (page_num, error) tuples).",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "doc",
                    "type": "fitz.Document"
                  },
                  {
                    "name": "num_pages",
                    "type": "int"
                  },
                  {
                    "name": "config",
                    "type": "PDFConfig"
                  },
                  {
                    "name": "progress_callback",
                    "type": "Optional[ProgressCallback]"
                  }
                ],
                "return_type": "Tuple[List[PDFPage], List[Tuple[int, str]]]"
              },
              "method_type": "instance"
            },
            {
              "name": "_extract_pages_parallel",
              "line": 446,
              "docstring": "Extract pages in parallel using thread pool.\n\nArgs:\n    doc: Opened PDF document.\n    num_pages: Number of pages to extract.\n    config: Configuration to use.\n    progress_callback: Optional progress callback.\n\nReturns:\n    Tuple of (successfully extracted pages, list of (page_num, error) tuples).\n\nNote:\n    Pages are returned in order despite parallel processing.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "doc",
                    "type": "fitz.Document"
                  },
                  {
                    "name": "num_pages",
                    "type": "int"
                  },
                  {
                    "name": "config",
                    "type": "PDFConfig"
                  },
                  {
                    "name": "progress_callback",
                    "type": "Optional[ProgressCallback]"
                  }
                ],
                "return_type": "Tuple[List[PDFPage], List[Tuple[int, str]]]"
              },
              "method_type": "instance"
            },
            {
              "name": "_extract_single_page",
              "line": 502,
              "docstring": "Extract a single page with all its data.\n\nArgs:\n    page: PyMuPDF page object.\n    page_num: Zero-based page number.\n    config: Configuration to use.\n\nReturns:\n    Extracted PDFPage object.\n\nRaises:\n    PDFPageRenderError: If page rendering or extraction fails.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "page",
                    "type": "fitz.Page"
                  },
                  {
                    "name": "page_num",
                    "type": "int"
                  },
                  {
                    "name": "config",
                    "type": "PDFConfig"
                  }
                ],
                "return_type": "PDFPage"
              },
              "method_type": "instance"
            },
            {
              "name": "extract_pages_iter",
              "line": 547,
              "docstring": "Extract pages as generator for memory-efficient streaming.\n\nYields pages one at a time without loading entire document into memory.\nUseful for processing very large PDFs where memory is constrained.\n\nArgs:\n    pdf_path: Path to the PDF file to process.\n    progress_callback: Optional callback function(current, total) called\n        after each page is yielded.\n    **config_overrides: Temporary config overrides (e.g., dpi=600).\n\nYields:\n    PDFPage objects one at a time.\n\nRaises:\n    PDFProcessingError: If file validation fails.\n    PDFEncryptionError: If PDF is encrypted.\n    PDFCorruptedError: If PDF structure is invalid.\n\nNote:\n    Failed pages are logged but skipped. Generator continues to next page.\n\nExample:\n    >>> for page in processor.extract_pages_iter(\"large.pdf\"):\n    ...     process_page(page)\n    ...     del page  # Free memory immediately",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "pdf_path",
                    "type": "PathType"
                  },
                  {
                    "name": "progress_callback",
                    "type": "Optional[ProgressCallback]"
                  }
                ],
                "return_type": "Iterator[PDFPage]"
              },
              "method_type": "instance"
            },
            {
              "name": "_render_page_to_image",
              "line": 608,
              "docstring": "Render PDF page to numpy image array at configured DPI.\n\nConverts a PyMuPDF page object to a numpy array suitable for image\nprocessing. Handles multiple color formats (grayscale, RGB, RGBA) and\nconverts to BGR format for OpenCV compatibility when needed.\n\nArgs:\n    page: PyMuPDF page object to render.\n    config: Configuration specifying DPI and color preferences.\n\nReturns:\n    Tuple containing:\n        - Numpy array with rendered page image:\n            * Grayscale: (height, width) uint8\n            * Color: (height, width, 3) BGR uint8\n        - Tuple of (width, height) in pixels at configured DPI\n\nRaises:\n    PDFPageRenderError: If page has unsupported color format or\n        rendering fails.\n\nNote:\n    PDF default resolution is 72 DPI. This method scales rendering\n    according to config.dpi using zoom matrix transformation.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "page",
                    "type": "fitz.Page"
                  },
                  {
                    "name": "config",
                    "type": "PDFConfig"
                  }
                ],
                "return_type": "Tuple[NDArray[np.uint8], Tuple[int, int]]"
              },
              "method_type": "instance"
            },
            {
              "name": "_extract_text_blocks",
              "line": 685,
              "docstring": "Extract text blocks with bounding box coordinates from page.\n\nRetrieves all text blocks from the page along with their spatial\npositions. Empty text blocks are filtered out. Coordinates are\nconverted from PDF points (72 DPI) to pixels at the configured DPI.\n\nArgs:\n    page: PyMuPDF page object from which to extract text.\n    config: Configuration specifying DPI for coordinate conversion.\n\nReturns:\n    List of TextBlock objects with text content and pixel coordinates.\n\nNote:\n    Only blocks with non-empty text are returned. Bounding boxes\n    represent the minimum rectangle enclosing the text block.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "page",
                    "type": "fitz.Page"
                  },
                  {
                    "name": "config",
                    "type": "PDFConfig"
                  }
                ],
                "return_type": "List[TextBlock]"
              },
              "method_type": "instance"
            },
            {
              "name": "extract_embedded_text",
              "line": 726,
              "docstring": "Extract all embedded text from PDF without spatial coordinates.\n\nProvides fast text extraction when bounding box information is not\nneeded. Useful for quick text searches, content preview, or text-only\nanalysis. Does not render pages to images.\n\nArgs:\n    pdf_path: Path to PDF file to extract text from. Must be valid,\n        non-encrypted PDF within size limits.\n    **config_overrides: Temporary config overrides (e.g., max_pages=100).\n\nReturns:\n    All text from all pages concatenated with double newline separators\n    between pages. Returns None if no text is found in any page.\n\nRaises:\n    PDFProcessingError: If file validation fails.\n    PDFEncryptionError: If PDF is encrypted.\n    PDFCorruptedError: If PDF structure is invalid.\n\nNote:\n    Much faster than extract_pages() since it doesn't render images.\n    Respects max_pages limit for consistency with other methods.\n    If a page fails text extraction, it's logged and skipped.\n\nExample:\n    >>> text = processor.extract_embedded_text(\"document.pdf\")\n    >>> if text:\n    ...     print(f\"Found {len(text)} characters\")",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "pdf_path",
                    "type": "PathType"
                  }
                ],
                "return_type": "Optional[str]"
              },
              "method_type": "instance"
            },
            {
              "name": "get_pdf_metadata",
              "line": 791,
              "docstring": "Extract metadata from PDF document.\n\nRetrieves document properties including title, author, creation date,\nand other metadata fields. Useful for audit trails, document\nclassification, and provenance tracking.\n\nArgs:\n    pdf_path: Path to PDF file. Must be valid, non-encrypted PDF.\n\nReturns:\n    Dictionary containing metadata fields (all snake_case):\n        - title (str): Document title\n        - author (str): Document author\n        - subject (str): Document subject\n        - creator (str): Application that created the document\n        - producer (str): PDF producer software\n        - creation_date (str): Creation timestamp (ISO format if parseable)\n        - modification_date (str): Last modification timestamp\n        - num_pages (int): Total number of pages\n        - format (str): PDF format version\n    All string fields return empty strings if not present in metadata.\n\nRaises:\n    PDFProcessingError: If file validation fails or PDF cannot be opened.\n    PDFEncryptionError: If PDF is encrypted.\n    PDFCorruptedError: If PDF structure is invalid.\n\nNote:\n    PyMuPDF returns camelCase keys; this method standardizes to\n    snake_case for Python conventions.\n\nExample:\n    >>> metadata = processor.get_pdf_metadata(\"drawing.pdf\")\n    >>> print(f\"Title: {metadata['title']}, Pages: {metadata['num_pages']}\")",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "pdf_path",
                    "type": "PathType"
                  }
                ],
                "return_type": "Dict[str, Union[str, int]]"
              },
              "method_type": "instance"
            },
            {
              "name": "extract_pages_from_directory",
              "line": 845,
              "docstring": "Batch process all PDFs in a directory.\n\nExtracts pages from all PDF files matching the pattern in the specified\ndirectory. Useful for bulk processing of drawing archives.\n\nArgs:\n    directory_path: Path to directory containing PDF files.\n    pattern: Glob pattern for matching PDF files (default: \"*.pdf\").\n    recursive: If True, search subdirectories recursively.\n    progress_callback: Optional callback(filename, current_file, total_files)\n        called before processing each file.\n    **config_overrides: Temporary config overrides applied to all files.\n\nReturns:\n    Dictionary mapping file paths (as strings) to lists of extracted\n    PDFPage objects. Files that fail processing are omitted from results\n    but logged as errors.\n\nRaises:\n    ValueError: If directory_path doesn't exist or is not a directory.\n\nExample:\n    >>> def progress(filename, current, total):\n    ...     print(f\"Processing {filename} ({current}/{total})\")\n    >>> results = processor.extract_pages_from_directory(\n    ...     \"drawings/\",\n    ...     progress_callback=progress\n    ... )\n    >>> print(f\"Processed {len(results)} files\")",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "directory_path",
                    "type": "PathType"
                  },
                  {
                    "name": "pattern",
                    "type": "str"
                  },
                  {
                    "name": "recursive",
                    "type": "bool"
                  },
                  {
                    "name": "progress_callback",
                    "type": "Optional[Callable[[str, int, int], None]]"
                  }
                ],
                "return_type": "Dict[str, List[PDFPage]]"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        }
      },
      "functions": [
        {
          "name": "_demo_usage",
          "line": 934,
          "docstring": "Demonstrate basic usage of PDFProcessor for manual testing.",
          "signature": {
            "parameters": [],
            "return_type": null
          }
        }
      ]
    },
    "src.drawing_intelligence.processing.shape_detector": {
      "file_path": "C:\\00Projects\\engineering_items_attributes_enrichment\\src\\drawing_intelligence\\processing\\shape_detector.py",
      "module_docstring": "Shape detection module for the Drawing Intelligence System.\n\nThis module provides YOLOv8-based object detection for identifying and classifying\nmechanical component shapes in engineering drawings. Supports both single-image\nand batch processing with configurable confidence thresholds and NMS parameters.\n\nClasses:\n    DetectionConfig: Configuration dataclass for shape detection parameters.\n    ShapeDetector: Main detector class implementing YOLOv8 inference pipeline.\n\nTypical usage example:\n    config = DetectionConfig(\n        model_path=\"models/yolov8_shapes.pt\",\n        confidence_threshold=0.5,\n        device=\"cuda\"\n    )\n    detector = ShapeDetector(config)\n\n    # Single image processing\n    result = detector.detect_shapes(image)\n\n    # Batch processing with context manager (recommended for GPU)\n    with detector:\n        results = detector.detect_shapes_batch(images)",
      "classes": {
        "DetectionConfig": {
          "line": 50,
          "docstring": "Configuration parameters for YOLOv8 shape detection.\n\nAttributes:\n    model_path: Absolute or relative path to YOLOv8 model weights file (.pt).\n    confidence_threshold: Minimum confidence score for detections during\n        inference. Must be in range [0.0, 1.0]. Default: 0.45.\n    nms_threshold: Intersection-over-Union threshold for Non-Maximum\n        Suppression. Must be in range [0.0, 1.0]. Default: 0.45.\n    device: Compute device for inference. Must be one of: 'cuda', 'cpu',\n        'mps'. Default: 'cuda'. Falls back to 'cpu' if unavailable.\n    batch_size: Number of images to process simultaneously in batch mode.\n        Must be >= 1. Default: 8.\n    max_det: Maximum number of detections to keep per image. Prevents\n        memory issues with extremely complex drawings. Must be >= 1.\n        Default: 300.\n    confidence_high_threshold: Threshold for classifying detections as\n        \"high confidence\" in summary statistics. Default: 0.7.\n    confidence_medium_threshold: Threshold for classifying detections as\n        \"medium confidence\" in summary statistics. Default: 0.5.\n    check_batch_consistency: If True, validates that all images in a batch\n        have the same dimensions. Default: True.\n    progress_callback: Optional callback function for batch progress\n        reporting. Called with (current_index, total_images). Default: None.\n\nRaises:\n    ValueError: If any threshold values are outside valid ranges or if\n        device is not a supported value.",
          "bases": [],
          "methods": [
            {
              "name": "__post_init__",
              "line": 91,
              "docstring": "Validate configuration parameters after initialization.\n\nRaises:\n    ValueError: If any configuration parameter is invalid.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        },
        "ShapeDetector": {
          "line": 140,
          "docstring": "YOLOv8-based shape detector for mechanical component recognition.\n\nDetects and classifies 20 types of mechanical components including:\nfasteners (bolt, screw, nut, washer, pin), transmission elements (bearing,\ngear, pulley, shaft), electromechanical (motor, sensor, controller),\nhydraulic/pneumatic (valve, pump, cylinder), and structural (bracket,\nhousing, connector, spring, fastener).\n\nThe detector uses lazy model loading to minimize memory usage and supports\nboth single-image and batch processing modes. Implements context manager\nprotocol for automatic resource cleanup.\n\nAttributes:\n    config: Detection configuration parameters.\n\nExample:\n    >>> config = DetectionConfig(model_path=\"yolov8n.pt\")\n    >>> detector = ShapeDetector(config)\n    >>> result = detector.detect_shapes(image)\n    >>> print(f\"Found {result.summary.total_detections} shapes\")\n\n    >>> # Recommended for batch processing with GPU\n    >>> with ShapeDetector(config) as detector:\n    ...     results = detector.detect_shapes_batch(images)\n\nNote:\n    Input images should be NumPy arrays with:\n    - Format: BGR (H, W, 3), RGB (H, W, 3), or grayscale (H, W)\n    - Dtype: uint8\n    - Value range: [0, 255]\n\n    Common pitfalls:\n    - OpenCV loads images in BGR format by default\n    - Normalized float images [0.0, 1.0] will fail validation\n    - RGBA images (4 channels) are not supported",
          "bases": [],
          "methods": [
            {
              "name": "__init__",
              "line": 178,
              "docstring": "Initialize shape detector with configuration.\n\nArgs:\n    config: Detection configuration containing model path, thresholds,\n        and device settings.\n\nRaises:\n    ShapeDetectionError: If model path is invalid or inaccessible.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "config",
                    "type": "DetectionConfig"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "__enter__",
              "line": 203,
              "docstring": "Enter context manager.\n\nReturns:\n    Self for use in with statement.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "'ShapeDetector'"
              },
              "method_type": "instance"
            },
            {
              "name": "__exit__",
              "line": 211,
              "docstring": "Exit context manager and cleanup resources.\n\nArgs:\n    exc_type: Exception type if an exception occurred.\n    exc_val: Exception value if an exception occurred.\n    exc_tb: Exception traceback if an exception occurred.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "exc_type",
                    "type": "Optional[type]"
                  },
                  {
                    "name": "exc_val",
                    "type": "Optional[Exception]"
                  },
                  {
                    "name": "exc_tb",
                    "type": "Optional[Any]"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "cleanup",
              "line": 226,
              "docstring": "Release model resources and free GPU memory.\n\nThis method is called automatically when using the detector as a\ncontext manager. For manual resource management, call this method\nexplicitly when done with the detector.\n\nNote:\n    After calling cleanup(), the detector can still be used - the\n    model will be reloaded on the next inference call.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "detect_shapes",
              "line": 254,
              "docstring": "Detect and classify shapes in a single image.\n\nPerforms the full detection pipeline: model loading (if needed),\ninference, post-processing, and summary statistics calculation.\n\nIMPORTANT: YOLOv8's inference already applies confidence thresholding\nusing config.confidence_threshold. No additional filtering is performed.\n\nArgs:\n    image: Input image as NumPy array. Must be:\n        - Format: BGR (H, W, 3), RGB (H, W, 3), or grayscale (H, W)\n        - Dtype: uint8\n        - Value range: [0, 255]\n\nReturns:\n    DetectionResult containing:\n        - List of Detection objects with bounding boxes and confidence\n        - DetectionSummary with aggregate statistics\n        - Inference time in milliseconds\n        - Model version identifier\n\nRaises:\n    ShapeDetectionError: If image validation fails, model loading fails,\n        or inference encounters an error. Error includes model version\n        and context for debugging.\n\nNote:\n    First call triggers lazy model loading, which may take several\n    seconds. Subsequent calls use the cached model instance.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "image",
                    "type": "np.ndarray"
                  }
                ],
                "return_type": "DetectionResult"
              },
              "method_type": "instance"
            },
            {
              "name": "_load_model",
              "line": 336,
              "docstring": "Lazy-load YOLOv8 model from configured path.\n\nLoads model weights, transfers to specified device (with fallback),\nand caches model version identifier. This method is called automatically\non first inference request.\n\nRaises:\n    ShapeDetectionError: If ultralytics package is not installed,\n        model file doesn't exist, or loading fails for any reason.\n\nNote:\n    Model is stored in self._model for reuse across multiple detections.\n    Thread-safe via lock to prevent duplicate loading.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "_postprocess_detections",
              "line": 392,
              "docstring": "Convert YOLO raw results to Detection dataclass objects.\n\nExtracts bounding boxes, confidence scores, and class predictions from\nYOLO output format, converting to absolute pixel coordinates and creating\nboth pixel-space and normalized bounding boxes.\n\nArgs:\n    results: YOLO results object from model.predict() containing boxes,\n        scores, and class predictions. Type is ultralytics Results but\n        using Any to avoid hard dependency.\n    image_shape: Original image dimensions as (height, width, channels).\n        Used to compute normalized bounding boxes.\n\nReturns:\n    List of Detection objects with unique IDs, bounding boxes in both\n    coordinate systems, and model version metadata. Returns empty list\n    if no detections found.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "results",
                    "type": "Any"
                  },
                  {
                    "name": "image_shape",
                    "type": "tuple"
                  }
                ],
                "return_type": "List[Detection]"
              },
              "method_type": "instance"
            },
            {
              "name": "_calculate_summary",
              "line": 457,
              "docstring": "Compute aggregate statistics for a set of detections.\n\nUses configurable thresholds from DetectionConfig to classify\ndetections into high/medium/low confidence categories.\n\nArgs:\n    detections: List of Detection objects to summarize.\n\nReturns:\n    DetectionSummary containing:\n        - total_detections: Count of all detections\n        - detections_by_class: Dict mapping class names to counts\n        - average_confidence: Mean confidence across all detections\n        - confidence_distribution: Dict with 'high', 'medium', and 'low'\n          confidence proportions based on configurable thresholds",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "detections",
                    "type": "List[Detection]"
                  }
                ],
                "return_type": "DetectionSummary"
              },
              "method_type": "instance"
            },
            {
              "name": "detect_shapes_batch",
              "line": 529,
              "docstring": "Detect shapes in multiple images using batch processing.\n\nProcesses images in batches (size determined by config.batch_size) to\nimprove throughput. Tracks total batch time and distributes across\nimages for approximate per-image timing.\n\nArgs:\n    images: List of input images. Each image must be:\n        - Format: BGR (H, W, 3), RGB (H, W, 3), or grayscale (H, W)\n        - Dtype: uint8\n        - Value range: [0, 255]\n\nReturns:\n    List of DetectionResult objects, one per input image. Order matches\n    input order. Failed batch images receive empty DetectionResult\n    with error logged.\n\nNote:\n    **Important timing caveat:** The `inference_time_ms` in each result\n    is an APPROXIMATION calculated by dividing the total batch inference\n    time equally among all images in the batch. Actual per-image times\n    may vary based on image complexity, but batch processing prevents\n    individual timing measurements.\n\n    Batch processing is significantly faster than repeated single-image\n    calls (typically 2-5x speedup). Individual image failures within a\n    batch are logged but don't halt processing of remaining images.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "images",
                    "type": "List[np.ndarray]"
                  }
                ],
                "return_type": "List[DetectionResult]"
              },
              "method_type": "instance"
            },
            {
              "name": "get_model_info",
              "line": 656,
              "docstring": "Retrieve metadata about the loaded detection model.\n\nReturns:\n    Dictionary containing:\n        - loaded (bool): Whether model is currently loaded in memory\n        - model_path (str): Path to model weights file\n        - model_version (str): Model identifier (only if loaded)\n        - requested_device (str): Device specified in config\n        - actual_device (str): Device actually in use (only if loaded)\n        - num_classes (int): Number of detectable classes (only if\n          loaded)\n        - class_names (List[str]): Names of detectable classes (only\n          if loaded)\n\nNote:\n    If model is not loaded, only 'loaded', 'model_path', and\n    'requested_device' keys are present.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "Dict[str, Union[bool, str, int, List[str]]]"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        }
      },
      "functions": []
    },
    "src.drawing_intelligence.processing": {
      "file_path": "C:\\00Projects\\engineering_items_attributes_enrichment\\src\\drawing_intelligence\\processing\\__init__.py",
      "module_docstring": "Processing modules for the Drawing Intelligence System.\n\nThis package contains all document and image processing components.",
      "classes": {},
      "functions": []
    },
    "src.drawing_intelligence.quality.quality_scorer": {
      "file_path": "C:\\00Projects\\engineering_items_attributes_enrichment\\src\\drawing_intelligence\\quality\\quality_scorer.py",
      "module_docstring": "Quality scoring module for the Drawing Intelligence System.\n\nThis module provides functionality for calculating confidence scores,\nassessing data completeness, and generating human review flags for\nprocessed engineering drawings.\n\nClasses:\n    QualityConfig: Configuration parameters for quality scoring.\n    QualityScorer: Main quality assessment engine.\n\nTypical usage example:\n    config = QualityConfig(\n        review_threshold=0.75,\n        critical_entities=[EntityType.PART_NUMBER, EntityType.DIMENSION]\n    )\n    scorer = QualityScorer(config)\n\n    # Calculate confidence\n    confidence = scorer.calculate_drawing_confidence(processing_result)\n\n    # Generate review flags if needed\n    if confidence < config.review_threshold:\n        flags = scorer.generate_review_flags(processing_result)\n\n    # Assess completeness\n    completeness = scorer.assess_completeness(processing_result)",
      "classes": {
        "QualityConfig": {
          "line": 66,
          "docstring": "Configuration parameters for quality scoring and review flag generation.\n\nThis dataclass encapsulates all configurable thresholds and weights\nused by the QualityScorer to assess drawing processing quality.\n\nAttributes:\n    review_threshold: Minimum confidence score required to avoid\n        human review. Must be between 0.0 and 1.0. Default: 0.75.\n    ocr_weight: Weight factor for OCR confidence in overall score.\n        Must be between 0.0 and 1.0. Default: 0.30.\n    detection_weight: Weight factor for shape detection confidence.\n        Must be between 0.0 and 1.0. Default: 0.40.\n    entity_weight: Weight factor for entity extraction confidence.\n        Must be between 0.0 and 1.0. Default: 0.30.\n    flag_missing_critical_entities: Whether to generate critical\n        severity flags when essential entity types are missing.\n        Default: True.\n    critical_entities: List of EntityType enums that are considered\n        essential. Defaults to [EntityType.PART_NUMBER].\n    completeness_entity_weight: Weight for entity completeness in\n        overall completeness score. Default: 0.40.\n    completeness_shape_weight: Weight for shape presence in overall\n        completeness score. Default: 0.30.\n    completeness_association_weight: Weight for associations in\n        overall completeness score. Default: 0.20.\n    completeness_title_block_weight: Weight for title block in\n        overall completeness score. Default: 0.10.\n    severity_critical_threshold: Max confidence for CRITICAL severity.\n        Default: 0.5.\n    severity_high_threshold: Max confidence for HIGH severity.\n        Default: 0.65.\n    severity_medium_threshold: Max confidence for MEDIUM severity.\n        Default: 0.75.\n    max_expected_association_rate: Maximum expected ratio of text\n        blocks that should be associated with shapes. Default: 0.7.\n    title_block_partial_score: Completeness score when title block\n        is missing (partial credit for other data). Default: 0.5.\n    entity_importance_weights: Dict mapping EntityType to importance\n        weight for completeness calculation. Higher weights indicate\n        more critical entity types.\n\nRaises:\n    ValueError: If any weight is outside [0.0, 1.0] range, or if\n        confidence weights or completeness weights don't sum to 1.0\n        (within tolerance).\n\nNote:\n    All weight groups must sum to 1.0 (\u00b10.01 tolerance):\n        - ocr_weight + detection_weight + entity_weight = 1.0\n        - completeness weights sum = 1.0",
          "bases": [],
          "methods": [
            {
              "name": "__post_init__",
              "line": 136,
              "docstring": "Initialize defaults and validate configuration.\n\nRaises:\n    ValueError: If validation fails for any constraint.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "_validate_range",
              "line": 232,
              "docstring": "Validate that a value is in the valid [0.0, 1.0] range.\n\nArgs:\n    name: Parameter name for error messages.\n    value: Value to validate.\n\nRaises:\n    ValueError: If value is outside [0.0, 1.0].",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "name",
                    "type": "str"
                  },
                  {
                    "name": "value",
                    "type": "float"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        },
        "QualityScorer": {
          "line": 246,
          "docstring": "Calculate confidence scores and generate review flags for drawings.\n\nThis class provides comprehensive quality assessment capabilities,\nincluding weighted confidence calculation, completeness analysis,\nand automated review flag generation based on configurable thresholds.\n\nThe scorer evaluates multiple quality dimensions:\n    - OCR text extraction confidence\n    - Shape detection confidence\n    - Entity extraction confidence\n    - Data completeness (critical fields present)\n    - Validation issues from data validators\n\nAttributes:\n    config: QualityConfig instance containing scoring parameters.\n\nExample:\n    >>> config = QualityConfig(review_threshold=0.70)\n    >>> scorer = QualityScorer(config)\n    >>> confidence = scorer.calculate_drawing_confidence(result)\n    >>> if confidence < 0.70:\n    ...     flags = scorer.generate_review_flags(result)",
          "bases": [],
          "methods": [
            {
              "name": "__init__",
              "line": 271,
              "docstring": "Initialize the quality scorer with configuration.\n\nArgs:\n    config: QualityConfig instance specifying scoring parameters\n        and thresholds.\n\nRaises:\n    TypeError: If config is not a QualityConfig instance.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "config",
                    "type": "QualityConfig"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "calculate_drawing_confidence",
              "line": 285,
              "docstring": "Calculate overall confidence score using weighted components.\n\nComputes a weighted average of OCR, detection, and entity\nextraction confidence scores. Applies any validation penalties\nfrom the processing result's validation report.\n\nThe formula used is:\n    overall = (ocr_weight \u00d7 ocr_conf) +\n             (detection_weight \u00d7 det_conf) +\n             (entity_weight \u00d7 entity_conf)\n\nIf a validation report exists with confidence_adjustment < 1.0,\nthe overall score is multiplied by this adjustment factor.\n\nArgs:\n    processing_result: Complete ProcessingResult containing OCR\n        results, detections, entities, and optional validation\n        report.\n\nReturns:\n    Overall confidence score normalized to range [0.0, 1.0].\n    Returns 0.0 if no OCR results, detections, or entities exist.\n\nNote:\n    Missing components (e.g., no detections) contribute 0.0 to\n    their weighted portion, reducing the overall score.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "processing_result",
                    "type": "ProcessingResult"
                  }
                ],
                "return_type": "float"
              },
              "method_type": "instance"
            },
            {
              "name": "generate_review_flags",
              "line": 369,
              "docstring": "Generate human review flags based on quality assessment.\n\nAnalyzes the processing result and creates ReviewFlag instances\nfor various quality issues, including:\n    1. Low overall confidence (below review_threshold)\n    2. Missing entities entirely\n    3. Missing shape detections\n    4. Missing critical entity types (e.g., PART_NUMBER)\n    5. High/critical severity validation issues\n    6. Processing failures\n\nArgs:\n    processing_result: Complete ProcessingResult to evaluate.\n        The overall_confidence field will be recalculated if\n        not already set.\n\nReturns:\n    List of ReviewFlag instances. Empty list if no issues found.\n    Flags are ordered by generation sequence (not severity).\n\nRaises:\n    ValueError: If processing_result is malformed.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "processing_result",
                    "type": "ProcessingResult"
                  }
                ],
                "return_type": "List[ReviewFlag]"
              },
              "method_type": "instance"
            },
            {
              "name": "assess_completeness",
              "line": 440,
              "docstring": "Assess data completeness across multiple categories.\n\nEvaluates the presence and quality of extracted data including:\n    - Critical entities (part number, dimensions, shapes)\n    - Entity type coverage (weighted by importance)\n    - Text-to-shape associations\n    - Title block information\n\nThe overall completeness score is a weighted average using\nconfigurable weights from QualityConfig.\n\nArgs:\n    processing_result: Complete ProcessingResult to assess.\n\nReturns:\n    CompletenessScore instance containing:\n        - overall_score: Weighted average [0.0, 1.0]\n        - Boolean flags for critical field presence\n        - List of missing critical field names\n        - Category-specific completeness scores\n\nNote:\n    A score of 1.0 indicates all expected data present with\n    high coverage. Scores below 0.5 typically indicate\n    significant data gaps requiring review.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "processing_result",
                    "type": "ProcessingResult"
                  }
                ],
                "return_type": "CompletenessScore"
              },
              "method_type": "instance"
            },
            {
              "name": "_check_critical_entities",
              "line": 543,
              "docstring": "Identify missing critical entity types.\n\nCompares extracted entity types against the configured list\nof critical entity types. Returns entity type names that\nwere expected but not found.\n\nArgs:\n    processing_result: ProcessingResult containing extracted\n        entities.\n\nReturns:\n    List of missing critical entity type names (strings).\n    Empty list if all critical entities are present.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "processing_result",
                    "type": "ProcessingResult"
                  }
                ],
                "return_type": "List[str]"
              },
              "method_type": "instance"
            },
            {
              "name": "_classify_severity",
              "line": 574,
              "docstring": "Classify severity level based on confidence score.\n\nMaps confidence scores to severity levels using configurable\nthresholds from QualityConfig.\n\nArgs:\n    confidence_score: Confidence value in range [0.0, 1.0].\n\nReturns:\n    Severity enum value corresponding to the confidence level.\n\nNote:\n    Lower confidence produces higher severity. This is used\n    primarily for low-confidence review flags.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "confidence_score",
                    "type": "float"
                  }
                ],
                "return_type": "Severity"
              },
              "method_type": "instance"
            },
            {
              "name": "_calculate_entity_completeness",
              "line": 603,
              "docstring": "Calculate entity extraction completeness score.\n\nEvaluates the presence of expected entity types, weighted by\ntheir importance. The score reflects both coverage (which types\nwere found) and importance (critical types weighted higher).\n\nUses entity importance weights from QualityConfig. The score is\ncalculated as: sum(found_weights) / sum(all_expected_weights).\n\nArgs:\n    processing_result: ProcessingResult containing extracted\n        entities.\n\nReturns:\n    Completeness score in range [0.0, 1.0]. Returns 0.0 if no\n    entities were extracted. Score of 1.0 indicates all expected\n    entity types were found.\n\nNote:\n    This is a subset assessment - not all entity types are\n    included in the expected set. Additional entities don't\n    increase the score beyond 1.0.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "processing_result",
                    "type": "ProcessingResult"
                  }
                ],
                "return_type": "float"
              },
              "method_type": "instance"
            },
            {
              "name": "_calculate_association_completeness",
              "line": 646,
              "docstring": "Calculate text-to-shape association completeness score.\n\nUses a heuristic based on the ratio of text blocks that have\nbeen associated with shapes. Since not all text requires\nassociation (e.g., notes, disclaimers), the expected association\nrate is capped at a configurable threshold.\n\nArgs:\n    processing_result: ProcessingResult containing OCR text blocks\n        and associations.\n\nReturns:\n    Completeness score in range [0.0, 1.0]. Returns 0.0 if no\n    OCR text blocks exist. A score of 1.0 indicates the expected\n    percentage of text blocks have been associated with shapes.\n\nNote:\n    The expected rate threshold is configurable in QualityConfig\n    and is based on typical engineering drawing text distribution.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "processing_result",
                    "type": "ProcessingResult"
                  }
                ],
                "return_type": "float"
              },
              "method_type": "instance"
            },
            {
              "name": "_flag_low_confidence",
              "line": 688,
              "docstring": "Generate flag for low overall confidence.\n\nArgs:\n    drawing_id: Drawing identifier for context.\n    confidence: Overall confidence score.\n\nReturns:\n    ReviewFlag for low confidence issue.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "drawing_id",
                    "type": "str"
                  },
                  {
                    "name": "confidence",
                    "type": "float"
                  }
                ],
                "return_type": "ReviewFlag"
              },
              "method_type": "instance"
            },
            {
              "name": "_flag_missing_entities",
              "line": 712,
              "docstring": "Generate flag for missing entity extractions.\n\nArgs:\n    drawing_id: Drawing identifier for context.\n\nReturns:\n    ReviewFlag for missing entities issue.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "drawing_id",
                    "type": "str"
                  }
                ],
                "return_type": "ReviewFlag"
              },
              "method_type": "instance"
            },
            {
              "name": "_flag_missing_detections",
              "line": 732,
              "docstring": "Generate flag for missing shape detections.\n\nArgs:\n    drawing_id: Drawing identifier for context.\n\nReturns:\n    ReviewFlag for missing detections issue.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "drawing_id",
                    "type": "str"
                  }
                ],
                "return_type": "ReviewFlag"
              },
              "method_type": "instance"
            },
            {
              "name": "_flag_missing_critical_entities",
              "line": 752,
              "docstring": "Generate flag for missing critical entity types.\n\nArgs:\n    drawing_id: Drawing identifier for context.\n    missing: List of missing critical entity type names.\n\nReturns:\n    ReviewFlag for missing critical entities issue.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "drawing_id",
                    "type": "str"
                  },
                  {
                    "name": "missing",
                    "type": "List[str]"
                  }
                ],
                "return_type": "ReviewFlag"
              },
              "method_type": "instance"
            },
            {
              "name": "_flag_validation_issues",
              "line": 778,
              "docstring": "Generate flags from validation report issues.\n\nArgs:\n    drawing_id: Drawing identifier for context.\n    validation_report: ValidationReport containing issues.\n\nReturns:\n    List of ReviewFlags for high/critical validation issues.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "drawing_id",
                    "type": "str"
                  },
                  {
                    "name": "validation_report"
                  }
                ],
                "return_type": "List[ReviewFlag]"
              },
              "method_type": "instance"
            },
            {
              "name": "_flag_processing_failure",
              "line": 827,
              "docstring": "Generate flag for processing failures.\n\nArgs:\n    drawing_id: Drawing identifier for context.\n\nReturns:\n    ReviewFlag for processing failure.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "drawing_id",
                    "type": "str"
                  }
                ],
                "return_type": "ReviewFlag"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        }
      },
      "functions": []
    },
    "src.drawing_intelligence.quality": {
      "file_path": "C:\\00Projects\\engineering_items_attributes_enrichment\\src\\drawing_intelligence\\quality\\__init__.py",
      "module_docstring": "Quality assessment modules for the Drawing Intelligence System.\n\nThis package contains quality scoring and validation components.",
      "classes": {},
      "functions": []
    },
    "src.drawing_intelligence.utils.config_loader": {
      "file_path": "C:\\00Projects\\engineering_items_attributes_enrichment\\src\\drawing_intelligence\\utils\\config_loader.py",
      "module_docstring": "Configuration loading and validation for the drawing intelligence system.\n\nThis module provides utilities to load system configuration from YAML files,\nresolve relative paths to absolute paths based on project root, and validate\nthat all required filesystem paths exist.\n\nTypical usage example:\n    config = Config.load()\n    errors = Config.validate(config)\n    if errors:\n        raise ConfigurationError(f\"Configuration invalid: {errors}\")\n\nAuthor: CLAUDE + Sandeep A (01Nov2025)\nRefactored: [Current Date] - Added path resolution automation and pathlib usage",
      "classes": {
        "SystemConfig": {
          "line": 22,
          "docstring": "Container for system configuration parameters.\n\nAttributes:\n    paths: Dictionary containing filesystem paths (data_dir, models_dir, etc.).\n    database: Dictionary containing database configuration (path, etc.).\n    shape_detection: Dictionary containing shape detection model configuration.\n    entity_extraction: Dictionary containing entity extraction configuration.\n    batch_processing: Dictionary containing batch processing configuration.\n    logging: Dictionary containing logging configuration.",
          "bases": [],
          "methods": [
            {
              "name": "__init__",
              "line": 34,
              "docstring": "Initialize SystemConfig from configuration dictionary.\n\nArgs:\n    **config_dict: Configuration dictionary with required keys:\n        paths, database, shape_detection, entity_extraction,\n        batch_processing, logging.\n\nRaises:\n    KeyError: If any required configuration section is missing.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        },
        "Config": {
          "line": 66,
          "docstring": "Static utility class for loading and validating configuration files.\n\nThis class provides methods to load configuration from YAML files and\nvalidate that all required paths and settings are properly configured.",
          "bases": [],
          "methods": [
            {
              "name": "_resolve_nested_path",
              "line": 88,
              "docstring": "Resolve a nested config path to absolute path in-place.\n\nNavigates through nested dictionary structure using dot notation\nand converts relative paths to absolute paths based on project root.\n\nArgs:\n    config_dict: Configuration dictionary to modify in-place.\n    key_path: Dot-separated path to the key (e.g., \"paths.data_dir\").\n    project_root: Project root directory for resolving relative paths.\n\nRaises:\n    KeyError: If any key in the path doesn't exist in config_dict.",
              "signature": {
                "parameters": [
                  {
                    "name": "config_dict",
                    "type": "Dict[str, Any]"
                  },
                  {
                    "name": "key_path",
                    "type": "str"
                  },
                  {
                    "name": "project_root",
                    "type": "Path"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "static"
            },
            {
              "name": "load",
              "line": 117,
              "docstring": "Load system configuration from a YAML file.\n\nReads configuration from the specified YAML file and resolves all\nrelative paths to absolute paths based on the project root directory.\nAll paths defined in _RELATIVE_PATH_KEYS are automatically resolved.\n\nArgs:\n    config_path: Relative path to the configuration YAML file from\n        project root. Defaults to \"config/system_config.yaml\".\n\nReturns:\n    SystemConfig object containing the loaded and resolved configuration.\n\nRaises:\n    FileNotFoundError: If the configuration file does not exist.\n    yaml.YAMLError: If the configuration file is not valid YAML.\n    KeyError: If required configuration keys are missing.\n    ValueError: If the configuration file doesn't contain a dictionary.",
              "signature": {
                "parameters": [
                  {
                    "name": "config_path",
                    "type": "Optional[str]"
                  }
                ],
                "return_type": "SystemConfig"
              },
              "method_type": "static"
            },
            {
              "name": "validate",
              "line": 167,
              "docstring": "Validate that all configured paths exist.\n\nChecks that all critical filesystem paths in the configuration exist\nand are accessible. Distinguishes between files and directories and\nvalidates accordingly.\n\nArgs:\n    config: SystemConfig object to validate.\n\nReturns:\n    List of error messages for any missing or inaccessible paths.\n    Empty list if all paths are valid.",
              "signature": {
                "parameters": [
                  {
                    "name": "config",
                    "type": "SystemConfig"
                  }
                ],
                "return_type": "List[str]"
              },
              "method_type": "static"
            }
          ],
          "nested_classes": []
        }
      },
      "functions": []
    },
    "src.drawing_intelligence.utils.error_handlers": {
      "file_path": "C:\\00Projects\\engineering_items_attributes_enrichment\\src\\drawing_intelligence\\utils\\error_handlers.py",
      "module_docstring": "Error handling utilities for the Drawing Intelligence System.\n\nThis module provides custom exceptions and error handling functions for robust\nerror management throughout the drawing processing pipeline.\n\nClasses:\n    DrawingProcessingError: Base exception for all drawing processing errors.\n    PDFProcessingError: Exception for PDF-specific processing errors.\n    OCRError: Exception for OCR-specific errors.\n    ShapeDetectionError: Exception for shape detection errors.\n    LLMAPIError: Exception for LLM API call errors.\n    BudgetExceededException: Exception for budget limit exceeded scenarios.\n    DatabaseError: Exception for database operation errors.\n    ConfigurationError: Exception for configuration errors.\n    ValidationError: Exception for data validation errors.\n\nFunctions:\n    handle_processing_error: Generic error handler with logging and recovery decision.\n    log_error_with_context: Log error with full context for debugging.\n    create_error_report: Create structured error report for storage/analysis.\n    wrap_with_error_handling: Decorator to add error handling to functions.\n    is_retriable_error: Determine if an error should trigger a retry.\n    get_retry_delay: Calculate retry delay using exponential backoff.",
      "classes": {
        "DrawingProcessingError": {
          "line": 34,
          "docstring": "Base exception for drawing processing errors.\n\nAttributes:\n    message: Error message describing what went wrong.\n    drawing_id: Optional identifier of the drawing being processed.\n    stage: Optional processing stage where the error occurred.\n    recoverable: Whether the error is recoverable with retry.\n    original_error: Optional underlying exception that was wrapped.",
          "bases": [
            "Exception"
          ],
          "methods": [
            {
              "name": "__init__",
              "line": 46,
              "docstring": "Initialize DrawingProcessingError.\n\nArgs:\n    message: Error message describing the issue.\n    drawing_id: Optional drawing identifier.\n    stage: Optional processing stage name.\n    recoverable: Whether error can be recovered with retry.\n    original_error: Optional underlying exception that caused this error.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "message",
                    "type": "str"
                  },
                  {
                    "name": "drawing_id",
                    "type": "Optional[str]"
                  },
                  {
                    "name": "stage",
                    "type": "Optional[str]"
                  },
                  {
                    "name": "recoverable",
                    "type": "bool"
                  },
                  {
                    "name": "original_error",
                    "type": "Optional[Exception]"
                  }
                ],
                "return_type": null
              },
              "method_type": "instance"
            },
            {
              "name": "to_dict",
              "line": 71,
              "docstring": "Convert exception to dictionary for logging and storage.\n\nReturns:\n    Dictionary containing error_type, message, drawing_id, stage,\n    recoverable status, and original error information if available.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "Dict[str, Any]"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        },
        "PDFProcessingError": {
          "line": 94,
          "docstring": "Exception for PDF-specific processing errors.\n\nAttributes:\n    page_number: Optional page number where error occurred.",
          "bases": [
            "DrawingProcessingError"
          ],
          "methods": [
            {
              "name": "__init__",
              "line": 102,
              "docstring": "Initialize PDFProcessingError.\n\nArgs:\n    message: Error message describing the PDF issue.\n    drawing_id: Optional drawing identifier.\n    page_number: Optional PDF page number where error occurred.\n    recoverable: Whether error can be recovered with retry.\n    original_error: Optional underlying exception that caused this error.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "message",
                    "type": "str"
                  },
                  {
                    "name": "drawing_id",
                    "type": "Optional[str]"
                  },
                  {
                    "name": "page_number",
                    "type": "Optional[int]"
                  },
                  {
                    "name": "recoverable",
                    "type": "bool"
                  },
                  {
                    "name": "original_error",
                    "type": "Optional[Exception]"
                  }
                ],
                "return_type": null
              },
              "method_type": "instance"
            },
            {
              "name": "to_dict",
              "line": 129,
              "docstring": "Convert exception to dictionary including page number.\n\nReturns:\n    Dictionary with all base fields plus page_number.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "Dict[str, Any]"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        },
        "OCRError": {
          "line": 141,
          "docstring": "Exception for OCR-specific errors.\n\nAttributes:\n    ocr_engine: Optional OCR engine name that failed.",
          "bases": [
            "DrawingProcessingError"
          ],
          "methods": [
            {
              "name": "__init__",
              "line": 149,
              "docstring": "Initialize OCRError.\n\nArgs:\n    message: Error message describing the OCR issue.\n    drawing_id: Optional drawing identifier.\n    ocr_engine: Optional name of OCR engine that failed.\n    recoverable: Whether error can be recovered (defaults to True).\n    original_error: Optional underlying exception that caused this error.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "message",
                    "type": "str"
                  },
                  {
                    "name": "drawing_id",
                    "type": "Optional[str]"
                  },
                  {
                    "name": "ocr_engine",
                    "type": "Optional[str]"
                  },
                  {
                    "name": "recoverable",
                    "type": "bool"
                  },
                  {
                    "name": "original_error",
                    "type": "Optional[Exception]"
                  }
                ],
                "return_type": null
              },
              "method_type": "instance"
            },
            {
              "name": "to_dict",
              "line": 176,
              "docstring": "Convert exception to dictionary including OCR engine.\n\nReturns:\n    Dictionary with all base fields plus ocr_engine.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "Dict[str, Any]"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        },
        "ShapeDetectionError": {
          "line": 188,
          "docstring": "Exception for shape detection errors.\n\nAttributes:\n    model_version: Optional version of detection model that failed.",
          "bases": [
            "DrawingProcessingError"
          ],
          "methods": [
            {
              "name": "__init__",
              "line": 196,
              "docstring": "Initialize ShapeDetectionError.\n\nArgs:\n    message: Error message describing the detection issue.\n    drawing_id: Optional drawing identifier.\n    model_version: Optional version of YOLO model that failed.\n    recoverable: Whether error can be recovered with retry.\n    original_error: Optional underlying exception that caused this error.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "message",
                    "type": "str"
                  },
                  {
                    "name": "drawing_id",
                    "type": "Optional[str]"
                  },
                  {
                    "name": "model_version",
                    "type": "Optional[str]"
                  },
                  {
                    "name": "recoverable",
                    "type": "bool"
                  },
                  {
                    "name": "original_error",
                    "type": "Optional[Exception]"
                  }
                ],
                "return_type": null
              },
              "method_type": "instance"
            },
            {
              "name": "to_dict",
              "line": 223,
              "docstring": "Convert exception to dictionary including model version.\n\nReturns:\n    Dictionary with all base fields plus model_version.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "Dict[str, Any]"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        },
        "LLMAPIError": {
          "line": 235,
          "docstring": "Exception for LLM API call errors.\n\nAttributes:\n    provider: LLM provider name (openai, anthropic, google).\n    status_code: HTTP status code if applicable.",
          "bases": [
            "DrawingProcessingError"
          ],
          "methods": [
            {
              "name": "__init__",
              "line": 244,
              "docstring": "Initialize LLMAPIError.\n\nArgs:\n    message: Error message describing the API issue.\n    drawing_id: Optional drawing identifier.\n    provider: Optional LLM provider name.\n    status_code: Optional HTTP status code.\n    recoverable: Whether error can be recovered (defaults to True).\n    original_error: Optional underlying exception that caused this error.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "message",
                    "type": "str"
                  },
                  {
                    "name": "drawing_id",
                    "type": "Optional[str]"
                  },
                  {
                    "name": "provider",
                    "type": "Optional[str]"
                  },
                  {
                    "name": "status_code",
                    "type": "Optional[int]"
                  },
                  {
                    "name": "recoverable",
                    "type": "bool"
                  },
                  {
                    "name": "original_error",
                    "type": "Optional[Exception]"
                  }
                ],
                "return_type": null
              },
              "method_type": "instance"
            },
            {
              "name": "to_dict",
              "line": 274,
              "docstring": "Convert exception to dictionary including provider and status.\n\nReturns:\n    Dictionary with all base fields plus provider and status_code.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "Dict[str, Any]"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        },
        "BudgetExceededException": {
          "line": 287,
          "docstring": "Exception for budget limit exceeded scenarios.\n\nAttributes:\n    current_cost: Current accumulated cost in USD.\n    budget_limit: Maximum allowed budget in USD.",
          "bases": [
            "DrawingProcessingError"
          ],
          "methods": [
            {
              "name": "__init__",
              "line": 296,
              "docstring": "Initialize BudgetExceededException.\n\nArgs:\n    message: Error message describing budget issue.\n    current_cost: Current cost in USD.\n    budget_limit: Budget limit in USD.\n    drawing_id: Optional drawing identifier.\n    original_error: Optional underlying exception that caused this error.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "message",
                    "type": "str"
                  },
                  {
                    "name": "current_cost",
                    "type": "float"
                  },
                  {
                    "name": "budget_limit",
                    "type": "float"
                  },
                  {
                    "name": "drawing_id",
                    "type": "Optional[str]"
                  },
                  {
                    "name": "original_error",
                    "type": "Optional[Exception]"
                  }
                ],
                "return_type": null
              },
              "method_type": "instance"
            },
            {
              "name": "to_dict",
              "line": 324,
              "docstring": "Convert exception to dictionary including cost information.\n\nReturns:\n    Dictionary with all base fields plus current_cost and budget_limit.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "Dict[str, Any]"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        },
        "DatabaseError": {
          "line": 337,
          "docstring": "Exception for database operation errors.\n\nAttributes:\n    operation: Optional database operation that failed.",
          "bases": [
            "DrawingProcessingError"
          ],
          "methods": [
            {
              "name": "__init__",
              "line": 345,
              "docstring": "Initialize DatabaseError.\n\nArgs:\n    message: Error message describing database issue.\n    drawing_id: Optional drawing identifier.\n    operation: Optional database operation (insert, update, query).\n    recoverable: Whether error can be recovered with retry.\n    original_error: Optional underlying database driver exception.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "message",
                    "type": "str"
                  },
                  {
                    "name": "drawing_id",
                    "type": "Optional[str]"
                  },
                  {
                    "name": "operation",
                    "type": "Optional[str]"
                  },
                  {
                    "name": "recoverable",
                    "type": "bool"
                  },
                  {
                    "name": "original_error",
                    "type": "Optional[Exception]"
                  }
                ],
                "return_type": null
              },
              "method_type": "instance"
            },
            {
              "name": "to_dict",
              "line": 372,
              "docstring": "Convert exception to dictionary including operation.\n\nReturns:\n    Dictionary with all base fields plus operation.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "Dict[str, Any]"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        },
        "ConfigurationError": {
          "line": 384,
          "docstring": "Exception for configuration errors.\n\nAttributes:\n    config_key: Optional configuration key that caused the error.",
          "bases": [
            "DrawingProcessingError"
          ],
          "methods": [
            {
              "name": "__init__",
              "line": 392,
              "docstring": "Initialize ConfigurationError.\n\nArgs:\n    message: Error message describing configuration issue.\n    config_key: Optional configuration key that is invalid.\n    original_error: Optional underlying exception that caused this error.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "message",
                    "type": "str"
                  },
                  {
                    "name": "config_key",
                    "type": "Optional[str]"
                  },
                  {
                    "name": "original_error",
                    "type": "Optional[Exception]"
                  }
                ],
                "return_type": null
              },
              "method_type": "instance"
            },
            {
              "name": "to_dict",
              "line": 414,
              "docstring": "Convert exception to dictionary including config key.\n\nReturns:\n    Dictionary with all base fields plus config_key.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "Dict[str, Any]"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        },
        "ValidationError": {
          "line": 426,
          "docstring": "Exception for data validation errors.\n\nAttributes:\n    field_name: Optional field name that failed validation.",
          "bases": [
            "DrawingProcessingError"
          ],
          "methods": [
            {
              "name": "__init__",
              "line": 434,
              "docstring": "Initialize ValidationError.\n\nArgs:\n    message: Error message describing validation issue.\n    drawing_id: Optional drawing identifier.\n    field_name: Optional field name that failed validation.\n    recoverable: Whether error can be recovered with retry.\n    original_error: Optional underlying exception that caused this error.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "message",
                    "type": "str"
                  },
                  {
                    "name": "drawing_id",
                    "type": "Optional[str]"
                  },
                  {
                    "name": "field_name",
                    "type": "Optional[str]"
                  },
                  {
                    "name": "recoverable",
                    "type": "bool"
                  },
                  {
                    "name": "original_error",
                    "type": "Optional[Exception]"
                  }
                ],
                "return_type": null
              },
              "method_type": "instance"
            },
            {
              "name": "to_dict",
              "line": 461,
              "docstring": "Convert exception to dictionary including field name.\n\nReturns:\n    Dictionary with all base fields plus field_name.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "Dict[str, Any]"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        }
      },
      "functions": [
        {
          "name": "handle_processing_error",
          "line": 473,
          "docstring": "Handle processing errors with logging and recovery decision.\n\nAnalyzes the exception type to determine if the operation should be retried\nand logs appropriate error information with context.\n\nArgs:\n    error: The exception that occurred during processing.\n    context: Dictionary containing contextual information such as drawing_id,\n        stage, and other relevant metadata.\n    logger: Optional logger instance. If None, uses module logger.\n\nReturns:\n    A tuple containing:\n        - bool: True if the error is recoverable and should be retried.\n        - str: Human-readable error message.\n\nExample:\n    >>> context = {\"drawing_id\": \"DWG-001\", \"stage\": \"ocr_extraction\"}\n    >>> should_retry, msg = handle_processing_error(OCRError(\"Failed\"), context)\n    >>> print(f\"Retry: {should_retry}, Message: {msg}\")",
          "signature": {
            "parameters": [
              {
                "name": "error",
                "type": "Exception"
              },
              {
                "name": "context",
                "type": "Dict[str, Any]"
              },
              {
                "name": "logger",
                "type": "Optional[logging.Logger]"
              }
            ],
            "return_type": "Tuple[bool, str]"
          }
        },
        {
          "name": "log_error_with_context",
          "line": 524,
          "docstring": "Log error with comprehensive context information for debugging.\n\nLogs error details including type, message, and all contextual information.\nIn DEBUG mode, also logs the full stack trace.\n\nArgs:\n    error: The exception that occurred.\n    logger: Logger instance to use for logging.\n    context: Dictionary with contextual information (drawing_id, stage, etc.).\n\nReturns:\n    None\n\nNote:\n    Stack traces are only logged when logger is at DEBUG level or lower.",
          "signature": {
            "parameters": [
              {
                "name": "error",
                "type": "Exception"
              },
              {
                "name": "logger",
                "type": "logging.Logger"
              },
              {
                "name": "context",
                "type": "Dict[str, Any]"
              }
            ],
            "return_type": "None"
          }
        },
        {
          "name": "create_error_report",
          "line": 574,
          "docstring": "Create a structured error report for storage and analysis.\n\nGenerates a comprehensive error report including error type, message,\nstack trace, and optional partial processing results.\n\nArgs:\n    error: The exception that occurred.\n    processing_result: Optional partial processing result object that may\n        contain drawing_id, completed_stages, and overall_confidence.\n    timestamp: Optional timestamp for the error. Defaults to current time.\n\nReturns:\n    A dictionary containing:\n        - error_type: Name of the exception class.\n        - error_message: String representation of the error.\n        - traceback: Full stack trace string.\n        - timestamp: ISO format timestamp of the error.\n        - Additional fields from DrawingProcessingError if applicable.\n        - partial_results: Dictionary of partial results if available.\n\nExample:\n    >>> error = OCRError(\"PaddleOCR failed\", drawing_id=\"DWG-001\")\n    >>> report = create_error_report(error)\n    >>> print(report['error_type'])\n    'OCRError'",
          "signature": {
            "parameters": [
              {
                "name": "error",
                "type": "Exception"
              },
              {
                "name": "processing_result",
                "type": "Optional[Any]"
              },
              {
                "name": "timestamp",
                "type": "Optional[datetime]"
              }
            ],
            "return_type": "Dict[str, Any]"
          }
        },
        {
          "name": "wrap_with_error_handling",
          "line": 633,
          "docstring": "Decorator to add standardized error handling to functions.\n\nWraps functions to catch and re-raise DrawingProcessingError instances,\nwhile converting unknown exceptions to DrawingProcessingError with\nrecoverable=False.\n\nArgs:\n    func: The function to wrap with error handling.\n\nReturns:\n    The wrapped function with error handling.\n\nRaises:\n    DrawingProcessingError: For both custom and wrapped unknown errors.\n\nExample:\n    >>> @wrap_with_error_handling\n    ... def risky_operation():\n    ...     raise ValueError(\"Something went wrong\")\n    >>> risky_operation()  # Raises DrawingProcessingError",
          "signature": {
            "parameters": [
              {
                "name": "func",
                "type": "Callable"
              }
            ],
            "return_type": "Callable"
          }
        },
        {
          "name": "is_retriable_error",
          "line": 675,
          "docstring": "Determine if an error should trigger a retry attempt.\n\nEvaluates error types and attributes to decide if the operation that\ncaused the error can reasonably be retried. For DrawingProcessingError\ninstances, inspects the original_error for more intelligent decisions.\n\nArgs:\n    error: The exception to evaluate.\n\nReturns:\n    True if the error is retriable (network issues, rate limits, or\n    DrawingProcessingError with recoverable=True), False otherwise.\n\nNote:\n    - DrawingProcessingError instances use their recoverable flag.\n    - For DatabaseError, inspects original_error for transient vs permanent issues.\n    - Network errors (ConnectionError, TimeoutError, OSError) are retriable.\n    - HTTP 429 (rate limit) errors are retriable.\n    - All other errors default to non-retriable.\n\nExample:\n    >>> error = OCRError(\"Temporary failure\", recoverable=True)\n    >>> is_retriable_error(error)\n    True\n    >>> import sqlite3\n    >>> db_error = DatabaseError(\n    ...     \"Database locked\",\n    ...     original_error=sqlite3.OperationalError(\"database is locked\")\n    ... )\n    >>> is_retriable_error(db_error)\n    True",
          "signature": {
            "parameters": [
              {
                "name": "error",
                "type": "Exception"
              }
            ],
            "return_type": "bool"
          }
        },
        {
          "name": "get_retry_delay",
          "line": 773,
          "docstring": "Calculate retry delay using exponential backoff with cap.\n\nImplements exponential backoff strategy: delay = base_delay * 2^(attempt-1),\ncapped at 60 seconds to prevent excessive wait times.\n\nArgs:\n    attempt: Current retry attempt number (1-indexed). First retry is 1.\n    base_delay: Base delay in seconds for the first retry. Defaults to 1.0.\n\nReturns:\n    Calculated delay in seconds, capped at 60.0 seconds.\n\nExample:\n    >>> get_retry_delay(1)  # First retry\n    1.0\n    >>> get_retry_delay(5)  # Fifth retry\n    16.0\n    >>> get_retry_delay(10)  # Would be 512, but capped\n    60.0",
          "signature": {
            "parameters": [
              {
                "name": "attempt",
                "type": "int"
              },
              {
                "name": "base_delay",
                "type": "float"
              }
            ],
            "return_type": "float"
          }
        }
      ]
    },
    "src.drawing_intelligence.utils.file_utils": {
      "file_path": "C:\\00Projects\\engineering_items_attributes_enrichment\\src\\drawing_intelligence\\utils\\file_utils.py",
      "module_docstring": "File utilities for the Drawing Intelligence System.\n\nProvides functions for file operations, validation, and path management.",
      "classes": {},
      "functions": [
        {
          "name": "ensure_directory",
          "line": 16,
          "docstring": "Create directory if it doesn't exist, including parent directories.\n\nArgs:\n    path: Directory path to create\n\nRaises:\n    OSError: If directory creation fails",
          "signature": {
            "parameters": [
              {
                "name": "path",
                "type": "str"
              }
            ],
            "return_type": "None"
          }
        },
        {
          "name": "get_file_hash",
          "line": 32,
          "docstring": "Calculate hash of file contents.\n\nArgs:\n    file_path: Path to file\n    algorithm: Hash algorithm ('md5', 'sha256')\n\nReturns:\n    Hexadecimal hash string\n\nRaises:\n    FileNotFoundError: If file doesn't exist\n    ValueError: If algorithm not supported",
          "signature": {
            "parameters": [
              {
                "name": "file_path",
                "type": "str"
              },
              {
                "name": "algorithm",
                "type": "str"
              }
            ],
            "return_type": "str"
          }
        },
        {
          "name": "get_file_size_mb",
          "line": 63,
          "docstring": "Get file size in megabytes.\n\nArgs:\n    file_path: Path to file\n\nReturns:\n    Size in MB (rounded to 2 decimal places)\n\nRaises:\n    FileNotFoundError: If file doesn't exist",
          "signature": {
            "parameters": [
              {
                "name": "file_path",
                "type": "str"
              }
            ],
            "return_type": "float"
          }
        },
        {
          "name": "list_files",
          "line": 84,
          "docstring": "List files in directory with optional filtering.\n\nArgs:\n    directory: Directory path to scan\n    extension: Optional file extension filter (e.g., '.pdf', '.png')\n    recursive: Whether to scan subdirectories\n\nReturns:\n    List of absolute file paths\n\nRaises:\n    NotADirectoryError: If path is not a directory",
          "signature": {
            "parameters": [
              {
                "name": "directory",
                "type": "str"
              },
              {
                "name": "extension",
                "type": "Optional[str]"
              },
              {
                "name": "recursive",
                "type": "bool"
              }
            ],
            "return_type": "List[str]"
          }
        },
        {
          "name": "safe_filename",
          "line": 121,
          "docstring": "Sanitize filename for safe filesystem use.\n\nRemoves/replaces unsafe characters and limits length.\n\nArgs:\n    filename: Original filename\n    max_length: Maximum filename length (default: 255)\n\nReturns:\n    Safe filename string",
          "signature": {
            "parameters": [
              {
                "name": "filename",
                "type": "str"
              },
              {
                "name": "max_length",
                "type": "int"
              }
            ],
            "return_type": "str"
          }
        },
        {
          "name": "generate_unique_id",
          "line": 158,
          "docstring": "Generate unique ID with optional prefix.\n\nFormat: PREFIX-YYYYMMDD-HHMMSS-UUID\nExample: DWG-20251102-143022-a1b2c3d4\n\nArgs:\n    prefix: Optional prefix (e.g., 'DWG', 'BATCH')\n\nReturns:\n    Unique ID string",
          "signature": {
            "parameters": [
              {
                "name": "prefix",
                "type": "str"
              }
            ],
            "return_type": "str"
          }
        },
        {
          "name": "copy_file_with_backup",
          "line": 180,
          "docstring": "Copy file, backing up destination if it exists.\n\nIf destination exists, it's renamed with .bak extension before copying.\n\nArgs:\n    source: Source file path\n    destination: Destination file path\n\nRaises:\n    FileNotFoundError: If source doesn't exist\n    OSError: If copy fails",
          "signature": {
            "parameters": [
              {
                "name": "source",
                "type": "str"
              },
              {
                "name": "destination",
                "type": "str"
              }
            ],
            "return_type": "None"
          }
        },
        {
          "name": "get_relative_path",
          "line": 215,
          "docstring": "Get path relative to base directory.\n\nArgs:\n    path: Absolute or relative path\n    base_dir: Base directory\n\nReturns:\n    Relative path string",
          "signature": {
            "parameters": [
              {
                "name": "path",
                "type": "str"
              },
              {
                "name": "base_dir",
                "type": "str"
              }
            ],
            "return_type": "str"
          }
        },
        {
          "name": "split_path_components",
          "line": 229,
          "docstring": "Split path into directory, filename, and extension.\n\nArgs:\n    path: File path\n\nReturns:\n    Tuple of (directory, filename_without_ext, extension)",
          "signature": {
            "parameters": [
              {
                "name": "path",
                "type": "str"
              }
            ],
            "return_type": "Tuple[str, str, str]"
          }
        },
        {
          "name": "ensure_file_extension",
          "line": 245,
          "docstring": "Ensure filename has the correct extension.\n\nArgs:\n    filename: Original filename\n    extension: Desired extension (with or without leading dot)\n\nReturns:\n    Filename with correct extension",
          "signature": {
            "parameters": [
              {
                "name": "filename",
                "type": "str"
              },
              {
                "name": "extension",
                "type": "str"
              }
            ],
            "return_type": "str"
          }
        },
        {
          "name": "is_path_safe",
          "line": 265,
          "docstring": "Check if path is safe (doesn't escape base directory).\n\nPrevents directory traversal attacks.\n\nArgs:\n    path: Path to check\n    base_dir: Base directory that should contain the path\n\nReturns:\n    True if path is safe, False otherwise",
          "signature": {
            "parameters": [
              {
                "name": "path",
                "type": "str"
              },
              {
                "name": "base_dir",
                "type": "str"
              }
            ],
            "return_type": "bool"
          }
        },
        {
          "name": "atomic_write",
          "line": 286,
          "docstring": "Write file atomically using temporary file and rename.\n\nPrevents partial writes in case of interruption.\n\nArgs:\n    file_path: Destination file path\n    content: Content to write\n    encoding: Text encoding (default: utf-8)\n\nRaises:\n    OSError: If write fails",
          "signature": {
            "parameters": [
              {
                "name": "file_path",
                "type": "str"
              },
              {
                "name": "content",
                "type": "str"
              },
              {
                "name": "encoding",
                "type": "str"
              }
            ],
            "return_type": "None"
          }
        },
        {
          "name": "get_available_disk_space",
          "line": 320,
          "docstring": "Get available disk space in GB for the filesystem containing path.\n\nArgs:\n    path: Any path on the filesystem to check\n\nReturns:\n    Available space in GB\n\nRaises:\n    OSError: If path doesn't exist or space check fails",
          "signature": {
            "parameters": [
              {
                "name": "path",
                "type": "str"
              }
            ],
            "return_type": "float"
          }
        }
      ]
    },
    "src.drawing_intelligence.utils.geometry_utils": {
      "file_path": "C:\\00Projects\\engineering_items_attributes_enrichment\\src\\drawing_intelligence\\utils\\geometry_utils.py",
      "module_docstring": "Geometry utilities for the Drawing Intelligence System.\n\nThis module provides dataclasses and utility functions for working with bounding boxes\nin both pixel and normalized coordinate systems. Key functionality includes:\n- Bounding box operations (IoU, overlap detection, containment checks)\n- Coordinate transformations (normalization, denormalization)\n- Geometric calculations (distance, area, aspect ratio)\n- Spatial manipulations (scaling, expanding, merging, clipping)\n\nThe module supports two coordinate systems:\n- BoundingBox: Integer pixel coordinates (x, y, width, height)\n- NormalizedBBox: Normalized [0,1] coordinates (x_center, y_center, width, height)\n\nTypical usage:\n    from drawing_intelligence.utils.geometry_utils import BoundingBox, calculate_iou\n\n    bbox1 = BoundingBox(x=10, y=20, width=100, height=50)\n    bbox2 = BoundingBox(x=50, y=30, width=100, height=50)\n    overlap = calculate_iou(bbox1, bbox2)",
      "classes": {
        "BoundingBox": {
          "line": 29,
          "docstring": "Bounding box with integer pixel coordinates.\n\nUses top-left corner (x, y) and dimensions (width, height) representation.\nAll coordinates must be non-negative integers.\n\nAttributes:\n    x: Left coordinate (pixels from left edge)\n    y: Top coordinate (pixels from top edge)\n    width: Width in pixels (must be >= 0)\n    height: Height in pixels (must be >= 0)\n\nRaises:\n    ValueError: If width or height is negative.\n\nExample:\n    >>> bbox = BoundingBox(x=10, y=20, width=100, height=50)\n    >>> bbox.center()\n    (60.0, 45.0)\n    >>> bbox.area()\n    5000",
          "bases": [],
          "methods": [
            {
              "name": "__post_init__",
              "line": 58,
              "docstring": "Validate bounding box dimensions.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "center",
              "line": 65,
              "docstring": "Calculate center point of bounding box with sub-pixel precision.\n\nReturns:\n    Tuple of (center_x, center_y) as floats\n\nExample:\n    >>> bbox = BoundingBox(x=10, y=20, width=11, height=11)\n    >>> bbox.center()\n    (15.5, 25.5)",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "Tuple[float, float]"
              },
              "method_type": "instance"
            },
            {
              "name": "area",
              "line": 81,
              "docstring": "Calculate area of bounding box.\n\nReturns:\n    Area in square pixels",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "int"
              },
              "method_type": "instance"
            },
            {
              "name": "iou",
              "line": 90,
              "docstring": "Calculate Intersection over Union with another bounding box.\n\nArgs:\n    other: Another BoundingBox\n\nReturns:\n    IoU score (0.0 to 1.0)",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "other",
                    "type": "'BoundingBox'"
                  }
                ],
                "return_type": "float"
              },
              "method_type": "instance"
            },
            {
              "name": "to_tuple",
              "line": 102,
              "docstring": "Convert to (x, y, width, height) tuple.\n\nReturns:\n    Tuple of (x, y, width, height)",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "Tuple[int, int, int, int]"
              },
              "method_type": "instance"
            },
            {
              "name": "to_corners",
              "line": 111,
              "docstring": "Convert to (x1, y1, x2, y2) corner coordinates.\n\nReturns:\n    Tuple of (x1, y1, x2, y2) representing top-left and bottom-right corners",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "Tuple[int, int, int, int]"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        },
        "NormalizedBBox": {
          "line": 122,
          "docstring": "Normalized bounding box with coordinates in [0, 1] range.\n\nUses center-based representation with normalized coordinates relative to\nimage dimensions. Commonly used for ML model input/output.\n\nAttributes:\n    x_center: Normalized center x coordinate (0.0 to 1.0)\n    y_center: Normalized center y coordinate (0.0 to 1.0)\n    width: Normalized width (0.0 to 1.0)\n    height: Normalized height (0.0 to 1.0)\n\nRaises:\n    ValueError: If any coordinate is outside [0, 1] range.\n\nExample:\n    >>> norm_bbox = NormalizedBBox(x_center=0.5, y_center=0.5, width=0.2, height=0.1)\n    >>> norm_bbox.to_tuple()\n    (0.5, 0.5, 0.2, 0.1)",
          "bases": [],
          "methods": [
            {
              "name": "__post_init__",
              "line": 149,
              "docstring": "Validate normalized coordinates are in [0, 1] range.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "to_tuple",
              "line": 160,
              "docstring": "Convert to (x_center, y_center, width, height) tuple.\n\nReturns:\n    Tuple of (x_center, y_center, width, height)",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "Tuple[float, float, float, float]"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        }
      },
      "functions": [
        {
          "name": "calculate_iou",
          "line": 170,
          "docstring": "Calculate Intersection over Union between two bounding boxes.\n\nArgs:\n    bbox1: First bounding box\n    bbox2: Second bounding box\n\nReturns:\n    IoU score (0.0 to 1.0)\n\nExample:\n    >>> bbox1 = BoundingBox(x=0, y=0, width=10, height=10)\n    >>> bbox2 = BoundingBox(x=5, y=5, width=10, height=10)\n    >>> calculate_iou(bbox1, bbox2)\n    0.25",
          "signature": {
            "parameters": [
              {
                "name": "bbox1",
                "type": "BoundingBox"
              },
              {
                "name": "bbox2",
                "type": "BoundingBox"
              }
            ],
            "return_type": "float"
          }
        },
        {
          "name": "calculate_distance",
          "line": 217,
          "docstring": "Calculate Euclidean distance between two points.\n\nArgs:\n    point1: First point (x, y)\n    point2: Second point (x, y)\n\nReturns:\n    Distance in pixels\n\nExample:\n    >>> calculate_distance((0, 0), (3, 4))\n    5.0",
          "signature": {
            "parameters": [
              {
                "name": "point1",
                "type": "Tuple[int, int]"
              },
              {
                "name": "point2",
                "type": "Tuple[int, int]"
              }
            ],
            "return_type": "float"
          }
        },
        {
          "name": "bbox_contains",
          "line": 238,
          "docstring": "Check if inner bounding box is completely inside outer bounding box.\n\nArgs:\n    outer: Outer bounding box\n    inner: Inner bounding box\n\nReturns:\n    True if inner is completely inside outer\n\nExample:\n    >>> outer = BoundingBox(x=0, y=0, width=100, height=100)\n    >>> inner = BoundingBox(x=10, y=10, width=20, height=20)\n    >>> bbox_contains(outer, inner)\n    True",
          "signature": {
            "parameters": [
              {
                "name": "outer",
                "type": "BoundingBox"
              },
              {
                "name": "inner",
                "type": "BoundingBox"
              }
            ],
            "return_type": "bool"
          }
        },
        {
          "name": "bbox_overlaps",
          "line": 266,
          "docstring": "Check if two bounding boxes overlap.\n\nArgs:\n    bbox1: First bounding box\n    bbox2: Second bounding box\n\nReturns:\n    True if boxes overlap\n\nExample:\n    >>> bbox1 = BoundingBox(x=0, y=0, width=10, height=10)\n    >>> bbox2 = BoundingBox(x=5, y=5, width=10, height=10)\n    >>> bbox_overlaps(bbox1, bbox2)\n    True",
          "signature": {
            "parameters": [
              {
                "name": "bbox1",
                "type": "BoundingBox"
              },
              {
                "name": "bbox2",
                "type": "BoundingBox"
              }
            ],
            "return_type": "bool"
          }
        },
        {
          "name": "expand_bbox",
          "line": 297,
          "docstring": "Expand bounding box by N pixels in all directions.\n\nExpands the box symmetrically around its center. If max dimensions are\nprovided, clips the result to stay within those bounds.\n\nArgs:\n    bbox: Original bounding box\n    pixels: Number of pixels to expand (can be negative to shrink)\n    max_width: Optional maximum width to clip expansion (image width)\n    max_height: Optional maximum height to clip expansion (image height)\n\nReturns:\n    Expanded bounding box clipped to boundaries if max dimensions provided.\n    May return a zero-area box if shrinkage or clipping results in no area.\n\nExample:\n    >>> bbox = BoundingBox(x=5, y=5, width=10, height=10)\n    >>> expand_bbox(bbox, pixels=10, max_width=100, max_height=100)\n    BoundingBox(x=0, y=0, width=25, height=25)",
          "signature": {
            "parameters": [
              {
                "name": "bbox",
                "type": "BoundingBox"
              },
              {
                "name": "pixels",
                "type": "int"
              },
              {
                "name": "max_width",
                "type": "Optional[int]"
              },
              {
                "name": "max_height",
                "type": "Optional[int]"
              }
            ],
            "return_type": "BoundingBox"
          }
        },
        {
          "name": "merge_bboxes",
          "line": 351,
          "docstring": "Merge multiple bounding boxes into single bounding box.\n\nArgs:\n    bboxes: List of bounding boxes to merge\n\nReturns:\n    Merged bounding box that contains all input boxes. Returns a zero-area\n    bounding box at origin if input list is empty.\n\nExample:\n    >>> boxes = [BoundingBox(0, 0, 10, 10), BoundingBox(20, 20, 10, 10)]\n    >>> merge_bboxes(boxes)\n    BoundingBox(x=0, y=0, width=30, height=30)\n    >>> merge_bboxes([])\n    BoundingBox(x=0, y=0, width=0, height=0)",
          "signature": {
            "parameters": [
              {
                "name": "bboxes",
                "type": "List[BoundingBox]"
              }
            ],
            "return_type": "BoundingBox"
          }
        },
        {
          "name": "normalize_bbox",
          "line": 386,
          "docstring": "Normalize bounding box to [0, 1] coordinates relative to image size.\n\nArgs:\n    bbox: Bounding box in pixel coordinates\n    image_width: Image width in pixels\n    image_height: Image height in pixels\n\nReturns:\n    Normalized bounding box\n\nRaises:\n    ValueError: If image dimensions are zero or negative\n\nExample:\n    >>> bbox = BoundingBox(x=50, y=100, width=100, height=50)\n    >>> normalize_bbox(bbox, 200, 200)\n    NormalizedBBox(x_center=0.5, y_center=0.625, width=0.5, height=0.25)",
          "signature": {
            "parameters": [
              {
                "name": "bbox",
                "type": "BoundingBox"
              },
              {
                "name": "image_width",
                "type": "int"
              },
              {
                "name": "image_height",
                "type": "int"
              }
            ],
            "return_type": "NormalizedBBox"
          }
        },
        {
          "name": "denormalize_bbox",
          "line": 434,
          "docstring": "Convert normalized bounding box back to pixel coordinates.\n\nUses rounding for better geometric accuracy when converting from\nfloating-point normalized coordinates to integer pixel coordinates.\n\nArgs:\n    norm_bbox: Normalized bounding box\n    image_width: Image width in pixels\n    image_height: Image height in pixels\n\nReturns:\n    Bounding box in pixel coordinates\n\nRaises:\n    ValueError: If image dimensions are zero or negative\n\nExample:\n    >>> norm = NormalizedBBox(x_center=0.5, y_center=0.5, width=0.5, height=0.25)\n    >>> denormalize_bbox(norm, 200, 200)\n    BoundingBox(x=50, y=75, width=100, height=50)",
          "signature": {
            "parameters": [
              {
                "name": "norm_bbox",
                "type": "NormalizedBBox"
              },
              {
                "name": "image_width",
                "type": "int"
              },
              {
                "name": "image_height",
                "type": "int"
              }
            ],
            "return_type": "BoundingBox"
          }
        },
        {
          "name": "clip_bbox_to_image",
          "line": 485,
          "docstring": "Clip bounding box to image boundaries.\n\nIf the bounding box is completely outside the image, returns a zero-area\nbounding box. Callers can check result.area() == 0 to detect this case.\n\nArgs:\n    bbox: Original bounding box\n    image_width: Image width in pixels\n    image_height: Image height in pixels\n\nReturns:\n    Clipped bounding box within image bounds (may have zero area)\n\nExample:\n    >>> bbox = BoundingBox(x=-10, y=-10, width=50, height=50)\n    >>> clipped = clip_bbox_to_image(bbox, 100, 100)\n    >>> clipped\n    BoundingBox(x=0, y=0, width=40, height=40)",
          "signature": {
            "parameters": [
              {
                "name": "bbox",
                "type": "BoundingBox"
              },
              {
                "name": "image_width",
                "type": "int"
              },
              {
                "name": "image_height",
                "type": "int"
              }
            ],
            "return_type": "BoundingBox"
          }
        },
        {
          "name": "bbox_intersection",
          "line": 522,
          "docstring": "Calculate intersection rectangle of two bounding boxes.\n\nArgs:\n    bbox1: First bounding box\n    bbox2: Second bounding box\n\nReturns:\n    Intersection bounding box. If boxes don't overlap, returns a zero-area\n    bounding box at origin. Callers can check result.area() == 0.\n\nExample:\n    >>> bbox1 = BoundingBox(x=0, y=0, width=10, height=10)\n    >>> bbox2 = BoundingBox(x=5, y=5, width=10, height=10)\n    >>> intersection = bbox_intersection(bbox1, bbox2)\n    >>> intersection\n    BoundingBox(x=5, y=5, width=5, height=5)",
          "signature": {
            "parameters": [
              {
                "name": "bbox1",
                "type": "BoundingBox"
              },
              {
                "name": "bbox2",
                "type": "BoundingBox"
              }
            ],
            "return_type": "BoundingBox"
          }
        },
        {
          "name": "calculate_aspect_ratio",
          "line": 562,
          "docstring": "Calculate aspect ratio of bounding box.\n\nArgs:\n    bbox: Bounding box\n\nReturns:\n    Aspect ratio (width / height)\n\nRaises:\n    ValueError: If height is zero\n\nExample:\n    >>> bbox = BoundingBox(x=0, y=0, width=16, height=9)\n    >>> calculate_aspect_ratio(bbox)\n    1.7777777777777777",
          "signature": {
            "parameters": [
              {
                "name": "bbox",
                "type": "BoundingBox"
              }
            ],
            "return_type": "float"
          }
        },
        {
          "name": "point_in_bbox",
          "line": 586,
          "docstring": "Check if a point is inside a bounding box.\n\nArgs:\n    point: Point coordinates (x, y)\n    bbox: Bounding box\n\nReturns:\n    True if point is inside bbox (inclusive of edges)\n\nExample:\n    >>> bbox = BoundingBox(x=0, y=0, width=10, height=10)\n    >>> point_in_bbox((5, 5), bbox)\n    True\n    >>> point_in_bbox((15, 15), bbox)\n    False",
          "signature": {
            "parameters": [
              {
                "name": "point",
                "type": "Tuple[int, int]"
              },
              {
                "name": "bbox",
                "type": "BoundingBox"
              }
            ],
            "return_type": "bool"
          }
        },
        {
          "name": "bbox_distance",
          "line": 610,
          "docstring": "Calculate minimum edge-to-edge distance between two bounding boxes.\n\nReturns 0.0 if boxes overlap. For non-overlapping boxes, calculates the\nshortest distance between any two edges.\n\nArgs:\n    bbox1: First bounding box\n    bbox2: Second bounding box\n\nReturns:\n    Minimum distance in pixels (0.0 if boxes overlap)\n\nExample:\n    >>> bbox1 = BoundingBox(x=0, y=0, width=10, height=10)\n    >>> bbox2 = BoundingBox(x=20, y=0, width=10, height=10)\n    >>> bbox_distance(bbox1, bbox2)\n    10.0",
          "signature": {
            "parameters": [
              {
                "name": "bbox1",
                "type": "BoundingBox"
              },
              {
                "name": "bbox2",
                "type": "BoundingBox"
              }
            ],
            "return_type": "float"
          }
        },
        {
          "name": "scale_bbox",
          "line": 658,
          "docstring": "Scale bounding box by a factor around its center.\n\nArgs:\n    bbox: Original bounding box\n    scale_factor: Scale factor (e.g., 1.5 for 150%, 0.5 for 50%)\n\nReturns:\n    Scaled bounding box\n\nRaises:\n    ValueError: If scale_factor is negative\n\nExample:\n    >>> bbox = BoundingBox(x=10, y=10, width=20, height=20)\n    >>> scale_bbox(bbox, scale_factor=2.0)\n    BoundingBox(x=0, y=0, width=40, height=40)",
          "signature": {
            "parameters": [
              {
                "name": "bbox",
                "type": "BoundingBox"
              },
              {
                "name": "scale_factor",
                "type": "float"
              }
            ],
            "return_type": "BoundingBox"
          }
        }
      ]
    },
    "src.drawing_intelligence.utils.image_utils": {
      "file_path": "C:\\00Projects\\engineering_items_attributes_enrichment\\src\\drawing_intelligence\\utils\\image_utils.py",
      "module_docstring": "Image utilities for the Drawing Intelligence System.\n\nProvides functions for image encoding, manipulation, and visualization.",
      "classes": {},
      "functions": [
        {
          "name": "encode_image_base64",
          "line": 16,
          "docstring": "Encode numpy image to base64 string.\n\nArgs:\n    image: Numpy array (BGR or grayscale)\n    format: Image format ('PNG', 'JPEG')\n\nReturns:\n    Base64-encoded string\n\nRaises:\n    ValueError: If image is invalid or encoding fails",
          "signature": {
            "parameters": [
              {
                "name": "image",
                "type": "np.ndarray"
              },
              {
                "name": "format",
                "type": "str"
              }
            ],
            "return_type": "str"
          }
        },
        {
          "name": "decode_image_base64",
          "line": 60,
          "docstring": "Decode base64 string to numpy image.\n\nArgs:\n    base64_string: Base64-encoded image string\n\nReturns:\n    Numpy array in BGR format\n\nRaises:\n    ValueError: If decoding fails",
          "signature": {
            "parameters": [
              {
                "name": "base64_string",
                "type": "str"
              }
            ],
            "return_type": "np.ndarray"
          }
        },
        {
          "name": "resize_image",
          "line": 98,
          "docstring": "Resize image to fit within dimensions.\n\nArgs:\n    image: Input image\n    max_width: Maximum width\n    max_height: Maximum height\n    maintain_aspect: Whether to maintain aspect ratio\n\nReturns:\n    Resized image",
          "signature": {
            "parameters": [
              {
                "name": "image",
                "type": "np.ndarray"
              },
              {
                "name": "max_width",
                "type": "int"
              },
              {
                "name": "max_height",
                "type": "int"
              },
              {
                "name": "maintain_aspect",
                "type": "bool"
              }
            ],
            "return_type": "np.ndarray"
          }
        },
        {
          "name": "crop_image",
          "line": 137,
          "docstring": "Crop image using bounding box.\n\nArgs:\n    image: Input image\n    bbox: BoundingBox object with x, y, width, height\n\nReturns:\n    Cropped image\n\nRaises:\n    ValueError: If bbox is invalid or out of bounds",
          "signature": {
            "parameters": [
              {
                "name": "image",
                "type": "np.ndarray"
              },
              {
                "name": "bbox",
                "type": "'BoundingBox'"
              }
            ],
            "return_type": "np.ndarray"
          }
        },
        {
          "name": "draw_bboxes",
          "line": 166,
          "docstring": "Draw bounding boxes on image for visualization.\n\nArgs:\n    image: Input image\n    bboxes: List of BoundingBox objects\n    labels: Optional list of labels for each bbox\n    colors: Optional list of BGR colors for each bbox\n    thickness: Line thickness\n    font_scale: Label font scale\n\nReturns:\n    Image with drawn bounding boxes",
          "signature": {
            "parameters": [
              {
                "name": "image",
                "type": "np.ndarray"
              },
              {
                "name": "bboxes",
                "type": "List['BoundingBox']"
              },
              {
                "name": "labels",
                "type": "Optional[List[str]]"
              },
              {
                "name": "colors",
                "type": "Optional[List[Tuple[int, int, int]]]"
              },
              {
                "name": "thickness",
                "type": "int"
              },
              {
                "name": "font_scale",
                "type": "float"
              }
            ],
            "return_type": "np.ndarray"
          }
        },
        {
          "name": "calculate_image_hash",
          "line": 244,
          "docstring": "Calculate perceptual hash of image (average hash algorithm).\n\nArgs:\n    image: Input image\n    hash_size: Size of hash (default: 8 for 64-bit hash)\n\nReturns:\n    Hash string (hexadecimal)",
          "signature": {
            "parameters": [
              {
                "name": "image",
                "type": "np.ndarray"
              },
              {
                "name": "hash_size",
                "type": "int"
              }
            ],
            "return_type": "str"
          }
        },
        {
          "name": "images_are_similar",
          "line": 277,
          "docstring": "Check if two images are similar using perceptual hashing.\n\nArgs:\n    image1: First image\n    image2: Second image\n    threshold: Similarity threshold (0.0-1.0)\n\nReturns:\n    True if images are similar above threshold",
          "signature": {
            "parameters": [
              {
                "name": "image1",
                "type": "np.ndarray"
              },
              {
                "name": "image2",
                "type": "np.ndarray"
              },
              {
                "name": "threshold",
                "type": "float"
              }
            ],
            "return_type": "bool"
          }
        },
        {
          "name": "calculate_md5_hash",
          "line": 306,
          "docstring": "Calculate MD5 hash of image data (exact match, not perceptual).\n\nArgs:\n    image: Input image\n\nReturns:\n    MD5 hash string",
          "signature": {
            "parameters": [
              {
                "name": "image",
                "type": "np.ndarray"
              }
            ],
            "return_type": "str"
          }
        },
        {
          "name": "pad_image",
          "line": 321,
          "docstring": "Pad image to target size with specified value.\n\nArgs:\n    image: Input image\n    target_width: Target width\n    target_height: Target height\n    pad_value: Padding value (default: 255 for white)\n\nReturns:\n    Padded image",
          "signature": {
            "parameters": [
              {
                "name": "image",
                "type": "np.ndarray"
              },
              {
                "name": "target_width",
                "type": "int"
              },
              {
                "name": "target_height",
                "type": "int"
              },
              {
                "name": "pad_value",
                "type": "int"
              }
            ],
            "return_type": "np.ndarray"
          }
        },
        {
          "name": "create_thumbnail",
          "line": 376,
          "docstring": "Create thumbnail of image with max dimension.\n\nArgs:\n    image: Input image\n    max_size: Maximum dimension (width or height)\n\nReturns:\n    Thumbnail image",
          "signature": {
            "parameters": [
              {
                "name": "image",
                "type": "np.ndarray"
              },
              {
                "name": "max_size",
                "type": "int"
              }
            ],
            "return_type": "np.ndarray"
          }
        },
        {
          "name": "concatenate_images",
          "line": 390,
          "docstring": "Concatenate multiple images with spacing.\n\nArgs:\n    images: List of images to concatenate\n    orientation: 'horizontal' or 'vertical'\n    spacing: Spacing between images in pixels\n    background_color: Background color for spacing (BGR)\n\nReturns:\n    Concatenated image",
          "signature": {
            "parameters": [
              {
                "name": "images",
                "type": "List[np.ndarray]"
              },
              {
                "name": "orientation",
                "type": "str"
              },
              {
                "name": "spacing",
                "type": "int"
              },
              {
                "name": "background_color",
                "type": "Tuple[int, int, int]"
              }
            ],
            "return_type": "np.ndarray"
          }
        }
      ]
    },
    "src.drawing_intelligence.utils.pdf_utils": {
      "file_path": "C:\\00Projects\\engineering_items_attributes_enrichment\\src\\drawing_intelligence\\utils\\pdf_utils.py",
      "module_docstring": "Utility functions for PDF processing operations.\n\nThis module contains reusable helper functions for coordinate conversion,\ncolor space transformation, and spatial analysis operations used across\nPDF processing modules.\n\nLocation: src/drawing_intelligence/utils/pdf_utils.py\n\nFunctions:\n    convert_rgb_to_bgr: Convert RGB image to BGR format for OpenCV.\n    convert_pdf_points_to_pixels: Convert PDF point coordinates to pixels.\n    normalize_bbox: Normalize bounding box coordinates to 0-1 range.\n    calculate_bbox_area: Calculate area of a bounding box.\n    bbox_iou: Calculate Intersection over Union between two bounding boxes.\n    validate_bbox: Validate bounding box is well-formed and within bounds.\n    clip_bbox_to_image: Clip bounding box coordinates to image boundaries.",
      "classes": {},
      "functions": [
        {
          "name": "convert_rgb_to_bgr",
          "line": 27,
          "docstring": "Convert RGB image to BGR format for OpenCV compatibility.\n\nOpenCV uses BGR color order by default, while most image sources\n(including PyMuPDF) use RGB. This function performs the conversion.\n\nArgs:\n    image: RGB image array with shape (height, width, 3) and dtype uint8.\n\nReturns:\n    BGR image array with same shape and dtype.\n\nExample:\n    >>> rgb_image = load_rgb_image()\n    >>> bgr_image = convert_rgb_to_bgr(rgb_image)\n    >>> cv2.imshow(\"Image\", bgr_image)  # OpenCV expects BGR",
          "signature": {
            "parameters": [
              {
                "name": "image",
                "type": "NDArray[np.uint8]"
              }
            ],
            "return_type": "NDArray[np.uint8]"
          }
        },
        {
          "name": "convert_pdf_points_to_pixels",
          "line": 47,
          "docstring": "Convert PDF point coordinates to pixel coordinates at specified DPI.\n\nPDF uses points as the base unit where 1 point = 1/72 inch. This function\nconverts point coordinates to pixels based on the target DPI.\n\nArgs:\n    points: Coordinates in PDF points as tuple (x0, y0, x1, y1).\n    dpi: Target dots per inch for conversion. Standard values are\n        72 (screen), 150 (draft), 300 (standard print), 600 (high quality).\n\nReturns:\n    Coordinates in pixels as tuple (x0, y0, x1, y1) with integer values.\n\nNote:\n    Conversion formula: pixels = points * (dpi / 72.0)\n\nExample:\n    >>> pdf_bbox = (0.0, 0.0, 612.0, 792.0)  # Letter size in points\n    >>> pixel_bbox = convert_pdf_points_to_pixels(pdf_bbox, 300)\n    >>> print(pixel_bbox)  # (0, 0, 2550, 3300) at 300 DPI",
          "signature": {
            "parameters": [
              {
                "name": "points",
                "type": "Tuple[float, float, float, float]"
              },
              {
                "name": "dpi",
                "type": "int"
              }
            ],
            "return_type": "Tuple[int, int, int, int]"
          }
        },
        {
          "name": "normalize_bbox",
          "line": 80,
          "docstring": "Normalize bounding box coordinates to 0-1 range.\n\nConverts absolute pixel coordinates to normalized coordinates relative\nto image dimensions. Useful for scale-invariant representations.\n\nArgs:\n    bbox: Bounding box in pixels as (x0, y0, x1, y1).\n    image_width: Width of the image in pixels.\n    image_height: Height of the image in pixels.\n\nReturns:\n    Normalized bounding box as (x0_norm, y0_norm, x1_norm, y1_norm)\n    where all values are in range [0.0, 1.0].\n\nRaises:\n    ValueError: If image dimensions are zero or negative.\n\nExample:\n    >>> bbox = (100, 200, 300, 400)\n    >>> normalized = normalize_bbox(bbox, 800, 600)\n    >>> print(normalized)  # (0.125, 0.333, 0.375, 0.667)",
          "signature": {
            "parameters": [
              {
                "name": "bbox",
                "type": "Tuple[int, int, int, int]"
              },
              {
                "name": "image_width",
                "type": "int"
              },
              {
                "name": "image_height",
                "type": "int"
              }
            ],
            "return_type": "Tuple[float, float, float, float]"
          }
        },
        {
          "name": "calculate_bbox_area",
          "line": 119,
          "docstring": "Calculate area of a bounding box in square pixels.\n\nArgs:\n    bbox: Bounding box as (x0, y0, x1, y1) where (x0, y0) is top-left\n        and (x1, y1) is bottom-right corner.\n\nReturns:\n    Area in square pixels. Returns 0 for invalid bounding boxes where\n    x1 <= x0 or y1 <= y0.\n\nExample:\n    >>> bbox = (10, 20, 50, 60)\n    >>> area = calculate_bbox_area(bbox)\n    >>> print(area)  # 1600 (40 * 40)",
          "signature": {
            "parameters": [
              {
                "name": "bbox",
                "type": "Tuple[int, int, int, int]"
              }
            ],
            "return_type": "int"
          }
        },
        {
          "name": "bbox_iou",
          "line": 140,
          "docstring": "Calculate Intersection over Union (IoU) between two bounding boxes.\n\nIoU is a metric for measuring overlap between two bounding boxes,\ncommonly used in object detection and spatial analysis.\n\nArgs:\n    bbox1: First bounding box as (x0, y0, x1, y1).\n    bbox2: Second bounding box as (x0, y0, x1, y1).\n\nReturns:\n    IoU value in range [0.0, 1.0] where:\n        - 0.0 = no overlap\n        - 1.0 = perfect overlap (identical boxes)\n\nNote:\n    Returns 0.0 if either bounding box has zero area.\n\nExample:\n    >>> box1 = (0, 0, 100, 100)\n    >>> box2 = (50, 50, 150, 150)\n    >>> iou = bbox_iou(box1, box2)\n    >>> print(f\"IoU: {iou:.2f}\")  # IoU: 0.14 (2500 / 17500)",
          "signature": {
            "parameters": [
              {
                "name": "bbox1",
                "type": "Tuple[int, int, int, int]"
              },
              {
                "name": "bbox2",
                "type": "Tuple[int, int, int, int]"
              }
            ],
            "return_type": "float"
          }
        },
        {
          "name": "validate_bbox",
          "line": 189,
          "docstring": "Validate that bounding box is within image bounds and well-formed.\n\nArgs:\n    bbox: Bounding box as (x0, y0, x1, y1).\n    max_width: Maximum allowed width (image width).\n    max_height: Maximum allowed height (image height).\n\nReturns:\n    True if bounding box is valid, False otherwise.\n\nNote:\n    A valid bounding box must satisfy:\n        - x0 < x1 and y0 < y1 (positive dimensions)\n        - All coordinates >= 0\n        - x1 <= max_width and y1 <= max_height (within bounds)\n\nExample:\n    >>> bbox = (10, 20, 100, 80)\n    >>> is_valid = validate_bbox(bbox, 200, 150)\n    >>> print(is_valid)  # True",
          "signature": {
            "parameters": [
              {
                "name": "bbox",
                "type": "Tuple[int, int, int, int]"
              },
              {
                "name": "max_width",
                "type": "int"
              },
              {
                "name": "max_height",
                "type": "int"
              }
            ],
            "return_type": "bool"
          }
        },
        {
          "name": "clip_bbox_to_image",
          "line": 230,
          "docstring": "Clip bounding box coordinates to image boundaries.\n\nEnsures bounding box stays within image dimensions by clamping\ncoordinates to valid ranges.\n\nArgs:\n    bbox: Bounding box as (x0, y0, x1, y1).\n    image_width: Width of the image in pixels.\n    image_height: Height of the image in pixels.\n\nReturns:\n    Clipped bounding box with all coordinates within [0, width/height].\n\nExample:\n    >>> bbox = (-10, 50, 1000, 200)\n    >>> clipped = clip_bbox_to_image(bbox, 800, 600)\n    >>> print(clipped)  # (0, 50, 800, 200)",
          "signature": {
            "parameters": [
              {
                "name": "bbox",
                "type": "Tuple[int, int, int, int]"
              },
              {
                "name": "image_width",
                "type": "int"
              },
              {
                "name": "image_height",
                "type": "int"
              }
            ],
            "return_type": "Tuple[int, int, int, int]"
          }
        }
      ]
    },
    "src.drawing_intelligence.utils.text_utils": {
      "file_path": "C:\\00Projects\\engineering_items_attributes_enrichment\\src\\drawing_intelligence\\utils\\text_utils.py",
      "module_docstring": "Text utilities for the Drawing Intelligence System.\n\nProvides functions for text processing, normalization, and unit conversion.",
      "classes": {},
      "functions": [
        {
          "name": "normalize_whitespace",
          "line": 52,
          "docstring": "Normalize multiple spaces, tabs, newlines to single space.\n\nArgs:\n    text: Input text\n\nReturns:\n    Normalized text with single spaces",
          "signature": {
            "parameters": [
              {
                "name": "text",
                "type": "str"
              }
            ],
            "return_type": "str"
          }
        },
        {
          "name": "remove_special_characters",
          "line": 68,
          "docstring": "Remove special characters, optionally keeping some.\n\nArgs:\n    text: Input text\n    keep: String of characters to keep (e.g., '.-_')\n\nReturns:\n    Cleaned text",
          "signature": {
            "parameters": [
              {
                "name": "text",
                "type": "str"
              },
              {
                "name": "keep",
                "type": "Optional[str]"
              }
            ],
            "return_type": "str"
          }
        },
        {
          "name": "extract_numbers",
          "line": 90,
          "docstring": "Extract all numeric values from text.\n\nHandles integers, decimals, and numbers with separators.\n\nArgs:\n    text: Input text\n\nReturns:\n    List of numbers found",
          "signature": {
            "parameters": [
              {
                "name": "text",
                "type": "str"
              }
            ],
            "return_type": "List[float]"
          }
        },
        {
          "name": "detect_measurement_unit",
          "line": 119,
          "docstring": "Detect measurement unit in text.\n\nArgs:\n    text: Input text (e.g., \"25.4mm\", \"1.5 inches\")\n\nReturns:\n    Unit string or None if not found",
          "signature": {
            "parameters": [
              {
                "name": "text",
                "type": "str"
              }
            ],
            "return_type": "Optional[str]"
          }
        },
        {
          "name": "convert_unit",
          "line": 141,
          "docstring": "Convert between measurement units.\n\nArgs:\n    value: Numeric value\n    from_unit: Source unit (e.g., 'inch', 'mm')\n    to_unit: Target unit\n\nReturns:\n    Converted value\n\nRaises:\n    ValueError: If units are unknown or incompatible",
          "signature": {
            "parameters": [
              {
                "name": "value",
                "type": "float"
              },
              {
                "name": "from_unit",
                "type": "str"
              },
              {
                "name": "to_unit",
                "type": "str"
              }
            ],
            "return_type": "float"
          }
        },
        {
          "name": "fuzzy_match",
          "line": 184,
          "docstring": "Fuzzy string matching using sequence matcher.\n\nArgs:\n    text1: First string\n    text2: Second string\n    threshold: Similarity threshold (0.0 to 1.0)\n\nReturns:\n    True if strings are similar above threshold",
          "signature": {
            "parameters": [
              {
                "name": "text1",
                "type": "str"
              },
              {
                "name": "text2",
                "type": "str"
              },
              {
                "name": "threshold",
                "type": "float"
              }
            ],
            "return_type": "bool"
          }
        },
        {
          "name": "extract_pattern",
          "line": 206,
          "docstring": "Extract first match of regex pattern from text.\n\nArgs:\n    text: Input text\n    pattern: Regular expression pattern\n\nReturns:\n    Matched string or None",
          "signature": {
            "parameters": [
              {
                "name": "text",
                "type": "str"
              },
              {
                "name": "pattern",
                "type": "str"
              }
            ],
            "return_type": "Optional[str]"
          }
        },
        {
          "name": "normalize_technical_symbols",
          "line": 223,
          "docstring": "Normalize technical symbols to readable text.\n\nArgs:\n    text: Input text with symbols\n\nReturns:\n    Text with symbols replaced by readable equivalents",
          "signature": {
            "parameters": [
              {
                "name": "text",
                "type": "str"
              }
            ],
            "return_type": "str"
          }
        },
        {
          "name": "extract_dimension_value",
          "line": 239,
          "docstring": "Extract dimension value with tolerance and unit from text.\n\nHandles formats like:\n- \"25.4mm\"\n- \"25.4 \u00b1 0.1 mm\"\n- \"\u00d825.4mm\"\n- \"1.5 inch\"\n\nArgs:\n    text: Input text\n\nReturns:\n    Dict with 'value', 'tolerance', 'unit', 'is_diameter' or None",
          "signature": {
            "parameters": [
              {
                "name": "text",
                "type": "str"
              }
            ],
            "return_type": "Optional[Dict[str, any]]"
          }
        },
        {
          "name": "split_camel_case",
          "line": 291,
          "docstring": "Split camelCase or PascalCase text into words.\n\nArgs:\n    text: CamelCase text\n\nReturns:\n    Space-separated words",
          "signature": {
            "parameters": [
              {
                "name": "text",
                "type": "str"
              }
            ],
            "return_type": "str"
          }
        },
        {
          "name": "remove_duplicate_spaces",
          "line": 306,
          "docstring": "Remove duplicate spaces while preserving single spaces.\n\nArgs:\n    text: Input text\n\nReturns:\n    Text with single spaces only",
          "signature": {
            "parameters": [
              {
                "name": "text",
                "type": "str"
              }
            ],
            "return_type": "str"
          }
        },
        {
          "name": "truncate_text",
          "line": 319,
          "docstring": "Truncate text to maximum length with suffix.\n\nArgs:\n    text: Input text\n    max_length: Maximum length including suffix\n    suffix: Suffix to add if truncated (default: '...')\n\nReturns:\n    Truncated text",
          "signature": {
            "parameters": [
              {
                "name": "text",
                "type": "str"
              },
              {
                "name": "max_length",
                "type": "int"
              },
              {
                "name": "suffix",
                "type": "str"
              }
            ],
            "return_type": "str"
          }
        },
        {
          "name": "extract_part_number_candidates",
          "line": 338,
          "docstring": "Extract potential part numbers from text.\n\nPart numbers typically contain alphanumeric patterns with dashes/underscores.\n\nArgs:\n    text: Input text\n\nReturns:\n    List of candidate part numbers",
          "signature": {
            "parameters": [
              {
                "name": "text",
                "type": "str"
              }
            ],
            "return_type": "List[str]"
          }
        },
        {
          "name": "clean_ocr_text",
          "line": 356,
          "docstring": "Clean common OCR errors and artifacts.\n\nArgs:\n    text: OCR-extracted text\n\nReturns:\n    Cleaned text",
          "signature": {
            "parameters": [
              {
                "name": "text",
                "type": "str"
              }
            ],
            "return_type": "str"
          }
        },
        {
          "name": "extract_words",
          "line": 383,
          "docstring": "Extract words from text, filtering by minimum length.\n\nArgs:\n    text: Input text\n    min_length: Minimum word length to include\n\nReturns:\n    List of words",
          "signature": {
            "parameters": [
              {
                "name": "text",
                "type": "str"
              },
              {
                "name": "min_length",
                "type": "int"
              }
            ],
            "return_type": "List[str]"
          }
        },
        {
          "name": "is_numeric_text",
          "line": 400,
          "docstring": "Check if text is primarily numeric.\n\nArgs:\n    text: Input text\n\nReturns:\n    True if text is mostly numbers",
          "signature": {
            "parameters": [
              {
                "name": "text",
                "type": "str"
              }
            ],
            "return_type": "bool"
          }
        },
        {
          "name": "normalize_line_endings",
          "line": 422,
          "docstring": "Normalize line endings to Unix style (LF).\n\nArgs:\n    text: Input text\n\nReturns:\n    Text with normalized line endings",
          "signature": {
            "parameters": [
              {
                "name": "text",
                "type": "str"
              }
            ],
            "return_type": "str"
          }
        },
        {
          "name": "capitalize_first_letter",
          "line": 438,
          "docstring": "Capitalize first letter of text, leaving rest unchanged.\n\nArgs:\n    text: Input text\n\nReturns:\n    Text with first letter capitalized",
          "signature": {
            "parameters": [
              {
                "name": "text",
                "type": "str"
              }
            ],
            "return_type": "str"
          }
        },
        {
          "name": "count_words",
          "line": 453,
          "docstring": "Count number of words in text.\n\nArgs:\n    text: Input text\n\nReturns:\n    Word count",
          "signature": {
            "parameters": [
              {
                "name": "text",
                "type": "str"
              }
            ],
            "return_type": "int"
          }
        }
      ]
    },
    "src.drawing_intelligence.utils.validation_utils": {
      "file_path": "C:\\00Projects\\engineering_items_attributes_enrichment\\src\\drawing_intelligence\\utils\\validation_utils.py",
      "module_docstring": "Validation utilities for the Drawing Intelligence System.\n\nProvides validation functions for various data types and inputs.",
      "classes": {},
      "functions": [
        {
          "name": "validate_pdf_file",
          "line": 13,
          "docstring": "Validate PDF file exists and is readable.\n\nArgs:\n    file_path: Path to PDF file\n\nReturns:\n    Tuple of (is_valid, error_message)",
          "signature": {
            "parameters": [
              {
                "name": "file_path",
                "type": "str"
              }
            ],
            "return_type": "Tuple[bool, str]"
          }
        },
        {
          "name": "validate_image_array",
          "line": 50,
          "docstring": "Validate numpy array is a valid image.\n\nArgs:\n    image: Numpy array to validate\n\nReturns:\n    Tuple of (is_valid, error_message)",
          "signature": {
            "parameters": [
              {
                "name": "image",
                "type": "np.ndarray"
              }
            ],
            "return_type": "Tuple[bool, str]"
          }
        },
        {
          "name": "validate_bbox",
          "line": 95,
          "docstring": "Validate bounding box is within image bounds and has positive dimensions.\n\nArgs:\n    bbox: BoundingBox object\n    image_width: Image width\n    image_height: Image height\n\nReturns:\n    True if bbox is valid",
          "signature": {
            "parameters": [
              {
                "name": "bbox",
                "type": "'BoundingBox'"
              },
              {
                "name": "image_width",
                "type": "int"
              },
              {
                "name": "image_height",
                "type": "int"
              }
            ],
            "return_type": "bool"
          }
        },
        {
          "name": "validate_confidence_score",
          "line": 122,
          "docstring": "Validate confidence score is in valid range [0.0, 1.0].\n\nArgs:\n    score: Confidence score\n\nReturns:\n    True if score is valid",
          "signature": {
            "parameters": [
              {
                "name": "score",
                "type": "float"
              }
            ],
            "return_type": "bool"
          }
        },
        {
          "name": "validate_entity_type",
          "line": 138,
          "docstring": "Validate entity type is recognized.\n\nArgs:\n    entity_type: Entity type string\n\nReturns:\n    True if entity type is valid",
          "signature": {
            "parameters": [
              {
                "name": "entity_type",
                "type": "str"
              }
            ],
            "return_type": "bool"
          }
        },
        {
          "name": "validate_api_key",
          "line": 155,
          "docstring": "Validate API key format for provider.\n\nArgs:\n    provider: Provider name ('openai', 'anthropic', 'google')\n    api_key: API key string\n\nReturns:\n    Tuple of (is_valid, error_message)",
          "signature": {
            "parameters": [
              {
                "name": "provider",
                "type": "str"
              },
              {
                "name": "api_key",
                "type": "str"
              }
            ],
            "return_type": "Tuple[bool, str]"
          }
        },
        {
          "name": "validate_drawing_id",
          "line": 200,
          "docstring": "Validate drawing ID format.\n\nExpected format: PREFIX-YYYYMMDD-HHMMSS-HASH\nExample: DWG-20251102-143022-a1b2c3d4\n\nArgs:\n    drawing_id: Drawing ID string\n\nReturns:\n    True if ID format is valid",
          "signature": {
            "parameters": [
              {
                "name": "drawing_id",
                "type": "str"
              }
            ],
            "return_type": "bool"
          }
        },
        {
          "name": "validate_file_size",
          "line": 221,
          "docstring": "Validate file size is within limit.\n\nArgs:\n    file_path: Path to file\n    max_size_mb: Maximum size in megabytes\n\nReturns:\n    Tuple of (is_valid, error_message)",
          "signature": {
            "parameters": [
              {
                "name": "file_path",
                "type": "str"
              },
              {
                "name": "max_size_mb",
                "type": "float"
              }
            ],
            "return_type": "Tuple[bool, str]"
          }
        },
        {
          "name": "validate_directory_writable",
          "line": 244,
          "docstring": "Validate directory exists and is writable.\n\nArgs:\n    directory: Directory path\n\nReturns:\n    Tuple of (is_valid, error_message)",
          "signature": {
            "parameters": [
              {
                "name": "directory",
                "type": "str"
              }
            ],
            "return_type": "Tuple[bool, str]"
          }
        },
        {
          "name": "validate_model_path",
          "line": 266,
          "docstring": "Validate model file exists and has correct extension.\n\nArgs:\n    model_path: Path to model file\n\nReturns:\n    Tuple of (is_valid, error_message)",
          "signature": {
            "parameters": [
              {
                "name": "model_path",
                "type": "str"
              }
            ],
            "return_type": "Tuple[bool, str]"
          }
        },
        {
          "name": "validate_coordinate",
          "line": 292,
          "docstring": "Validate coordinate is within bounds.\n\nArgs:\n    x: X coordinate\n    y: Y coordinate\n    max_x: Maximum X value (exclusive)\n    max_y: Maximum Y value (exclusive)\n\nReturns:\n    True if coordinate is valid",
          "signature": {
            "parameters": [
              {
                "name": "x",
                "type": "int"
              },
              {
                "name": "y",
                "type": "int"
              },
              {
                "name": "max_x",
                "type": "int"
              },
              {
                "name": "max_y",
                "type": "int"
              }
            ],
            "return_type": "bool"
          }
        },
        {
          "name": "validate_percentage",
          "line": 308,
          "docstring": "Validate value is a valid percentage (0-100).\n\nArgs:\n    value: Percentage value\n\nReturns:\n    True if value is valid",
          "signature": {
            "parameters": [
              {
                "name": "value",
                "type": "float"
              }
            ],
            "return_type": "bool"
          }
        },
        {
          "name": "validate_email",
          "line": 321,
          "docstring": "Validate email address format.\n\nArgs:\n    email: Email address\n\nReturns:\n    True if email format is valid",
          "signature": {
            "parameters": [
              {
                "name": "email",
                "type": "str"
              }
            ],
            "return_type": "bool"
          }
        },
        {
          "name": "validate_url",
          "line": 339,
          "docstring": "Validate URL format.\n\nArgs:\n    url: URL string\n\nReturns:\n    True if URL format is valid",
          "signature": {
            "parameters": [
              {
                "name": "url",
                "type": "str"
              }
            ],
            "return_type": "bool"
          }
        },
        {
          "name": "validate_color",
          "line": 357,
          "docstring": "Validate BGR color tuple.\n\nArgs:\n    color: Tuple of (B, G, R) values\n\nReturns:\n    True if color is valid",
          "signature": {
            "parameters": [
              {
                "name": "color",
                "type": "Tuple[int, int, int]"
              }
            ],
            "return_type": "bool"
          }
        },
        {
          "name": "validate_json_serializable",
          "line": 373,
          "docstring": "Validate object is JSON serializable.\n\nArgs:\n    obj: Object to validate\n\nReturns:\n    Tuple of (is_valid, error_message)",
          "signature": {
            "parameters": [
              {
                "name": "obj",
                "type": "any"
              }
            ],
            "return_type": "Tuple[bool, str]"
          }
        }
      ]
    },
    "src.drawing_intelligence.utils": {
      "file_path": "C:\\00Projects\\engineering_items_attributes_enrichment\\src\\drawing_intelligence\\utils\\__init__.py",
      "module_docstring": "Utility functions for drawing intelligence system.",
      "classes": {},
      "functions": []
    },
    "src.drawing_intelligence.llm.providers.anthropic_provider": {
      "file_path": "C:\\00Projects\\engineering_items_attributes_enrichment\\src\\drawing_intelligence\\llm\\providers\\anthropic_provider.py",
      "module_docstring": "Anthropic (Claude) API Provider Implementation.\n\nThis module provides integration with Anthropic's Claude API, supporting both\ntext-only and vision-enabled prompts. Implements the LLMProvider interface\nwith automatic token usage tracking and credential validation.\n\nThe provider handles:\n- Lazy client initialization with thread safety\n- Image encoding and format validation for vision requests\n- Token usage extraction and cost calculation\n- Comprehensive error handling with retry logic\n- Rate limiting with exponential backoff\n\nNote:\n    Anthropic's API does not support structured output formats natively.\n    Use prompt engineering for structured outputs.",
      "classes": {
        "AnthropicProvider": {
          "line": 43,
          "docstring": "Concrete implementation of LLMProvider for Anthropic's Claude models.\n\nSupports Claude 3 model family including Opus, Sonnet, and Haiku variants.\nImplements lazy client initialization with thread safety to avoid connection\noverhead until first API call.\n\nAttributes:\n    api_key: The API key for Anthropic authentication.\n    model_registry: Reference to ModelRegistry for pricing/capabilities.\n    max_retries: Maximum number of retry attempts for rate limits.\n    PROVIDER_NAME: Constant identifier for this provider.\n\nExample:\n    >>> provider = AnthropicProvider(\n    ...     api_key=\"sk-ant-...\",\n    ...     model_registry=registry\n    ... )\n    >>> response = provider.call(\n    ...     prompt=\"Extract part numbers from this drawing\",\n    ...     image=drawing_bytes,\n    ...     model=\"claude-3-sonnet-20240229\"\n    ... )\n    >>> print(response.content)\n    >>> cost = provider.calculate_cost(response.tokens_used, model)",
          "bases": [
            "LLMProvider"
          ],
          "methods": [
            {
              "name": "__init__",
              "line": 85,
              "docstring": "Initialize the Anthropic provider with API credentials.\n\nArgs:\n    api_key: Anthropic API key. If not provided, attempts to load\n        from ANTHROPIC_API_KEY environment variable.\n    model_registry: ModelRegistry instance for pricing/capabilities.\n        If None, a default instance is created.\n    max_retries: Maximum retry attempts for rate limit errors.\n    suppress_format_warning: If True, suppress warnings about\n        response_format being ignored.\n\nRaises:\n    ValueError: If no API key is provided or found in environment.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "api_key",
                    "type": "Optional[str]"
                  },
                  {
                    "name": "model_registry",
                    "type": "Optional[ModelRegistry]"
                  },
                  {
                    "name": "max_retries",
                    "type": "int"
                  },
                  {
                    "name": "suppress_format_warning",
                    "type": "bool"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "client",
              "line": 120,
              "docstring": "Thread-safe lazy-loaded Anthropic API client.\n\nUses functools.cached_property for thread-safe initialization.\nCreates the client on first access to avoid initialization overhead.\n\nReturns:\n    Initialized Anthropic client instance.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "anthropic.Anthropic"
              },
              "method_type": "instance"
            },
            {
              "name": "_detect_image_format",
              "line": 131,
              "docstring": "Detect image MIME type from byte signature.\n\nArgs:\n    image_bytes: Raw image data.\n\nReturns:\n    MIME type string (e.g., 'image/png').\n\nRaises:\n    LLMImageError: If image format cannot be determined or is invalid.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "image_bytes",
                    "type": "bytes"
                  }
                ],
                "return_type": "str"
              },
              "method_type": "instance"
            },
            {
              "name": "_validate_image_constraints",
              "line": 168,
              "docstring": "Validate image size constraints before API call.\n\nArgs:\n    image_bytes: Raw image data.\n\nRaises:\n    LLMImageError: If image exceeds size limits.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "image_bytes",
                    "type": "bytes"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "_validate_model",
              "line": 185,
              "docstring": "Validate model against model registry.\n\nArgs:\n    model: Model identifier string.\n    requires_vision: If True, ensure model supports vision.\n\nRaises:\n    LLMModelError: If model is not supported or doesn't meet\n        requirements.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "model",
                    "type": "str"
                  },
                  {
                    "name": "requires_vision",
                    "type": "bool"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "_validate_parameters",
              "line": 210,
              "docstring": "Validate call parameters.\n\nArgs:\n    prompt: User prompt text.\n    max_tokens: Maximum tokens to generate.\n    temperature: Sampling temperature.\n\nRaises:\n    ValueError: If parameters are invalid.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "prompt",
                    "type": "str"
                  },
                  {
                    "name": "max_tokens",
                    "type": "int"
                  },
                  {
                    "name": "temperature",
                    "type": "float"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "_create_error_response",
              "line": 237,
              "docstring": "Create standardized error response.\n\nArgs:\n    model: Model identifier that failed.\n    error_message: Error description.\n\nReturns:\n    LLMResponse with success=False and zero tokens.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "model",
                    "type": "str"
                  },
                  {
                    "name": "error_message",
                    "type": "str"
                  }
                ],
                "return_type": "LLMResponse"
              },
              "method_type": "instance"
            },
            {
              "name": "call",
              "line": 260,
              "docstring": "Execute a synchronous call to the Anthropic API with retry logic.\n\nSupports both text-only and vision-enabled requests. Images are\nautomatically validated, format-detected, and base64-encoded.\nImplements exponential backoff for rate limit errors.\n\nArgs:\n    prompt: The user prompt/instruction text (non-empty).\n    image: Optional image data as raw bytes. Supported formats:\n        PNG, JPEG, WebP, GIF. Must be \u22645MB and \u22644096px per dimension.\n    model: Claude model identifier from ModelRegistry.\n    max_tokens: Maximum tokens in completion (1-4096).\n    temperature: Sampling temperature (0.0-1.0). Lower = deterministic.\n    response_format: Ignored with warning unless suppressed.\n\nReturns:\n    LLMResponse containing:\n        - content: Generated text response\n        - tokens_used: Input/output tokens and image count\n        - model_used: Actual model that processed the request\n        - provider: Always \"anthropic\"\n        - success: True if call succeeded\n        - error_message: None on success, details on failure\n\nRaises:\n    LLMAuthenticationError: Invalid API credentials.\n    LLMRateLimitError: Rate limit exceeded after retries.\n    LLMModelError: Invalid or unsupported model.\n    LLMImageError: Invalid image format or size.\n    LLMAPIError: Other API errors.\n    ValueError: Invalid parameters.\n\nNote:\n    For vision requests, Anthropic charges ~1,150 tokens per image.\n    This is included in the API's input_tokens count.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "prompt",
                    "type": "str"
                  },
                  {
                    "name": "image",
                    "type": "Optional[bytes]"
                  },
                  {
                    "name": "model",
                    "type": "str"
                  },
                  {
                    "name": "max_tokens",
                    "type": "int"
                  },
                  {
                    "name": "temperature",
                    "type": "float"
                  },
                  {
                    "name": "response_format",
                    "type": "Optional[Dict[str, Any]]"
                  }
                ],
                "return_type": "LLMResponse"
              },
              "method_type": "instance"
            },
            {
              "name": "calculate_cost",
              "line": 413,
              "docstring": "Calculate cost for a completed API call.\n\nArgs:\n    tokens_used: Token usage from LLMResponse.\n    model: Model identifier used for the call.\n\nReturns:\n    Cost in USD.\n\nRaises:\n    LLMModelError: If model not found in registry.\n\nExample:\n    >>> tokens = TokenUsage(\n    ...     input_tokens=1000,\n    ...     output_tokens=500,\n    ...     image_count=1\n    ... )\n    >>> cost = provider.calculate_cost(\n    ...     tokens, \"claude-3-sonnet-20240229\"\n    ... )\n    >>> print(f\"${cost:.4f}\")",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "tokens_used",
                    "type": "TokenUsage"
                  },
                  {
                    "name": "model",
                    "type": "str"
                  }
                ],
                "return_type": "float"
              },
              "method_type": "instance"
            },
            {
              "name": "get_available_models",
              "line": 452,
              "docstring": "Retrieve list of Anthropic models from registry.\n\nReturns:\n    List of model identifiers (canonical names and model IDs).",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "List[str]"
              },
              "method_type": "instance"
            },
            {
              "name": "validate_credentials",
              "line": 464,
              "docstring": "Test API key validity with a minimal API call.\n\nSends a minimal request to claude-3-haiku-20240307 to verify\nauthentication. Does not check quota limits.\n\nReturns:\n    True if credentials are valid and API is accessible.\n    False if authentication fails or API is unreachable.\n\nNote:\n    This method consumes ~10 tokens and counts toward rate limits.\n\nExample:\n    >>> provider = AnthropicProvider(api_key=\"sk-ant-...\")\n    >>> if provider.validate_credentials():\n    ...     print(\"Credentials valid\")\n    ... else:\n    ...     print(\"Authentication failed\")",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "bool"
              },
              "method_type": "instance"
            },
            {
              "name": "__repr__",
              "line": 496,
              "docstring": "Return string representation for debugging.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "str"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        }
      },
      "functions": []
    },
    "src.drawing_intelligence.llm.providers.base_provider": {
      "file_path": "C:\\00Projects\\engineering_items_attributes_enrichment\\src\\drawing_intelligence\\llm\\providers\\base_provider.py",
      "module_docstring": "Base provider interface for LLM integrations.\n\nThis module defines the abstract base class and data structures for integrating\nmultiple LLM providers (OpenAI, Anthropic, Google) with standardized interfaces.\nAll concrete provider implementations must inherit from LLMProvider and implement\nthe required abstract methods.\n\nClasses:\n    LLMProvider: Abstract base class for LLM providers.\n    LLMResponse: Standardized response container for LLM API calls.\n    TokenUsage: Token usage tracking for cost calculation.\n    ErrorDetails: Structured error information.\n    ModelInfo: Model capabilities and pricing information.\n\nExceptions:\n    LLMProviderError: Base exception for all LLM provider errors.\n    AuthenticationError: Invalid or expired credentials.\n    RateLimitError: Provider rate limit exceeded.\n    TimeoutError: Request timeout.\n    APIError: General API error.\n    ModelNotFoundError: Requested model not available.\n    InvalidInputError: Invalid input parameters.\n\nExample:\n    >>> class OpenAIProvider(LLMProvider):\n    ...     def call(self, prompt, image, model, max_tokens, temperature, response_format, timeout):\n    ...         # Implementation\n    ...         pass",
      "classes": {
        "LLMProviderError": {
          "line": 46,
          "docstring": "Base exception for all LLM provider errors.\n\nAttributes:\n    message: Human-readable error message.\n    provider: Provider name where error occurred.\n    model: Model identifier if applicable.\n    request_id: Optional request/trace ID for debugging.",
          "bases": [
            "Exception"
          ],
          "methods": [
            {
              "name": "__init__",
              "line": 56,
              "docstring": null,
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "message",
                    "type": "str"
                  },
                  {
                    "name": "provider",
                    "type": "Optional[str]"
                  },
                  {
                    "name": "model",
                    "type": "Optional[str]"
                  },
                  {
                    "name": "request_id",
                    "type": "Optional[str]"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        },
        "AuthenticationError": {
          "line": 70,
          "docstring": "Raised when API credentials are invalid or expired.",
          "bases": [
            "LLMProviderError"
          ],
          "methods": [],
          "nested_classes": []
        },
        "RateLimitError": {
          "line": 76,
          "docstring": "Raised when provider rate limit is exceeded.",
          "bases": [
            "LLMProviderError"
          ],
          "methods": [],
          "nested_classes": []
        },
        "TimeoutError": {
          "line": 82,
          "docstring": "Raised when request exceeds timeout threshold.",
          "bases": [
            "LLMProviderError"
          ],
          "methods": [],
          "nested_classes": []
        },
        "APIError": {
          "line": 88,
          "docstring": "Raised for general API errors.",
          "bases": [
            "LLMProviderError"
          ],
          "methods": [],
          "nested_classes": []
        },
        "ModelNotFoundError": {
          "line": 94,
          "docstring": "Raised when requested model is not available.",
          "bases": [
            "LLMProviderError"
          ],
          "methods": [],
          "nested_classes": []
        },
        "InvalidInputError": {
          "line": 100,
          "docstring": "Raised when input parameters are invalid.",
          "bases": [
            "LLMProviderError"
          ],
          "methods": [],
          "nested_classes": []
        },
        "TokenUsage": {
          "line": 112,
          "docstring": "Token usage tracking for LLM API calls.\n\nTracks input/output tokens and image count for cost calculation and budget monitoring.\nAll token counts must be non-negative integers. Immutable for data integrity.\n\nAttributes:\n    input_tokens: Number of tokens in the prompt/context sent to the LLM.\n    output_tokens: Number of tokens generated by the LLM in the response.\n    image_count: Number of images included in the request (for vision models).\n        Defaults to 0 for text-only requests.\n\nRaises:\n    ValueError: If any token count is negative.\n\nExample:\n    >>> usage = TokenUsage(input_tokens=500, output_tokens=150, image_count=2)\n    >>> total_tokens = usage.input_tokens + usage.output_tokens",
          "bases": [],
          "methods": [
            {
              "name": "__post_init__",
              "line": 136,
              "docstring": "Validate token counts are non-negative.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "to_dict",
              "line": 151,
              "docstring": "Convert to dictionary for serialization.\n\nReturns:\n    dict[str, int]: Dictionary representation.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "dict[str, int]"
              },
              "method_type": "instance"
            },
            {
              "name": "from_dict",
              "line": 164,
              "docstring": "Create TokenUsage from dictionary.\n\nArgs:\n    data: Dictionary with token counts.\n\nReturns:\n    TokenUsage: New instance.",
              "signature": {
                "parameters": [
                  {
                    "name": "cls"
                  },
                  {
                    "name": "data",
                    "type": "dict[str, int]"
                  }
                ],
                "return_type": "TokenUsage"
              },
              "method_type": "class"
            }
          ],
          "nested_classes": []
        },
        "ErrorDetails": {
          "line": 181,
          "docstring": "Structured error information for failed LLM calls.\n\nAttributes:\n    error_code: Machine-readable error code (e.g., 'rate_limit', 'invalid_key').\n    message: Human-readable error message.\n    details: Additional provider-specific error information.",
          "bases": [],
          "methods": [
            {
              "name": "to_dict",
              "line": 194,
              "docstring": "Convert to dictionary for serialization.\n\nReturns:\n    dict[str, Any]: Dictionary representation.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "dict[str, Any]"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        },
        "LLMResponse": {
          "line": 208,
          "docstring": "Standardized LLM response container.\n\nEncapsulates the response from any LLM provider with metadata for tracking,\ndebugging, and cost calculation. The `success` flag gates downstream processing.\nImmutable for data integrity.\n\nAttributes:\n    content: The generated text response from the LLM. Empty string if call failed.\n    tokens_used: Token usage breakdown (input/output/images) for cost tracking.\n    model_used: Exact model identifier used (may differ from requested if fallback occurred).\n    provider: Provider name (e.g., 'openai', 'anthropic', 'google').\n    success: True if API call completed successfully, False otherwise.\n    cost_usd: Cost in USD for this API call.\n    latency_ms: API response time in milliseconds.\n    request_id: Optional request/trace ID for debugging.\n    error_details: Structured error information if success=False, None otherwise.\n    metadata: Additional provider-specific metadata (e.g., finish_reason).\n\nExample:\n    >>> response = LLMResponse(\n    ...     content=\"Extracted: Part #12345\",\n    ...     tokens_used=TokenUsage(input_tokens=150, output_tokens=20),\n    ...     model_used=\"gpt-4o-mini\",\n    ...     provider=\"openai\",\n    ...     success=True,\n    ...     cost_usd=0.0025,\n    ...     latency_ms=234.5\n    ... )",
          "bases": [],
          "methods": [
            {
              "name": "to_dict",
              "line": 250,
              "docstring": "Convert to dictionary for serialization.\n\nReturns:\n    dict[str, Any]: Dictionary representation.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "dict[str, Any]"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        },
        "ModelInfo": {
          "line": 273,
          "docstring": "Model capabilities and pricing information.\n\nAttributes:\n    name: Model identifier (e.g., 'gpt-4o', 'claude-3-opus-20240229').\n    supports_vision: Whether model supports image inputs.\n    max_input_tokens: Maximum input context window size.\n    max_output_tokens: Maximum output tokens per request.\n    input_cost_per_1m: Cost per 1M input tokens in USD.\n    output_cost_per_1m: Cost per 1M output tokens in USD.\n    image_cost: Optional cost per image in USD.",
          "bases": [],
          "methods": [],
          "nested_classes": []
        },
        "LLMProvider": {
          "line": 300,
          "docstring": "Abstract base class for LLM provider implementations.\n\nDefines the contract that all concrete LLM providers (OpenAI, Anthropic, Google)\nmust implement. Ensures consistent interface for API calls, credential validation,\nand model availability checks across all providers.\n\nConcrete implementations must handle:\n- API authentication and credential management\n- Request/response serialization\n- Provider-specific error handling and retries\n- Rate limiting and timeout handling\n- Input validation and sanitization\n\nExample:\n    >>> class CustomProvider(LLMProvider):\n    ...     def call(self, prompt, image, model, max_tokens, temperature, response_format, timeout):\n    ...         # Custom implementation\n    ...         return LLMResponse(...)\n    ...\n    ...     def get_available_models(self):\n    ...         return [ModelInfo(...), ...]\n    ...\n    ...     def validate_credentials(self):\n    ...         return self._check_api_key()",
          "bases": [
            "ABC"
          ],
          "methods": [
            {
              "name": "call",
              "line": 328,
              "docstring": "Make API call to the LLM provider.\n\nExecutes a single API request with the given parameters. Implementations must\nhandle authentication, request formatting, response parsing, and error handling.\n\nArgs:\n    prompt: The text prompt to send to the LLM. Must not be empty or whitespace.\n    image: Optional image for vision models. Can be:\n        - bytes: Raw image data (PNG/JPEG)\n        - Path: File path to image\n        - str: URL or file path string\n        None for text-only requests.\n    model: Model identifier string (e.g., 'gpt-4o', 'claude-3-opus-20240229').\n        Must be a valid model for this provider.\n    max_tokens: Maximum number of tokens to generate in the response.\n        Must be positive and within provider's model limits.\n    temperature: Sampling temperature (0.0 = deterministic, higher = creative).\n        Valid range depends on provider (typically [0.0, 2.0]).\n    response_format: Optional response format specification. Provider-specific\n        structure (e.g., {\"type\": \"json_object\"} for OpenAI JSON mode).\n    timeout: Request timeout in seconds. Defaults to 30.0 seconds.\n\nReturns:\n    LLMResponse: Standardized response with content, token usage, cost, and metadata.\n        Returns success=False with error_details if API call fails.\n\nRaises:\n    InvalidInputError: If parameters are invalid (empty prompt, negative max_tokens, etc.).\n    AuthenticationError: If API credentials are invalid or expired.\n    RateLimitError: If provider rate limit is exceeded.\n    TimeoutError: If request exceeds timeout threshold.\n    ModelNotFoundError: If requested model is not available.\n    APIError: For other provider-specific API errors.\n\nExample:\n    >>> provider = OpenAIProvider(api_key=\"sk-...\")\n    >>> response = provider.call(\n    ...     prompt=\"Extract part number from this drawing\",\n    ...     image=Path(\"drawing.png\"),\n    ...     model=\"gpt-4o\",\n    ...     max_tokens=500,\n    ...     temperature=0.0,\n    ...     timeout=60.0\n    ... )\n    >>> if response.success:\n    ...     print(f\"Cost: ${response.cost_usd:.4f}\")\n    ...     print(response.content)",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "prompt",
                    "type": "str"
                  },
                  {
                    "name": "image",
                    "type": "Optional[Union[bytes, Path, str]]"
                  },
                  {
                    "name": "model",
                    "type": "str"
                  },
                  {
                    "name": "max_tokens",
                    "type": "int"
                  },
                  {
                    "name": "temperature",
                    "type": "float"
                  },
                  {
                    "name": "response_format",
                    "type": "Optional[dict[str, Any]]"
                  },
                  {
                    "name": "timeout",
                    "type": "float"
                  }
                ],
                "return_type": "LLMResponse"
              },
              "method_type": "instance"
            },
            {
              "name": "get_available_models",
              "line": 389,
              "docstring": "Get list of available models with capabilities and pricing.\n\nReturns model information including vision support, token limits, and pricing.\nUsed for validation, dynamic model selection, and cost estimation.\n\nReturns:\n    list[ModelInfo]: List of model information objects supported by this provider.\n        Empty list if no models are available or credentials are invalid.\n\nExample:\n    >>> provider = OpenAIProvider(api_key=\"sk-...\")\n    >>> models = provider.get_available_models()\n    >>> vision_models = [m for m in models if m.supports_vision]\n    >>> print(f\"Vision models: {[m.name for m in vision_models]}\")",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "list[ModelInfo]"
              },
              "method_type": "instance"
            },
            {
              "name": "validate_credentials",
              "line": 408,
              "docstring": "Validate API credentials for this provider.\n\nChecks if the configured API key/credentials are valid by making a lightweight\nAPI call. Should be called during initialization to fail fast if credentials\nare invalid. Returns False on failure rather than raising exceptions.\n\nReturns:\n    bool: True if credentials are valid and API is accessible, False otherwise.\n\nExample:\n    >>> provider = AnthropicProvider(api_key=\"sk-ant-...\")\n    >>> if not provider.validate_credentials():\n    ...     raise ConfigurationError(\"Invalid Anthropic API key\")",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "bool"
              },
              "method_type": "instance"
            },
            {
              "name": "calculate_cost",
              "line": 426,
              "docstring": "Calculate cost for API call based on token usage.\n\nImplements provider-specific pricing logic. Costs vary by model tier\nand whether images are included in the request.\n\nArgs:\n    tokens_used: Token usage breakdown from the API call.\n    model: Model identifier used for the call.\n\nReturns:\n    float: Cost in USD for this API call.\n\nRaises:\n    ModelNotFoundError: If model is not recognized by this provider.\n\nExample:\n    >>> provider = OpenAIProvider(api_key=\"sk-...\")\n    >>> usage = TokenUsage(input_tokens=1000, output_tokens=500, image_count=1)\n    >>> cost = provider.calculate_cost(usage, \"gpt-4o\")\n    >>> print(f\"Cost: ${cost:.4f}\")",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "tokens_used",
                    "type": "TokenUsage"
                  },
                  {
                    "name": "model",
                    "type": "str"
                  }
                ],
                "return_type": "float"
              },
              "method_type": "instance"
            },
            {
              "name": "get_provider_name",
              "line": 450,
              "docstring": "Get the name of this provider.\n\nReturns:\n    str: Provider name (e.g., 'openai', 'anthropic', 'google').",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "str"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        }
      },
      "functions": []
    },
    "src.drawing_intelligence.llm.providers.google_provider": {
      "file_path": "C:\\00Projects\\engineering_items_attributes_enrichment\\src\\drawing_intelligence\\llm\\providers\\google_provider.py",
      "module_docstring": "Google AI (Gemini) LLM provider implementation for text and vision models.\n\nThis module implements the BaseLLMProvider interface for Google's Gemini models,\nincluding Gemini 1.5 Pro, Flash, and legacy Pro/Pro Vision variants. Supports both\ntext-only and image-based completions with configurable parameters.\n\nFeatures:\n    - Automatic retry with exponential backoff for transient errors\n    - Multi-image support for batch vision analysis\n    - Accurate cost estimation with native token counting\n    - Secure API key handling with Vertex AI support\n    - Comprehensive error handling with custom exceptions\n    - PIL-based image validation with dimension checking\n    - Configurable retry and budget controls\n    - Structured logging with request tracing\n\nExample:\n    >>> provider = GoogleProvider(\n    ...     api_key=\"AIza...\",\n    ...     timeout=60.0,\n    ...     max_retries=3,\n    ...     budget_limit_usd=10.0\n    ... )\n    >>> response = provider.call(\n    ...     prompt=\"Extract dimensions from this drawing\",\n    ...     images=[image_bytes],\n    ...     model=\"gemini-1.5-pro\",\n    ...     max_tokens=1000,\n    ...     temperature=0.0\n    ... )\n    >>> print(f\"Cost: ${response.estimated_cost_usd:.4f}\")\n\nModel Pricing (per 1M tokens):\n    - gemini-1.5-pro: $1.25 input / $5.00 output (2M context)\n    - gemini-1.5-flash: $0.075 input / $0.30 output (1M context)\n    - gemini-pro: $0.50 input / $1.50 output (32K context)\n\nNote:\n    Requires 'google-generativeai' package: pip install google-generativeai\n\nExceptions:\n    GoogleProviderError: Base exception for all provider errors.\n    InvalidModelError: Unsupported model requested.\n    InvalidParameterError: Invalid API parameters.\n    RateLimitError: API rate limit exceeded.\n    QuotaExceededError: API quota exhausted.\n    AuthenticationError: Authentication failure.\n    ImageValidationError: Image validation failure.\n    BudgetExceededError: Cost exceeds budget limit.\n    UnsupportedFeatureError: Unsupported feature requested.",
      "classes": {
        "GoogleProviderError": {
          "line": 79,
          "docstring": "Base exception for Google provider errors.",
          "bases": [
            "Exception"
          ],
          "methods": [],
          "nested_classes": []
        },
        "InvalidModelError": {
          "line": 85,
          "docstring": "Raised when an unsupported model is requested.",
          "bases": [
            "GoogleProviderError"
          ],
          "methods": [],
          "nested_classes": []
        },
        "InvalidParameterError": {
          "line": 91,
          "docstring": "Raised when invalid parameters are provided.",
          "bases": [
            "GoogleProviderError"
          ],
          "methods": [],
          "nested_classes": []
        },
        "RateLimitError": {
          "line": 97,
          "docstring": "Raised when API rate limit is exceeded.",
          "bases": [
            "GoogleProviderError"
          ],
          "methods": [],
          "nested_classes": []
        },
        "QuotaExceededError": {
          "line": 103,
          "docstring": "Raised when API quota is exceeded.",
          "bases": [
            "GoogleProviderError"
          ],
          "methods": [],
          "nested_classes": []
        },
        "AuthenticationError": {
          "line": 109,
          "docstring": "Raised when API authentication fails.",
          "bases": [
            "GoogleProviderError"
          ],
          "methods": [],
          "nested_classes": []
        },
        "ImageValidationError": {
          "line": 115,
          "docstring": "Raised when image validation fails.",
          "bases": [
            "GoogleProviderError"
          ],
          "methods": [],
          "nested_classes": []
        },
        "BudgetExceededError": {
          "line": 121,
          "docstring": "Raised when estimated cost exceeds budget limit.",
          "bases": [
            "GoogleProviderError"
          ],
          "methods": [],
          "nested_classes": []
        },
        "UnsupportedFeatureError": {
          "line": 127,
          "docstring": "Raised when an unsupported feature is requested.",
          "bases": [
            "GoogleProviderError"
          ],
          "methods": [],
          "nested_classes": []
        },
        "GeminiModel": {
          "line": 138,
          "docstring": "Supported Gemini model identifiers.",
          "bases": [
            "str",
            "Enum"
          ],
          "methods": [],
          "nested_classes": []
        },
        "ModelInfo": {
          "line": 150,
          "docstring": "Model metadata including pricing and capabilities.",
          "bases": [],
          "methods": [],
          "nested_classes": []
        },
        "GoogleProvider": {
          "line": 219,
          "docstring": "Google AI (Gemini) API provider for LLM text and vision completions.\n\nImplements the BaseLLMProvider interface with support for Gemini model family.\nHandles lazy client initialization, credential validation, and both text-only\nand vision-enabled requests with automatic retry logic.\n\nAttributes:\n    api_key: Google AI API authentication key.\n    timeout: Request timeout in seconds.\n    max_retries: Maximum retry attempts for transient errors.\n    budget_limit_usd: Maximum allowed cost per call (None = unlimited).\n    base_delay: Base delay for exponential backoff (seconds).\n    max_delay: Maximum delay for exponential backoff (seconds).\n    use_vertex_ai: Whether to use Vertex AI endpoint.\n    project_id: GCP project ID (required for Vertex AI).\n    location: GCP location (required for Vertex AI).\n\nSupported Models:\n    - gemini-1.5-pro: Latest multimodal model (2M context)\n    - gemini-1.5-flash: Fast multimodal model (1M context)\n    - gemini-pro: Baseline text model (32K context)\n    - gemini-pro-vision: Legacy vision model (16K context)",
          "bases": [
            "BaseLLMProvider"
          ],
          "methods": [
            {
              "name": "__init__",
              "line": 250,
              "docstring": "Initialize Google AI provider with credentials and configuration.\n\nArgs:\n    api_key: Google AI API key (format: 'AIza...') or service account JSON.\n    timeout: Request timeout in seconds (default: 60.0).\n    max_retries: Maximum retry attempts for transient errors (default: 3).\n    budget_limit_usd: Maximum cost per call in USD (None = unlimited).\n    base_delay: Base delay for exponential backoff (default: 1.0s).\n    max_delay: Maximum backoff delay (default: 30.0s).\n    use_vertex_ai: Use Vertex AI endpoint instead of AI Studio (default: False).\n    project_id: GCP project ID (required if use_vertex_ai=True).\n    location: GCP location (required if use_vertex_ai=True, e.g. 'us-central1').\n\nRaises:\n    ValueError: If api_key is empty or Vertex AI config is incomplete.\n\nExample:\n    >>> # Standard AI Studio usage\n    >>> provider = GoogleProvider(api_key=\"AIza...\")\n    >>>\n    >>> # With budget control\n    >>> provider = GoogleProvider(\n    ...     api_key=\"AIza...\",\n    ...     budget_limit_usd=5.0,\n    ...     max_retries=5\n    ... )\n    >>>\n    >>> # Vertex AI usage\n    >>> provider = GoogleProvider(\n    ...     api_key=\"path/to/service-account.json\",\n    ...     use_vertex_ai=True,\n    ...     project_id=\"my-project\",\n    ...     location=\"us-central1\"\n    ... )",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "api_key",
                    "type": "str"
                  },
                  {
                    "name": "timeout",
                    "type": "float"
                  },
                  {
                    "name": "max_retries",
                    "type": "int"
                  },
                  {
                    "name": "budget_limit_usd",
                    "type": "Optional[float]"
                  },
                  {
                    "name": "base_delay",
                    "type": "float"
                  },
                  {
                    "name": "max_delay",
                    "type": "float"
                  },
                  {
                    "name": "use_vertex_ai",
                    "type": "bool"
                  },
                  {
                    "name": "project_id",
                    "type": "Optional[str]"
                  },
                  {
                    "name": "location",
                    "type": "Optional[str]"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "_get_genai",
              "line": 328,
              "docstring": "Lazy initialization of Google GenerativeAI module.\n\nCreates the genai module on first call to avoid initialization overhead\nwhen provider is instantiated but not used.\n\nReturns:\n    google.generativeai module instance.\n\nRaises:\n    ImportError: If google-generativeai package is not installed.\n\nNote:\n    Module is cached after first initialization. Subsequent calls return\n    the same instance.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "types.ModuleType"
              },
              "method_type": "instance"
            },
            {
              "name": "get_model_info",
              "line": 383,
              "docstring": "Get metadata for a specific model.\n\nArgs:\n    model: Model identifier.\n\nReturns:\n    ModelInfo with pricing, context limits, and capabilities.\n\nRaises:\n    InvalidModelError: If model is not in registry.\n\nExample:\n    >>> info = provider.get_model_info(\"gemini-1.5-pro\")\n    >>> print(f\"Context: {info.context_limit}, Vision: {info.supports_vision}\")",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "model",
                    "type": "str"
                  }
                ],
                "return_type": "ModelInfo"
              },
              "method_type": "instance"
            },
            {
              "name": "call",
              "line": 406,
              "docstring": "Execute Google AI API completion request with retry logic.\n\nSupports both text-only and vision-enabled completions. Automatically\nconstructs appropriate message format based on presence of image data.\nImplements exponential backoff for transient errors.\n\nArgs:\n    prompt: User prompt text. For vision requests, describes what\n        to extract or analyze from images.\n    image: Optional single image bytes (deprecated, use images instead).\n    model: Gemini model identifier (default: 'gemini-1.5-pro').\n    max_tokens: Maximum tokens in response (1-8192 typical range).\n    temperature: Sampling temperature (0.0=deterministic, 2.0=creative).\n    response_format: Optional format specification. Use {\"type\": \"json_object\"}\n        to force JSON output (only supported on newer models).\n    seed: Optional integer for deterministic sampling (not supported).\n    stream: If True, returns streaming response (not yet implemented).\n    images: Optional list of image bytes (JPEG/PNG/WebP/GIF).\n    safety_settings: Optional content filtering settings.\n    top_p: Optional nucleus sampling parameter (0.0-1.0).\n    top_k: Optional top-k sampling parameter (1-40).\n\nReturns:\n    LLMResponse: Structured response containing content, tokens, cost, etc.\n\nRaises:\n    InvalidModelError: If model is not supported.\n    InvalidParameterError: If parameters are out of valid range.\n    ImageValidationError: If image validation fails.\n    BudgetExceededError: If estimated cost exceeds budget limit.\n    UnsupportedFeatureError: If streaming is requested.\n    RateLimitError: If API rate limit is exceeded.\n    QuotaExceededError: If API quota is exceeded.\n    AuthenticationError: If API authentication fails.\n\nExample:\n    >>> response = provider.call(\n    ...     prompt=\"Extract part number from this drawing\",\n    ...     images=[pdf_page_bytes],\n    ...     model=\"gemini-1.5-pro\",\n    ...     max_tokens=500,\n    ...     temperature=0.0,\n    ...     safety_settings={\"HARM_CATEGORY_DANGEROUS_CONTENT\": \"BLOCK_NONE\"}\n    ... )\n    >>> print(f\"Cost: ${response.estimated_cost_usd:.4f}\")",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "prompt",
                    "type": "str"
                  },
                  {
                    "name": "image",
                    "type": "Optional[bytes]"
                  },
                  {
                    "name": "model",
                    "type": "str"
                  },
                  {
                    "name": "max_tokens",
                    "type": "int"
                  },
                  {
                    "name": "temperature",
                    "type": "float"
                  },
                  {
                    "name": "response_format",
                    "type": "Optional[Dict[str, Any]]"
                  },
                  {
                    "name": "seed",
                    "type": "Optional[int]"
                  },
                  {
                    "name": "stream",
                    "type": "bool"
                  },
                  {
                    "name": "images",
                    "type": "Optional[List[bytes]]"
                  },
                  {
                    "name": "safety_settings",
                    "type": "Optional[Dict[str, Any]]"
                  },
                  {
                    "name": "top_p",
                    "type": "Optional[float]"
                  },
                  {
                    "name": "top_k",
                    "type": "Optional[int]"
                  }
                ],
                "return_type": "LLMResponse"
              },
              "method_type": "instance"
            },
            {
              "name": "_build_content",
              "line": 708,
              "docstring": "Build Gemini API content format.\n\nArgs:\n    prompt: User prompt text.\n    images: List of image bytes (empty for text-only).\n\nReturns:\n    String for text-only requests, or list of content parts for vision requests.\n\nRaises:\n    ImageValidationError: If PIL image conversion fails.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "prompt",
                    "type": "str"
                  },
                  {
                    "name": "images",
                    "type": "List[bytes]"
                  }
                ],
                "return_type": "Union[str, List[Union[str, Image.Image]]]"
              },
              "method_type": "instance"
            },
            {
              "name": "_validate_parameters",
              "line": 742,
              "docstring": "Validate API call parameters.\n\nArgs:\n    model_info: Model metadata.\n    max_tokens: Maximum response tokens.\n    temperature: Sampling temperature.\n    top_p: Nucleus sampling parameter.\n    top_k: Top-k sampling parameter.\n\nRaises:\n    InvalidParameterError: If parameters are out of valid range.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "model_info",
                    "type": "ModelInfo"
                  },
                  {
                    "name": "max_tokens",
                    "type": "int"
                  },
                  {
                    "name": "temperature",
                    "type": "float"
                  },
                  {
                    "name": "top_p",
                    "type": "Optional[float]"
                  },
                  {
                    "name": "top_k",
                    "type": "Optional[int]"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "_validate_image",
              "line": 782,
              "docstring": "Validate image data before sending to API.\n\nArgs:\n    image_bytes: Raw image data.\n    index: Image index for error messages.\n\nRaises:\n    ImageValidationError: If image validation fails.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "image_bytes",
                    "type": "bytes"
                  },
                  {
                    "name": "index",
                    "type": "int"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "_estimate_input_tokens",
              "line": 832,
              "docstring": "Estimate input token count using Google's native counter.\n\nArgs:\n    genai: Google GenerativeAI module.\n    model: Model identifier.\n    prompt: Input prompt text.\n\nReturns:\n    Estimated input token count.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "genai",
                    "type": "types.ModuleType"
                  },
                  {
                    "name": "model",
                    "type": "str"
                  },
                  {
                    "name": "prompt",
                    "type": "str"
                  }
                ],
                "return_type": "int"
              },
              "method_type": "instance"
            },
            {
              "name": "_estimate_tokens",
              "line": 854,
              "docstring": "Estimate token count for text (fallback method).\n\nArgs:\n    text: Text to estimate tokens for.\n\nReturns:\n    Estimated token count.\n\nNote:\n    Uses rough approximation: words * 4/3.\n    For accurate counts, use _estimate_input_tokens.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "text",
                    "type": "str"
                  }
                ],
                "return_type": "int"
              },
              "method_type": "instance"
            },
            {
              "name": "_calculate_cost",
              "line": 871,
              "docstring": "Calculate API call cost in USD.\n\nArgs:\n    model_info: Model metadata with pricing.\n    tokens: Token usage breakdown.\n\nReturns:\n    Cost in USD.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "model_info",
                    "type": "ModelInfo"
                  },
                  {
                    "name": "tokens",
                    "type": "TokenUsage"
                  }
                ],
                "return_type": "float"
              },
              "method_type": "instance"
            },
            {
              "name": "_is_rate_limit_error",
              "line": 888,
              "docstring": "Check if error is a rate limit error.\n\nArgs:\n    error: Exception to check.\n\nReturns:\n    True if error indicates rate limiting.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "error",
                    "type": "Exception"
                  }
                ],
                "return_type": "bool"
              },
              "method_type": "instance"
            },
            {
              "name": "_is_quota_error",
              "line": 904,
              "docstring": "Check if error is a quota exceeded error.\n\nArgs:\n    error: Exception to check.\n\nReturns:\n    True if error indicates quota exhaustion.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "error",
                    "type": "Exception"
                  }
                ],
                "return_type": "bool"
              },
              "method_type": "instance"
            },
            {
              "name": "_is_auth_error",
              "line": 917,
              "docstring": "Check if error is an authentication error.\n\nArgs:\n    error: Exception to check.\n\nReturns:\n    True if error indicates authentication failure.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "error",
                    "type": "Exception"
                  }
                ],
                "return_type": "bool"
              },
              "method_type": "instance"
            },
            {
              "name": "_is_retryable_error",
              "line": 933,
              "docstring": "Determine if an error is retryable.\n\nArgs:\n    error: Exception raised during API call.\n\nReturns:\n    True if error is transient and should be retried.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "error",
                    "type": "Exception"
                  }
                ],
                "return_type": "bool"
              },
              "method_type": "instance"
            },
            {
              "name": "_calculate_backoff_delay",
              "line": 977,
              "docstring": "Calculate exponential backoff delay.\n\nArgs:\n    attempt: Current attempt number (0-indexed).\n\nReturns:\n    Delay in seconds (capped at max_delay).",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "attempt",
                    "type": "int"
                  }
                ],
                "return_type": "float"
              },
              "method_type": "instance"
            },
            {
              "name": "get_available_models",
              "line": 992,
              "docstring": "Get list of supported Gemini model identifiers.\n\nReturns:\n    Model IDs that can be passed to call() method.\n    Ordered from most to least capable.\n\nNote:\n    This is a static list. Google's model availability may change.\n    Use validate_credentials() to test specific model access.\n\nExample:\n    >>> models = provider.get_available_models()\n    >>> print(models[0])  # Most capable model\n    'gemini-1.5-pro'",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "List[str]"
              },
              "method_type": "instance"
            },
            {
              "name": "validate_credentials",
              "line": 1011,
              "docstring": "Test Google AI API credentials with minimal request.\n\nMakes a lightweight API call to verify that the api_key is valid and\nhas access to at least one model. Uses gemini-1.5-flash with minimal\ntoken limit to minimize cost (<$0.001 per validation).\n\nReturns:\n    True if credentials are valid and API is accessible,\n    False otherwise.\n\nNote:\n    - This method makes a real API call and incurs minimal cost\n    - Network errors or service outages will return False\n    - Successful validation does not guarantee access to all models\n\nExample:\n    >>> provider = GoogleProvider(api_key=\"AIza...\")\n    >>> if provider.validate_credentials():\n    ...     print(\"Ready to process drawings\")\n    ... else:\n    ...     print(\"Invalid API key or Google AI service unavailable\")",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "bool"
              },
              "method_type": "instance"
            },
            {
              "name": "close",
              "line": 1047,
              "docstring": "Close the Google AI client and cleanup resources.\n\nCall this method when the provider is no longer needed to release\nresources.\n\nExample:\n    >>> provider = GoogleProvider(api_key=\"AIza...\")\n    >>> try:\n    ...     response = provider.call(...)\n    ... finally:\n    ...     provider.close()",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "__enter__",
              "line": 1070,
              "docstring": "Context manager entry.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "'GoogleProvider'"
              },
              "method_type": "instance"
            },
            {
              "name": "__exit__",
              "line": 1074,
              "docstring": "Context manager exit.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "exc_type",
                    "type": "Any"
                  },
                  {
                    "name": "exc_val",
                    "type": "Any"
                  },
                  {
                    "name": "exc_tb",
                    "type": "Any"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        }
      },
      "functions": []
    },
    "src.drawing_intelligence.llm.providers.openai_provider": {
      "file_path": "C:\\00Projects\\engineering_items_attributes_enrichment\\src\\drawing_intelligence\\llm\\providers\\openai_provider.py",
      "module_docstring": "OpenAI LLM provider implementation for text and vision models.\n\nThis module implements the BaseLLMProvider interface for OpenAI's GPT models,\nincluding GPT-4, GPT-4 Turbo, and GPT-4 Vision variants. Supports both text-only\nand image-based completions with configurable parameters.\n\nFeatures:\n    - Automatic retry with exponential backoff for transient errors\n    - Vision model validation and multi-image support\n    - Cost estimation and budget warnings\n    - Secure API key handling with format validation\n    - Streaming response support\n    - Comprehensive error handling with custom exceptions\n\nExample:\n    >>> provider = OpenAIProvider(\n    ...     api_key=\"sk-proj-...\",\n    ...     timeout=60.0,\n    ...     max_retries=3\n    ... )\n    >>> response = provider.call(\n    ...     prompt=\"Describe this drawing\",\n    ...     image=image_bytes,\n    ...     model=\"gpt-4o\",\n    ...     max_tokens=500,\n    ...     temperature=0.0\n    ... )\n    >>> print(f\"Cost: ${response.estimated_cost_usd:.4f}\")\n\nModel Pricing (per 1M tokens):\n    - gpt-4o: $2.50 input / $10.00 output\n    - gpt-4-turbo: $10.00 input / $30.00 output\n    - gpt-3.5-turbo: $0.50 input / $1.50 output\n\nNote:\n    Requires 'openai' package: pip install openai>=1.0.0",
      "classes": {
        "OpenAIProviderError": {
          "line": 60,
          "docstring": "Base exception for OpenAI provider errors.",
          "bases": [
            "Exception"
          ],
          "methods": [],
          "nested_classes": []
        },
        "InvalidModelError": {
          "line": 66,
          "docstring": "Raised when an unsupported model is requested.",
          "bases": [
            "OpenAIProviderError"
          ],
          "methods": [],
          "nested_classes": []
        },
        "InvalidParameterError": {
          "line": 72,
          "docstring": "Raised when invalid parameters are provided.",
          "bases": [
            "OpenAIProviderError"
          ],
          "methods": [],
          "nested_classes": []
        },
        "RateLimitError": {
          "line": 78,
          "docstring": "Raised when API rate limit is exceeded.",
          "bases": [
            "OpenAIProviderError"
          ],
          "methods": [],
          "nested_classes": []
        },
        "AuthenticationError": {
          "line": 84,
          "docstring": "Raised when API authentication fails.",
          "bases": [
            "OpenAIProviderError"
          ],
          "methods": [],
          "nested_classes": []
        },
        "ImageValidationError": {
          "line": 90,
          "docstring": "Raised when image validation fails.",
          "bases": [
            "OpenAIProviderError"
          ],
          "methods": [],
          "nested_classes": []
        },
        "OpenAIProvider": {
          "line": 101,
          "docstring": "OpenAI API provider for LLM text and vision completions.\n\nImplements the BaseLLMProvider interface with support for GPT-4 family models.\nHandles lazy client initialization, credential validation, and both text-only\nand vision-enabled requests with automatic retry logic.\n\nAttributes:\n    api_key: OpenAI API authentication key.\n    base_url: Optional custom API endpoint URL.\n    timeout: Request timeout in seconds.\n    max_retries: Maximum retry attempts for transient errors.\n    organization: Optional organization ID for billing/tracking.\n    http_client: Optional custom HTTP client configuration.\n\nSupported Models:\n    - gpt-4o: Latest multimodal model (128K context)\n    - gpt-4-turbo-2024-04-09: Fast GPT-4 variant (128K context)\n    - gpt-4-vision-preview: Vision-enabled GPT-4 (128K context)\n    - gpt-4o-mini: Cost-effective multimodal (128K context)\n    - gpt-3.5-turbo: Baseline text model (16K context)\n\nModel Pricing (per 1M tokens):\n    - gpt-4o: $2.50 input / $10.00 output\n    - gpt-4-turbo: $10.00 input / $30.00 output\n    - gpt-4o-mini: $0.15 input / $0.60 output\n    - gpt-3.5-turbo: $0.50 input / $1.50 output",
          "bases": [
            "BaseLLMProvider"
          ],
          "methods": [
            {
              "name": "__init__",
              "line": 160,
              "docstring": "Initialize OpenAI provider with credentials and configuration.\n\nArgs:\n    api_key: OpenAI API key (format: 'sk-...' or 'sk-proj-...').\n    base_url: Optional custom base URL for Azure OpenAI or proxies.\n    timeout: Request timeout in seconds (default: 60.0).\n    max_retries: Maximum retry attempts for transient errors (default: 3).\n    organization: Optional organization ID for billing tracking.\n    http_client: Optional custom httpx.Client for advanced proxy/TLS config.\n\nRaises:\n    ValueError: If api_key is empty or has invalid format.\n\nExample:\n    >>> # Basic initialization\n    >>> provider = OpenAIProvider(api_key=\"sk-proj-...\")\n    >>>\n    >>> # With organization and custom timeout\n    >>> provider = OpenAIProvider(\n    ...     api_key=\"sk-proj-...\",\n    ...     organization=\"org-123\",\n    ...     timeout=120.0,\n    ...     max_retries=5\n    ... )",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "api_key",
                    "type": "str"
                  },
                  {
                    "name": "base_url",
                    "type": "Optional[str]"
                  },
                  {
                    "name": "timeout",
                    "type": "float"
                  },
                  {
                    "name": "max_retries",
                    "type": "int"
                  },
                  {
                    "name": "organization",
                    "type": "Optional[str]"
                  },
                  {
                    "name": "http_client",
                    "type": "Optional[Any]"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "_get_client",
              "line": 216,
              "docstring": "Lazy initialization of OpenAI client.\n\nCreates the OpenAI client on first call to avoid initialization overhead\nwhen provider is instantiated but not used.\n\nReturns:\n    OpenAI: Configured OpenAI client instance.\n\nRaises:\n    ImportError: If openai package is not installed.\n\nNote:\n    Client is cached after first initialization. Subsequent calls return\n    the same instance.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "'OpenAI'"
              },
              "method_type": "instance"
            },
            {
              "name": "call",
              "line": 264,
              "docstring": "Execute OpenAI API completion request with retry logic.\n\nSupports both text-only and vision-enabled completions. Automatically\nconstructs appropriate message format based on presence of image data.\nImplements exponential backoff for transient errors.\n\nArgs:\n    prompt: User prompt text. For vision requests, describes what\n        to extract or analyze from images.\n    image: Optional single image bytes (JPEG/PNG/WebP/GIF).\n    model: OpenAI model identifier (default: 'gpt-4o').\n    max_tokens: Maximum tokens in response (1-4096 typical range).\n    temperature: Sampling temperature (0.0=deterministic, 1.0=creative).\n    response_format: Optional format specification. Use {\"type\": \"json_object\"}\n        to force JSON output.\n    seed: Optional integer for deterministic sampling (beta feature).\n    stream: If True, returns streaming response (not yet implemented).\n    images: Optional list of multiple images (alternative to single image).\n\nReturns:\n    LLMResponse: Structured response containing:\n        - content: Model's text response\n        - tokens_used: TokenUsage breakdown (input/output/images)\n        - model_used: Actual model used\n        - provider: Always \"openai\"\n        - success: True if call succeeded\n        - error_message: Error details if success=False\n        - request_id: OpenAI request ID for tracing\n        - finish_reason: Completion reason (stop, length, etc.)\n        - timestamp: Response timestamp\n        - estimated_cost_usd: Estimated cost in USD\n\nRaises:\n    InvalidModelError: If model is not supported.\n    InvalidParameterError: If parameters are out of valid range.\n    ImageValidationError: If image validation fails.\n\nExample:\n    >>> # Text-only request\n    >>> response = provider.call(\n    ...     prompt=\"Explain quantum computing\",\n    ...     model=\"gpt-4o\",\n    ...     max_tokens=500,\n    ...     temperature=0.0\n    ... )\n    >>>\n    >>> # Vision request with deterministic output\n    >>> response = provider.call(\n    ...     prompt=\"Extract part number from this drawing\",\n    ...     image=pdf_page_bytes,\n    ...     model=\"gpt-4o\",\n    ...     max_tokens=500,\n    ...     temperature=0.0,\n    ...     seed=42\n    ... )\n    >>> print(f\"Cost: ${response.estimated_cost_usd:.4f}\")\n\nNote:\n    - Vision models required when image/images provided\n    - Images are base64-encoded before sending to API\n    - Automatically retries on rate limits (429) and network errors\n    - Cost estimation uses hardcoded pricing (may drift from actual)",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "prompt",
                    "type": "str"
                  },
                  {
                    "name": "image",
                    "type": "Optional[bytes]"
                  },
                  {
                    "name": "model",
                    "type": "str"
                  },
                  {
                    "name": "max_tokens",
                    "type": "int"
                  },
                  {
                    "name": "temperature",
                    "type": "float"
                  },
                  {
                    "name": "response_format",
                    "type": "Optional[Dict[str, Any]]"
                  },
                  {
                    "name": "seed",
                    "type": "Optional[int]"
                  },
                  {
                    "name": "stream",
                    "type": "bool"
                  },
                  {
                    "name": "images",
                    "type": "Optional[List[bytes]]"
                  }
                ],
                "return_type": "LLMResponse"
              },
              "method_type": "instance"
            },
            {
              "name": "_build_messages",
              "line": 486,
              "docstring": "Build OpenAI API message format.\n\nArgs:\n    prompt: User prompt text.\n    images: List of image bytes (empty for text-only).\n\nReturns:\n    List of message dictionaries in OpenAI format.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "prompt",
                    "type": "str"
                  },
                  {
                    "name": "images",
                    "type": "List[bytes]"
                  }
                ],
                "return_type": "List[Dict[str, Any]]"
              },
              "method_type": "instance"
            },
            {
              "name": "_validate_parameters",
              "line": 515,
              "docstring": "Validate API call parameters.\n\nArgs:\n    model: Model identifier.\n    max_tokens: Maximum response tokens.\n    temperature: Sampling temperature.\n\nRaises:\n    InvalidParameterError: If parameters are out of valid range.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "model",
                    "type": "str"
                  },
                  {
                    "name": "max_tokens",
                    "type": "int"
                  },
                  {
                    "name": "temperature",
                    "type": "float"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "_validate_image",
              "line": 540,
              "docstring": "Validate image data before sending to API.\n\nArgs:\n    image_bytes: Raw image data.\n    index: Image index for error messages.\n\nRaises:\n    ImageValidationError: If image validation fails.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "image_bytes",
                    "type": "bytes"
                  },
                  {
                    "name": "index",
                    "type": "int"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "_encode_image",
              "line": 586,
              "docstring": "Encode image bytes to base64 string for API transmission.\n\nArgs:\n    image_bytes: Raw image data (JPEG, PNG, etc.).\n\nReturns:\n    str: Base64-encoded image string suitable for OpenAI API.\n\nRaises:\n    ImageValidationError: If encoding fails.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "image_bytes",
                    "type": "bytes"
                  }
                ],
                "return_type": "str"
              },
              "method_type": "instance"
            },
            {
              "name": "_is_vision_model",
              "line": 605,
              "docstring": "Check if a model supports vision capabilities.\n\nArgs:\n    model: Model identifier to check.\n\nReturns:\n    bool: True if model supports image inputs.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "model",
                    "type": "str"
                  }
                ],
                "return_type": "bool"
              },
              "method_type": "instance"
            },
            {
              "name": "_estimate_cost",
              "line": 620,
              "docstring": "Estimate API call cost in USD.\n\nArgs:\n    model: Model used for the call.\n    tokens: Token usage breakdown.\n\nReturns:\n    float: Estimated cost in USD.\n\nNote:\n    Uses hardcoded pricing table. Actual costs may vary slightly\n    due to image token calculations and pricing updates.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "model",
                    "type": "str"
                  },
                  {
                    "name": "tokens",
                    "type": "TokenUsage"
                  }
                ],
                "return_type": "float"
              },
              "method_type": "instance"
            },
            {
              "name": "_is_retryable_error",
              "line": 646,
              "docstring": "Determine if an error is retryable.\n\nArgs:\n    error: Exception raised during API call.\n\nReturns:\n    bool: True if error is transient and should be retried.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "error",
                    "type": "Exception"
                  }
                ],
                "return_type": "bool"
              },
              "method_type": "instance"
            },
            {
              "name": "_calculate_backoff_delay",
              "line": 673,
              "docstring": "Calculate exponential backoff delay.\n\nArgs:\n    attempt: Current attempt number (0-indexed).\n\nReturns:\n    float: Delay in seconds.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "attempt",
                    "type": "int"
                  }
                ],
                "return_type": "float"
              },
              "method_type": "instance"
            },
            {
              "name": "get_available_models",
              "line": 688,
              "docstring": "Get list of supported OpenAI model identifiers.\n\nReturns:\n    list[str]: Model IDs that can be passed to call() method.\n        Ordered from most to least capable.\n\nNote:\n    This is a static list of commonly-used models. OpenAI's model\n    availability may change. Use validate_credentials() to test\n    specific model access.\n\nExample:\n    >>> models = provider.get_available_models()\n    >>> print(models[0])  # Most capable model\n    'gpt-4o'",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "list[str]"
              },
              "method_type": "instance"
            },
            {
              "name": "validate_credentials",
              "line": 716,
              "docstring": "Test OpenAI API credentials with minimal request.\n\nMakes a lightweight API call to verify that the api_key is valid and\nhas access to at least one model. Uses gpt-3.5-turbo with 5-token limit\nto minimize cost (<$0.001 per validation).\n\nReturns:\n    bool: True if credentials are valid and API is accessible,\n        False otherwise.\n\nNote:\n    - This method makes a real API call and incurs minimal cost\n    - Network errors or service outages will return False\n    - Successful validation does not guarantee access to all models\n\nExample:\n    >>> provider = OpenAIProvider(api_key=\"sk-...\")\n    >>> if provider.validate_credentials():\n    ...     print(\"Ready to process drawings\")\n    ... else:\n    ...     print(\"Invalid API key or OpenAI service unavailable\")",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "bool"
              },
              "method_type": "instance"
            },
            {
              "name": "close",
              "line": 753,
              "docstring": "Close the OpenAI client and cleanup resources.\n\nCall this method when the provider is no longer needed to release\nnetwork connections and other resources.\n\nExample:\n    >>> provider = OpenAIProvider(api_key=\"sk-...\")\n    >>> try:\n    ...     response = provider.call(...)\n    ... finally:\n    ...     provider.close()",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            },
            {
              "name": "__enter__",
              "line": 776,
              "docstring": "Context manager entry.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  }
                ],
                "return_type": "'OpenAIProvider'"
              },
              "method_type": "instance"
            },
            {
              "name": "__exit__",
              "line": 780,
              "docstring": "Context manager exit.",
              "signature": {
                "parameters": [
                  {
                    "name": "self"
                  },
                  {
                    "name": "exc_type",
                    "type": "Any"
                  },
                  {
                    "name": "exc_val",
                    "type": "Any"
                  },
                  {
                    "name": "exc_tb",
                    "type": "Any"
                  }
                ],
                "return_type": "None"
              },
              "method_type": "instance"
            }
          ],
          "nested_classes": []
        }
      },
      "functions": []
    }
  }
}